{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "995914ca",
   "metadata": {},
   "source": [
    "Groundwater | Case Study\n",
    "\n",
    "# Topic 4 : From Concept to Code: Implementing the Limmat Valley Model\n",
    "\n",
    "Dr. Xiang-Zhao Kong & Dr. Beatrice Marti & Louise Noël du Payrat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de7418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "from shapely.ops import unary_union, linemerge\n",
    "from shapely.affinity import rotate, translate, scale\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.spatial import cKDTree\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling, transform_bounds\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import flopy\n",
    "import flopy.plot as fpl\n",
    "from flopy.discretization import StructuredGrid\n",
    "from flopy.utils import Raster, GridIntersect\n",
    "import flopy.utils.binaryfile as bf\n",
    "\n",
    "# Add the support repo to the path\n",
    "sys.path.append('../SUPPORT_REPO/src')\n",
    "sys.path.append('../SUPPORT_REPO/src/scripts/scripts_exercises')\n",
    "\n",
    "# Import local modules\n",
    "from data_utils import (\n",
    "    download_named_file, \n",
    "    get_default_data_folder, \n",
    "    fast_resample_dem_to_modelgrid\n",
    ")\n",
    "from print_images import display_image\n",
    "from progress_tracking import (\n",
    "    create_model_implementation_progress_tracker, \n",
    "    create_nested_step_completion_marker, \n",
    ")\n",
    "from grid_utils import (\n",
    "    build_grid_gdf_and_ibound, \n",
    "    interpolate_isohypses_to_grid\n",
    ")\n",
    "from river_utils import compute_medial_centerlines\n",
    "from map_utils import plot_interactive_model_domain_3d\n",
    "import modelviz_utils as mvu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f1e22",
   "metadata": {},
   "source": [
    "In the previous steps, we defined our modeling objectives and developed a perceptual model of the Limmat Valley aquifer. We gathered data on the aquifer's geometry, its boundaries, and the key hydrological processes like recharge and river interaction.\n",
    "\n",
    "Now, we will translate this perceptual understanding into a numerical groundwater model using **MODFLOW 2005** and the Python package **FloPy**. This means we describe the aquifer with numbers and grids, so a computer can simulate water movement. This process involves several key steps:\n",
    "\n",
    "1.  **Discretization:** Defining the model grid (layers, rows, columns) that will represent our aquifer in space.\n",
    "2.  **Parameterization:** Assigning hydraulic properties (like conductivity and storage) to the grid cells.\n",
    "3.  **Boundary Conditions:** Implementing the physical boundaries of our system, such as rivers, recharge, and wells.\n",
    "4.  **Solving:** Choosing a numerical solver and running the simulation.\n",
    "5.  **Post-processing:** Visualizing and analyzing the initial results.\n",
    "\n",
    "You can use the checklist below to keep track of your progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b98df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_implementation_progress_tracker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711ca6e",
   "metadata": {},
   "source": [
    "## 1 Workspace Setup\n",
    "Let's begin by setting up our model workspace. This involves creating a flopy workspace that we will fill with the model grid, boundary conditions, and other necessary components as we progress through the case study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a1598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of our model and the workspace where files will be stored.\n",
    "# We'll create a directory in your default data folder for this course to keep \n",
    "# things organized. \n",
    "model_name = 'limmat_valley_model'\n",
    "workspace = os.path.join(get_default_data_folder(), model_name)\n",
    "\n",
    "# Create the workspace directory if it doesn't exist\n",
    "os.makedirs(workspace, exist_ok=True)\n",
    "\n",
    "# Define the path to the MODFLOW executable\n",
    "# We assume it's in a standard location accessible from the system's PATH.\n",
    "executable = 'mf2005' \n",
    "\n",
    "# Create the MODFLOW model object\n",
    "# The model object is the main object in FloPy that represents the MODFLOW model.\n",
    "# It manages all the information about the model, including the grid, boundary \n",
    "# conditions, and other settings.\n",
    "# We'll fill it with the necessary components as we go along.\n",
    "mf = flopy.modflow.Modflow(\n",
    "    modelname=model_name, \n",
    "    model_ws=workspace, \n",
    "    exe_name=executable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782cbac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d9758d",
   "metadata": {},
   "source": [
    "## 2 Discretization (DIS) Package\n",
    "The DIS package defines the geometry and time discretization of a MODFLOW model. It tells MODFLOW how the model domain is divided into layers, rows, and columns, and how time is represented in stress periods.\n",
    "\n",
    "Key inputs are:  \n",
    "- Spatial discretization:  \n",
    "    - nlay, nrow, ncol – number of layers, rows, and columns.  \n",
    "    - delr, delc – cell sizes in the row and column directions.  \n",
    "    - top – array of top elevations of the model domain.  \n",
    "    - botm – arrays of bottom elevations for each layer.  \n",
    "- Temporal discretization:  \n",
    "    - nper – number of stress periods.  \n",
    "    - perlen – length of each stress period.  \n",
    "    - nstp – number of time steps per stress period.  \n",
    "    - tsmult – time step multiplier (controls time-step progression).  \n",
    "    - steady – flag indicating whether a period is steady-state or transient.  \n",
    "\n",
    "The DIS package is the foundation of the model: all other packages (boundary conditions, hydraulic properties, solute transport) build on the grid and time discretization it defines.\n",
    "\n",
    "### 2.1 Model Grid\n",
    "\n",
    "The first step is to define the spatial domain of our model. Based on our perceptual model, we will create a single-layer model. A single-layer model is a 2D model. This 2D model can still represent thickness and vertical flows. For this reason, people sometimes call it quasi-3D or 2.5D. \n",
    "\n",
    "We choose a grid size of 50 meters by 50 meters to start with. This means that each grid cell will represent a 50m x 50m area in the real world. This is a compromise between detail and computational efficiency. It will not allow us to capture small-scale features, but it will provide a good overview of the aquifer's behavior. We can refine the grid later in the modelling process if needed and we can assess the impact of the model resolution on the results in the sensitivity analysis.\n",
    "\n",
    "We start with an initial grid and then rotate it to align with the flow direction. This will help us reduce the number of model cells and speed up the model run time.\n",
    "\n",
    "#### 2.1.1 Data processing: Build the model grid\n",
    "This cell creates a simple, uniform structured grid aligned to the case-study boundary. It reads the boundary polygon, derives grid dimensions from a chosen cell size, and instantiates a FloPy `StructuredGrid` with a defined origin and an initial rotation (set to 0° here for a clean baseline). Use this as a starting point before refining rotation or replacing the dummy elevations.  \n",
    "\n",
    "- Inputs: `boundary_path` (GeoPackage/GeoJSON), `cell_size` (m)\n",
    "- Steps: (1) load boundary, (2) compute grid extent and `nrow`/`ncol`, (3) build uniform `delr`/`delc` and the grid,\n",
    "- Outputs: `modelgrid` (FloPy `StructuredGrid`) with origin, CRS, and rotation set,\n",
    "\n",
    "Note: Rotation is initially 0° to verify alignment. After inspection, update the angle (or use the rotation-iteration helper) and recompute the grid artifacts so downstream visualization, MODFLOW setup, and exports use the chosen rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Compute a structured grid aligned to the model boundary. \n",
    "# Inputs: \n",
    "# - Path to the model boundary polygon `boundary_path` (string)\n",
    "# - Desired cell size `cell_size` (float)\n",
    "# Steps:\n",
    "# 1. Get the model boundary polygon\n",
    "# 2. Compute the grid dimensions based on the boundary and cell size\n",
    "# 3. Create the structured grid\n",
    "# Outputs: \n",
    "# - Structured grid object `modelgrid` (FloPy StructuredGrid)\n",
    "\n",
    "# --- 0. Inputs --- \n",
    "# Path to the model boundary polygon      \n",
    "boundary_path = download_named_file(\n",
    "    name='model_boundary',\n",
    "    data_type='gis'\n",
    ")\n",
    "\n",
    "# Desired cell size\n",
    "cell_size = 50  # meters\n",
    "\n",
    "# --- 1. Get the model boundary polygon --- \n",
    "gdf = gpd.read_file(boundary_path)\n",
    "\n",
    "# --- 2. Compute the grid dimensions based on the boundary and cell size ---\n",
    "# Get the bounding box of the geometry in your GeoPackage\n",
    "# Assuming you want to use the total bounds of all geometries in the GeoPackage\n",
    "xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "\n",
    "# Rotation of the grid to minimize the number of cells. The grid is rotated \n",
    "# around the lower left corner (xll, yll).\n",
    "rotation = 0  # degrees, let's first see how it looks without rotation.\n",
    "\n",
    "# Calculate number of rows and columns\n",
    "ncol = int(np.ceil((xmax - xmin) / cell_size))\n",
    "nrow = int(np.ceil((ymax - ymin) / cell_size))\n",
    "\n",
    "# Define delr and delc (cell widths along rows and columns)\n",
    "# Delr and delc are the widths of the grid cells in the x and y directions, respectively.\n",
    "# Here, we assume a uniform grid, so we can use the same cell size for all cells.\n",
    "# If you have varying cell sizes, you would need to define them accordingly.\n",
    "# For a non-uniform grid, you would typically provide arrays of varying sizes.\n",
    "# Here, we use np.full to create arrays filled with the cell_size value.\n",
    "# For a regular grid, these will be arrays of the cell_size\n",
    "delr = np.full(ncol, cell_size)\n",
    "delc = np.full(nrow, cell_size)\n",
    "\n",
    "# Define the origin of the grid (lower-left corner)\n",
    "# FloPy by default assumes the origin (xll, yll) is the lower-left corner\n",
    "xll = xmin\n",
    "yll = ymin\n",
    "\n",
    "# We define the number of layers in the model.\n",
    "nlay = 1\n",
    "\n",
    "# We use dummy data for the top and the bottom elevation for now. We'll replace \n",
    "# these with actual data later.\n",
    "top = np.ones((nrow, ncol)) * 100 # Dummy top elevation\n",
    "botm = np.ones((nlay, nrow, ncol)) * 50 # Dummy bottom elevation\n",
    "\n",
    "# Create the structured grid object\n",
    "# The StructuredGrid object is used to define the grid structure in FloPy.\n",
    "# Check out the documentation for more details: \n",
    "# https://flopy.readthedocs.io/en/stable/source/flopy.discretization.structuredgrid.html\n",
    "modelgrid = StructuredGrid(\n",
    "    delr=delr,\n",
    "    delc=delc,\n",
    "    top=top,\n",
    "    botm=botm,\n",
    "    xoff=xll,\n",
    "    yoff=yll,\n",
    "    angrot=rotation,\n",
    "    lenuni=2,  # Length unit code: 2 for meters\n",
    "    crs=gdf.crs.to_string() # Automatically get CRS from geopackage\n",
    ")\n",
    "print(\"Model grid created with the following parameters:\")\n",
    "print(modelgrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca541a6",
   "metadata": {},
   "source": [
    "#### 2.1.2 Visualization: Quick grid quality assessment\n",
    "Overlay the FloPy grid on the case-study boundary to verify extent, rotation, and coverage (Figure 1). Grid lines are drawn, and a legend highlights the boundary. The cell also prints the total number of model cells (nlay × nrow × ncol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: visually check extent, rotation, and active cells. \n",
    "# Inputs: \n",
    "# - modelgrid\n",
    "# - gdf\n",
    "# Plots: Boundary and grid overlay. \n",
    "# No side effects in this cell.\n",
    "\n",
    "# Plotting the grid \n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10)) # Adjusted figsize to be more square if needed\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax) # Pass ax directly\n",
    "pc = pmv.plot_array(modelgrid.top, alpha=0.5, cmap='terrain') # Added cmap for better visualization\n",
    "pmv.plot_grid()\n",
    "\n",
    "# Plot the GeoPackage boundary on top for verification\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "# Add a legend for the boundary\n",
    "boundary_legend = mlines.Line2D([], [], color='red', label='Model Boundary')\n",
    "ax.legend(handles=[boundary_legend], loc='upper right')\n",
    "\n",
    "ax.set_title(\"Figure 1: Initial FloPy Grid with GeoPackage Boundary (red).\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "plt.show()\n",
    "\n",
    "# Build grid polygons, tag active cells (≥50% inside), and get IBOUND\n",
    "grid_gdf, ibound = build_grid_gdf_and_ibound(\n",
    "    modelgrid=modelgrid,\n",
    "    boundary_gdf=gdf,        # your boundary GeoDataFrame\n",
    "    frac_threshold=0.5,      # change if needed\n",
    "    nlay=nlay                 # use your model's nlay\n",
    ")\n",
    "\n",
    "# Count the number of cells in the grid\n",
    "total_cells = ncol * nrow * nlay\n",
    "print(f\"Total number of cells in the grid: {total_cells}\")\n",
    "\n",
    "# Count the number of active cells\n",
    "active_cells = ibound[ibound > 0].sum()\n",
    "print(f\"Total number of active cells in the grid: {active_cells}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544731a3",
   "metadata": {},
   "source": [
    "Congratulation! You have successfully set up your first model grid and display it in Figure 1. The grid is a fundamental part of the model, as it defines the spatial resolution and extent of the simulation.  \n",
    "\n",
    "You will notice, that the main flow direction is diagonal to the cells orientation. There are a few reasons why this is sub-optimal: \n",
    "\n",
    "1. A diagonal flow direction can lead to *numerical dispersion* and other artifacts in the simulation results. As you might know from other lectures, the finite-difference method used in MODFLOW, calculates flow across the faces of the grid cells. It cannot directly compute flow diagonally across a single cell. Instead, it approximates a diagonal path as a series or orthogonal, \"stair-step\" movements from one cell to the next. We therefore try to allign the x-axis of the model grid along the main flow direction of a groundwater body. \n",
    "2. We also try to align the grid with major hydrogeological features and boundaries to avoid creating jagged, \"stair-step\" boundaries.\n",
    "3. Because Modflow2005 only includes active model cells (inside the model boundary) in the simulation, the number of active model cells matters. It is the most important factor in the model design that determines the computational speed of the simulation. \n",
    "\n",
    "#### 2.1.3 Typically necessary iterations \n",
    "Creating a model grid is rarely a one-shot process. After the first attempt, visualization often reveals mismatches that require adjustment. Common iterations include:\n",
    "\n",
    "- Rotation and alignment – adjusting the grid angle so that rows/columns follow the main axis of the model domain (e.g., a river valley).  \n",
    "- Extent and origin – shifting or expanding the grid so the boundary fits cleanly within the grid cells.  \n",
    "- Cell size – refining or coarsening resolution to balance accuracy with computational cost.\n",
    "\n",
    "Such iterations are a normal part of model development. We visualize, adjust parameters, and regenerate the grid until it represents the case study domain well enough for the next steps. Here, we demonstrate one such iteration: rotating the grid to better align with the flow direction and buffering the model boundary to ensure full coverage.\n",
    "\n",
    "##### Grid Rotation and Buffering\n",
    "We rotate the model grid to align it with the model boundary. We will also buffer the model boundary to ensure that the grid cells cover the entire area of interest. The easiest way to do that are by following the steps below, each step is accompanied by visual checks: \n",
    "1. Rotate the model boundary polygon to align with the main flow direction and major hydrogeological features. \n",
    "2. Buffer the rotated model boundary polygon to ensure that the grid cells cover the entire area of interest.\n",
    "3. Create a new grid based on the buffered polygon and apply the rotation to the structured grid.\n",
    "\n",
    "We start with the rotation of the model boundary polygon. It should be rotated to minimize the number of grid cells outside the model boundary. Optimally, the grid cells should be aligned with the main flow direction.  \n",
    "\n",
    "The rotation angle (variable `grid_rotation_angle` in code below) can be adjusted by trial and error to find the best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fb4aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Rotation of the model boundary --- \n",
    "# To generate a rotated grid in FloPy, the easiest way is to create a regular \n",
    "# grid and then apply a rotation transformation to it. \n",
    "# We first rotate the model boundary polygon to the desired angle. From there, \n",
    "# we can create a regular grid and then apply the rotation to the grid in the \n",
    "# structured grid object.\n",
    "# This approach allows us to maintain the integrity of the grid while applying\n",
    "# the desired rotation.\n",
    "# Every step includes visual checks.\n",
    "\n",
    "# Buffer the model boundary gdf\n",
    "gdf['geometry'] = gdf['geometry'].buffer(10)\n",
    "\n",
    "# Define the rotation angle in degrees\n",
    "grid_rotation_angle = 30  # degrees, identified by trial and error, you can adjust this angle to minimize the number of cells outside the boundary\n",
    "origin_rotation = Point(0, 0)  # Origin for rotation, can be adjusted as needed\n",
    "# Rotate the model boundary polygon\n",
    "gdf_rotated = gdf.copy()\n",
    "\n",
    "gdf_rotated['geometry'] = gdf_rotated['geometry'].apply(\n",
    "    lambda geom: rotate(geom, grid_rotation_angle, origin=origin_rotation)\n",
    ")\n",
    "# Get the bounding box of the rotated geometry\n",
    "xmin_rotated, ymin_rotated, xmax_rotated, ymax_rotated = gdf_rotated.total_bounds\n",
    "# Plot the rotated boundary to verify\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "gdf_rotated.plot(ax=ax, facecolor='none', edgecolor='blue', linewidth=2)\n",
    "ax.set_title(\"Figure 2: Rotated Model Boundary.\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f2518",
   "metadata": {},
   "source": [
    "Figure 2 shows the rotated model boundary. An angle of 30 degrees seems to be suitable for the Limmat Valley model. In the next step, we will create a new grid based on this rotated model boundary (see Figure 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Creation of a new Model Grid based on the rotated Model Boundary ---\n",
    "# We now have new bounding box coordinates for the rotated model boundary. \n",
    "# These we need to rotate back to the original coordinate system to create a\n",
    "# regular grid that fits the rotated boundary.\n",
    "# We use the rotated bounding box to define the grid dimensions.\n",
    "# Calculate the new grid dimensions based on the rotated bounding box\n",
    "width_rotated = xmax_rotated - xmin_rotated\n",
    "height_rotated = ymax_rotated - ymin_rotated\n",
    "\n",
    "# Calculate the number of rows and columns based on the rotated bounding box\n",
    "ncol_rotated = int(np.ceil(width_rotated / cell_size)) - 1 # Based on visual inspection of rotated grid.\n",
    "nrow_rotated = int(np.ceil(height_rotated / cell_size))\n",
    "\n",
    "# Compare number of rows and columns with the original grid\n",
    "print(f\"Original Grid: {ncol} columns, {nrow} rows\")\n",
    "print(f\"Rotated Grid: {ncol_rotated} columns, {nrow_rotated} rows\")\n",
    "\n",
    "# Define the delr and delc for the rotated grid\n",
    "delr_rotated = np.full(ncol_rotated, cell_size)\n",
    "delc_rotated = np.full(nrow_rotated, cell_size) \n",
    "\n",
    "# Plot the rotated grid and the rotated boundary to verify\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "# Create a new StructuredGrid with the rotated dimensions\n",
    "rotated_grid = StructuredGrid(\n",
    "    delr=delr_rotated,\n",
    "    delc=delc_rotated,\n",
    "    top=np.ones((nrow_rotated, ncol_rotated)) * 100,  # Example top elevation\n",
    "    botm=np.ones((nlay, nrow_rotated, ncol_rotated)) * 50,  # Example bottom elevation\n",
    "    xoff=xmin_rotated,  # Use the lower-left of the rotated extent\n",
    "    yoff=ymin_rotated,  # Use the lower-left of the rotated extent\n",
    "    angrot=0,  # We are currently in the rotated coordinate system, so no additional rotation is needed\n",
    "    lenuni=2,  # Length unit code: 2 for meters\n",
    "    crs=gdf_rotated.crs.to_string()  # Automatically get CRS from geopackage\n",
    ")\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=rotated_grid, ax=ax)\n",
    "pc = pmv.plot_array(rotated_grid.top, alpha=0.5, cmap='terrain')\n",
    "pmv.plot_grid()\n",
    "ax.set_aspect('equal', adjustable='box') # Ensure correct aspect ratio\n",
    "ax.set_title(\"Figure 3: Rotated FloPy Grid with Rotated Boundary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4dbd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Rotation of the new Model Grid in the CH Coordinate System ---\n",
    "# Now we need to rotate the lower-left corner of the rotated grid back to the \n",
    "# original coordinate system.\n",
    "# The lower-left corner of the rotated bounding box\n",
    "# Create points from the rotated bounding box coordinates\n",
    "min_point_rotated = Point(xmin_rotated, ymin_rotated)\n",
    "max_point_rotated = Point(xmax_rotated, ymax_rotated)\n",
    "\n",
    "# Apply inverse rotation (negative angle) around the same origin\n",
    "min_point_original = rotate(min_point_rotated, -grid_rotation_angle, \n",
    "                            origin=origin_rotation)\n",
    "max_point_original = rotate(max_point_rotated, -grid_rotation_angle, \n",
    "                            origin=origin_rotation)\n",
    "\n",
    "# Extract the coordinates\n",
    "xmin_original = min_point_original.x\n",
    "ymin_original = min_point_original.y\n",
    "xmax_original = max_point_original.x\n",
    "ymax_original = max_point_original.y\n",
    "\n",
    "print(f\"Original coordinates after inverse rotation:\")\n",
    "print(f\"xmin: {xmin_original:.2f}, ymin: {ymin_original:.2f}\")\n",
    "print(f\"xmax: {xmax_original:.2f}, ymax: {ymax_original:.2f}\")\n",
    "\n",
    "xll = xmin_original\n",
    "yll = ymin_original\n",
    "\n",
    "print(f\"Corrected grid lower-left corner:\")\n",
    "print(f\"xll = {xll:.2f}\")\n",
    "print(f\"yll = {yll:.2f}\")\n",
    "print(f\"Number of cells in the rotated grid: {nrow_rotated * ncol_rotated * nlay}\")\n",
    "print(f\"Number of cells in the original grid: {nrow * ncol * nlay}\")\n",
    "print(f\"The rotated grid has {round(((nrow * ncol * nlay) - (nrow_rotated * ncol_rotated * nlay))/(nrow * ncol * nlay)*100)} % less cells than the initial grid.\")\n",
    "\n",
    "# Update the top and bottom elevation arrays\n",
    "# For simplicity, we keep the dummy elevations. They are reset later.\n",
    "top = np.ones((nrow_rotated, ncol_rotated)) * 100  # Example top elevation\n",
    "botm = np.ones((nlay, nrow_rotated, ncol_rotated)) * 50  # Example bottom elevation\n",
    "\n",
    "# Create the FloPy structured grid with the rotated bounding box\n",
    "modelgrid = StructuredGrid(\n",
    "    delr=delr_rotated,\n",
    "    delc=delc_rotated,\n",
    "    top=top,\n",
    "    botm=botm,\n",
    "    xoff=xmin_original,  # Use the lower-left of the rotated extent\n",
    "    yoff=ymin_original,  # Use the lower-left of the rotated extent\n",
    "    angrot=-grid_rotation_angle,  # Apply the desired rotation to the grid\n",
    "    lenuni=2,  # Length unit code: 2 for meters\n",
    "    crs=gdf.crs.to_string()  # Automatically get CRS from geopackage\n",
    ")\n",
    "\n",
    "# Update grid polygons, tag active cells (≥50% inside), and get IBOUND\n",
    "grid_gdf, ibound = build_grid_gdf_and_ibound(\n",
    "    modelgrid=modelgrid,\n",
    "    boundary_gdf=gdf,        # your boundary GeoDataFrame\n",
    "    frac_threshold=0.5,      # change if needed\n",
    "    nlay=nlay                 # use your model's nlay\n",
    ")\n",
    "# Count the number of active cells\n",
    "active_cells = ibound[ibound > 0].sum()\n",
    "print(f\"Total number of active cells in the grid: {active_cells}\")\n",
    "\n",
    "print(\"Model grid created with the following parameters:\")\n",
    "print(modelgrid)\n",
    "# Add the modelgrid to the MODFLOW model\n",
    "mf.modelgrid = modelgrid\n",
    "\n",
    "# Plot the rotated grid and the model_boundary to check alignment\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mf.modelgrid, ax=ax)\n",
    "pc = pmv.plot_array(mf.modelgrid.top, alpha=0.5, cmap='terrain')\n",
    "pmv.plot_grid() \n",
    "\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Model Boundary')\n",
    "ax.legend(handles=[red_line], loc='upper right')\n",
    "ax.set_title(\"Figure 4: Correctly Rotated Grid with Model Boundaries\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "plt.show()\n",
    "ax.set_aspect('equal', adjustable='box') # Ensure correct aspect ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb5ef7",
   "metadata": {},
   "source": [
    "After rotating the grid, the number of cells increases slightly because the rotated extent no longer fits as tightly around the model boundary. We accept this trade-off, since aligning the grid with the main groundwater flow direction reduces numerical dispersion and improves the accuracy of simulated flow paths.\n",
    "\n",
    "You might wonder why we care about numerical dispersion, given the large uncertainties involved in groundwater flow modelling. Even though groundwater flow models involve many uncertainties (hydraulic properties, recharge estimates, boundary conditions), we still want to minimize numerical errors such as numerical dispersion. The reason is simple: uncertainties are part of the real system and can be reduced with better data or calibration, but numerical errors are artificial and only come from how we discretize and solve the equations.\n",
    "\n",
    "Numerical dispersion can smear sharp flow patterns, mix solutes unrealistically, or dampen hydraulic gradients. If we can reduce this error (e.g., by aligning the grid with the main flow direction), the model output better reflects the true hydrogeological processes, and we can focus on the real uncertainties that matter for decision-making.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c7101",
   "metadata": {},
   "source": [
    "#### 2.1.4 Save model grid for external use\n",
    "Let's export the model grid to a shapefile in case we want to use it for visualizations outside flopy. Visualizing it in a different context, e.g. in QGIS, is a good sanity check. This will help us to verify that the grid is correctly aligned with the model boundary and that the cells are not too large or too small (see Figure 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model grid to shapefile\n",
    "# Create a list to store grid cell polygons\n",
    "grid_cells = []\n",
    "\n",
    "# Get grid cell vertices using FloPy's grid functionality\n",
    "for i in range(modelgrid.nrow):\n",
    "    for j in range(modelgrid.ncol):\n",
    "        # Get cell vertices\n",
    "        cell_vertices = modelgrid.get_cell_vertices(i, j)\n",
    "        \n",
    "        # Create polygon from vertices\n",
    "        cell_polygon = Polygon(cell_vertices)\n",
    "        \n",
    "        # Store cell information\n",
    "        grid_cells.append({\n",
    "            'row': i,\n",
    "            'col': j,\n",
    "            'cell_id': f\"{i}_{j}\",\n",
    "            'geometry': cell_polygon,\n",
    "            'x': modelgrid.xcellcenters[i, j],\n",
    "            'y': modelgrid.ycellcenters[i, j]\n",
    "        })\n",
    "\n",
    "# Create GeoDataFrame\n",
    "grid_gdf = gpd.GeoDataFrame(grid_cells, crs=modelgrid.crs)\n",
    "\n",
    "# Export to GeoPackage\n",
    "grid_geopackage_path = os.path.join(workspace, 'model_grid.gpkg')\n",
    "grid_gdf.to_file(grid_geopackage_path, driver='GPKG', layer='model_grid')\n",
    "\n",
    "print(f\"Model grid exported to: {grid_geopackage_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(\n",
    "    image_filename='model_grid_on_openstreetmap.png', \n",
    "    image_folder='4_model_implementation',\n",
    "    caption='Figure 5: Model grid (grey) overlaid on OpenStreetMap background. The grid is rotated to minimize the number of cells while maintaining alignment with the model boundary (red). '\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551d7fb",
   "metadata": {},
   "source": [
    "We now have a regular grid that fits the rotated boundary. The grid is defined by its origin, the number of rows and columns, and the cell size. The grid is a fundamental part of the model, as it defines the spatial resolution and extent of the simulation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d271cb",
   "metadata": {},
   "source": [
    "> **Optional Challenge:**   \n",
    "> Try to find a better rotation angle by adjusting the `grid_rotation_angle` variable in the code above. You can also try to change the `cell_size` to see how it affects the number of cells inside the model boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e07d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29cb3f9",
   "metadata": {},
   "source": [
    "### 2.2 Model Top\n",
    "Now that we have the model grid, let's define the top of the model. The top of the model will be defined by the DEM, which we will use to create a single layer model. \n",
    "\n",
    "#### 2.2.1 Data processing: Resample DEM to model grid\n",
    "We derive the model top elevation from the DEM. These are the steps to achieve this:\n",
    "\n",
    "1. Resample the DEM to the model grid.\n",
    "2. Extract the elevation values at the model grid locations.\n",
    "3. Assign these values to the model top layer.\n",
    "\n",
    "Let's have a look at our DEM in the model area (Figure 6). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Inspect the DEM ---\n",
    "# Get the DEM data from the server\n",
    "dem_path = download_named_file(\n",
    "    name='dem',\n",
    "    data_type='gis'\n",
    ")\n",
    "\n",
    "# Load it into object rio\n",
    "rio = Raster.load(dem_path)\n",
    "\n",
    "# Get the DEM array and its valid index\n",
    "arr = rio.get_array(1)\n",
    "idx = np.isfinite(arr)\n",
    "\n",
    "# Get the min and max values for plotting\n",
    "vmin, vmax = arr[idx].min(), arr[idx].max()\n",
    "\n",
    "# Plot the DEM\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "ax = rio.plot(ax=ax, vmin=vmin, vmax=vmax)\n",
    "plt.colorbar(ax.images[0], shrink=0.7)\n",
    "# pmv.plot_grid(ax=ax, lw=0.5, color=\"white\")\n",
    "ax.set_title(\"Figure 6: DEM in original resolution in the model area.\")\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53385c00",
   "metadata": {},
   "source": [
    "The resolution of the DEM does not match the model grid resolution, so we will resample the DEM to fit the model grid. We will use the `rio.resample_to_grid` function to resample the DEM to the model grid resolution. This will create a new raster that matches the model grid resolution and can be used as the model top (Figure 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Resample the DEM ---\n",
    "# Depending on the resolution of the DEM, resampling can be computationally \n",
    "# intensive.\n",
    "t0 = time.time() # To log the time it takes to resample the DEM\n",
    "model_top = rio.resample_to_grid(modelgrid, band=rio.bands[0], method=\"nearest\")\n",
    "resample_time = time.time() - t0\n",
    "\n",
    "# We round to 10 centimeters to avoid having to store too many digits\n",
    "model_top = np.round(model_top, 1)\n",
    "\n",
    "# Update vmin and vmax based on the resampled data\n",
    "vmin, vmax = model_top.min(), model_top.max()\n",
    "\n",
    "# Now to visualize using flopy and matplotlib\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "im = pmv.plot_array(model_top, masked_values=rio.nodatavals, vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Overlay the buffered model boundary with proper legend handling\n",
    "boundary_patch = gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "\n",
    "plt.title(f\"Resample time, nearest neighbor: {resample_time:.3f} sec\")\n",
    "plt.colorbar(im, shrink=0.7, label=\"Elevation (m a.s.l.)\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "\n",
    "# Create custom legend handle to avoid warnings\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Buffered Model Boundary')\n",
    "ax.legend(handles=[red_line])\n",
    "ax.set_title(\"Figure 7: Resampled DEM on Model Grid with Buffered Model Boundary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d216a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Save the model top layer to a file for later use\n",
    "# This step makes sense if resampling is slow. Instead of repeating the \n",
    "# resampling every time you run the notebook, you can just load the\n",
    "# precomputed file.\n",
    "top_file_path = os.path.join(workspace, 'model_top.npy')\n",
    "np.save(top_file_path, model_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bdb87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7da4d4",
   "metadata": {},
   "source": [
    "### 2.3 Model Bottom\n",
    "\n",
    "Next we tackle the bottom layer. The groundwater map of the canton of Zurich shows contour lines of the thickness of the aquifer for the deeper zones but for the shallower zones we see the range of the aquifer thickness. We calculate the bottom of the model by subtracting the thickness of the unsaturated zone and the aquifer thickness from the model top. \n",
    "\n",
    "$$ \\text{Bottom of the model} = \\text{Top of the model} - \\text{Unsaturated thickness} - \\text{Aquifer thickness}$$\n",
    "\n",
    "We'll walk you through the steps to create the bottom layer of the model in the following code cells.\n",
    "\n",
    "#### 2.3.1 Data processing: Unsaturated thickness\n",
    "The unsaturated thickness is the depth from the ground surface to the water table. It varies across the model area and is influenced by factors such as topography, soil properties, and land use. In our context, we can derive it from the difference between the DEM and the interpolated water table elevation. Let's interpolate the groundwater table elevation to the model grid and calculate the unsaturated thickness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6534657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lines of equal head elevations \n",
    "isolines = download_named_file('groundwater_map_norm', data_type='gis')\n",
    "gdf_isolines = gpd.read_file(isolines, layer='GS_GW_ISOHYPSE_MW_L')\n",
    "\n",
    "# Print column information to help identify elevation column\n",
    "#print(\"Available columns in geodataframe:\")\n",
    "#print(gdf_isolines.columns.tolist())\n",
    "#print(\"\\nFirst few rows:\")\n",
    "#print(gdf_isolines.head())\n",
    "\n",
    "gw_elevations = interpolate_isohypses_to_grid(gdf_isolines, modelgrid)\n",
    "print(f\"Interpolation successful! Grid shape: {gw_elevations.shape}\")\n",
    "print(f\"Elevation range: {np.nanmin(gw_elevations):.2f} to {np.nanmax(gw_elevations):.2f}\")\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(15, 6))\n",
    "        \n",
    "# Plot interpolated grid\n",
    "im = ax1.imshow(gw_elevations, extent=modelgrid.extent, origin='lower', cmap='viridis')\n",
    "ax1.set_title('Interpolated Groundwater Elevations')\n",
    "plt.colorbar(im, ax=ax1, label='Elevation (m)')\n",
    "\n",
    "plt.tight_layout()\n",
    "ax1.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ee2092",
   "metadata": {},
   "source": [
    "#### 2.3.1 Data processing: Interpolate aquifer thickness to model grid\n",
    "We'll start by displaying the contours of aquifer thickness in the model area (Figure 8). This will help us visualize the aquifer thickness and understand how it varies across the model area. Please note that the aquifer thickness is very thin in parts of the model area. Cells in this region may run dry during the simulation, which is a common occurrence in groundwater models of shallow unconfined aquifers. By default, cells that run dry become impermeable in modflow but we can set rewetting parameters which allow the model to iteratively re-activate dry cells. This can, however, lead to numerical instability. We'll have to keep an eye on this during the simulation and adjust the model parameters for re-wetting if necessary. \n",
    "\n",
    "A summary of the steps:\n",
    "1. Visualize the aquifer thickness contours.\n",
    "2. Interpolate the aquifer thickness to the model grid.\n",
    "3. Subtract the aquifer thickness from the model top to obtain the model bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc573a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Visualize available aquifer bottom data ---\n",
    "# Load the polygon layers with information about aquifer thickness.\n",
    "gw_map_path = download_named_file(\n",
    "    name='groundwater_map_norm', \n",
    "    data_type='gis', \n",
    ")\n",
    "\n",
    "deep_contours_gdf = gpd.read_file(gw_map_path, layer=\"GS_GW_MAECHTIGKEIT_L\")\n",
    "shallow_gdf = gpd.read_file(gw_map_path, layer=\"GS_GW_LEITER_F\") \n",
    "\n",
    "# Reproject the GeoDataFrames to match the model grid CRS\n",
    "deep_contours_gdf = deep_contours_gdf.to_crs(modelgrid.crs)\n",
    "shallow_gdf = shallow_gdf.to_crs(modelgrid.crs)\n",
    "\n",
    "# For the deep contours, the aquifer thickness in meters is in the field \n",
    "# \"LABEL\". For the shallow contours, we have the field \"GWLTYP\" which corresponds \n",
    "# to a range of aquifer thickness. We have to manually assign a label attribute \n",
    "# here, using the GIS-Broswer as reference. \n",
    "# type_labels maps GWLTYP to the corresponding aquifer thickness in meters.\n",
    "type_labels = {\n",
    "        1: 2, \n",
    "        2: 2,\n",
    "        4: 10,\n",
    "        6: 20,\n",
    "    }\n",
    "# Create a new column 'aquifer_thickness' in shallow_gdf\n",
    "shallow_gdf['aquifer_thickness'] = shallow_gdf['GWLTYP'].map(type_labels)\n",
    "\n",
    "# Create a new column 'aquifer_thickness' in deep_contours_gdf\n",
    "deep_contours_gdf['aquifer_thickness'] = deep_contours_gdf['LABEL'].astype(float)\n",
    "\n",
    "# Discard rows in the shallow_gdf where aquifer_thickness is NaN\n",
    "shallow_gdf = shallow_gdf.dropna(subset=['aquifer_thickness'])\n",
    "\n",
    "# Now we need to make sure all shapes are available as lines. \n",
    "# Convert shallow polygons to contour lines by taking their boundaries\n",
    "shallow_contours_gdf = shallow_gdf.copy()\n",
    "shallow_contours_gdf.geometry = shallow_contours_gdf.geometry.boundary\n",
    "\n",
    "# Define the buffered model boundary as a contour with 5m thickness (2 meters \n",
    "# is very shallow and will quickly lead to cells drying).\n",
    "boundary_contour_gdf = gdf.copy()\n",
    "boundary_contour_gdf['aquifer_thickness'] = 5.0\n",
    "\n",
    "# View the first few rows of the deep contours and shallow contours\n",
    "# print(\"Deep contours (aquifer thickness in meters):\")\n",
    "# print(deep_contours_gdf[['LABEL', 'aquifer_thickness']].head())\n",
    "# print(\"\\nShallow contours (aquifer thickness in meters):\")\n",
    "# print(shallow_gdf[['GWLTYP', 'aquifer_thickness']].head())\n",
    "\n",
    "# Combine all contour dataframes into one\n",
    "# We select only the 'aquifer_thickness' and 'geometry' columns to ensure consistency\n",
    "all_contours_gdf = gpd.GeoDataFrame(\n",
    "    pd.concat([\n",
    "        deep_contours_gdf[['aquifer_thickness', 'geometry']],\n",
    "        shallow_contours_gdf[['aquifer_thickness', 'geometry']],\n",
    "        boundary_contour_gdf[['aquifer_thickness', 'geometry']]\n",
    "    ], ignore_index=True),\n",
    "    crs=gdf.crs\n",
    ")\n",
    "\n",
    "# Clip the contours to the model boundary polygon\n",
    "clipped_gdf = gpd.clip(all_contours_gdf, gdf)\n",
    "\n",
    "# Now we can plot the combined contours\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "clipped_gdf.plot(ax=ax, column='aquifer_thickness', cmap='viridis',\n",
    "                 legend=True, legend_kwds={'label': \"Aquifer Thickness (m)\"})\n",
    "ax.set_title(\"Figure 8: Contours of aquifer thickness in the model area.\")\n",
    "ax.set_xlabel(\"X-coordinate\")\n",
    "ax.set_ylabel(\"Y-coordinate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c507e7c",
   "metadata": {},
   "source": [
    "Now we need to subtract the aquifer thickness from the top of the model to define the bottom of the model. \n",
    "\n",
    "For this, we interpolate the contour lines of the aquifer thickness to the model grid (Figure 9). This will create a new raster that matches the model grid resolution which we can subtract from the top of the model to obtain the bottom elevation (Figure 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497fea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Interpolate the aquifer thickness on the model grid and calculate \n",
    "# aquifer thickness\n",
    "\n",
    "# ---    Interpolate aquifer thickness to model grid ---\n",
    "# Extract all points from the combined contour lines for interpolation\n",
    "points_for_interp = []\n",
    "for idx, row in clipped_gdf.iterrows():\n",
    "    if row.geometry is None or row.geometry.is_empty:\n",
    "        continue\n",
    "    if row.geometry.geom_type == 'MultiLineString':\n",
    "        for line in row.geometry.geoms:\n",
    "            for x, y in line.coords:\n",
    "                points_for_interp.append((x, y, row['aquifer_thickness']))\n",
    "    elif row.geometry.geom_type == 'LineString':\n",
    "        for x, y in row.geometry.coords:\n",
    "            points_for_interp.append((x, y, row['aquifer_thickness']))\n",
    "\n",
    "points_for_interp = np.array(points_for_interp)\n",
    "\n",
    "# --- PLOT: Points for Interpolation of Aquifer Thickness on Model Grid ---\n",
    "# Uncomment the following lines to visualize the points used for interpolation\n",
    "# fig, ax = plt.subplots(figsize=(12, 12))\n",
    "# sc = ax.scatter(points_for_interp[:, 0], points_for_interp[:, 1], c=points_for_interp[:, 2], cmap='viridis', s=5)\n",
    "# plt.colorbar(sc, label='Aquifer Thickness (m)')\n",
    "# ax.set_title(\"Step 1. Points from All Contours for Interpolation\")\n",
    "# ax.set_xlabel(\"X-coordinate\")\n",
    "# ax.set_ylabel(\"Y-coordinate\")\n",
    "# ax.set_aspect('equal', adjustable='box')\n",
    "# plt.show()\n",
    "\n",
    "# Interpolate directly onto the model grid cell centers\n",
    "grid_x, grid_y = modelgrid.xcellcenters, modelgrid.ycellcenters\n",
    "\n",
    "# First, use linear interpolation. This creates a smooth surface between contours.\n",
    "aquifer_thickness_linear = griddata(\n",
    "    points_for_interp[:, :2], \n",
    "    points_for_interp[:, 2],\n",
    "    (grid_x, grid_y), \n",
    "    method='linear'\n",
    ")\n",
    "\n",
    "# Linear interpolation leaves NaNs outside the convex hull of the data.\n",
    "# Second, fill these NaNs using nearest neighbor interpolation to cover the whole grid.\n",
    "nan_indices = np.isnan(aquifer_thickness_linear)\n",
    "aquifer_thickness_resampled = griddata(\n",
    "    points_for_interp[:, :2], \n",
    "    points_for_interp[:, 2],\n",
    "    (grid_x[nan_indices], grid_y[nan_indices]), \n",
    "    method='nearest'\n",
    ")\n",
    "aquifer_thickness_linear[nan_indices] = aquifer_thickness_resampled\n",
    "\n",
    "# The final resampled grid\n",
    "aquifer_thickness_resampled = aquifer_thickness_linear\n",
    "\n",
    "# Save aquifer thickness to a file for later use\n",
    "aquifer_thickness_file_path = os.path.join(workspace, 'aquifer_thickness.npy')\n",
    "np.save(aquifer_thickness_file_path, aquifer_thickness_resampled)\n",
    "\n",
    "# --- PLOT: Resampled Grid on Model Grid ---\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "im = pmv.plot_array(aquifer_thickness_resampled)\n",
    "plt.colorbar(im, shrink=0.7, label=\"Aquifer Thickness (m)\")\n",
    "ax.set_title(\"Figure 9: Aquifer thickness resampled to model grid.\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.show()\n",
    "\n",
    "# --- 3. Calculate the aquifer bottom ---\n",
    "# Subtract the aquifer thickness from the groundwater level to define the bottom\n",
    "model_bottom = gw_elevations - aquifer_thickness_resampled\n",
    "\n",
    "# Ensure the model bottom is a 3d array (nlay, nrow_rotated, ncol_rotated)\n",
    "if model_bottom.ndim == 2:\n",
    "    model_bottom = model_bottom[np.newaxis, :, :]  # Add a new axis for layers\n",
    "\n",
    "# --- PLOT: Final Aquifer Bottom ---\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "im = pmv.plot_array(model_bottom, vmin=np.nanmin(model_bottom), \n",
    "                    vmax=np.nanmax(model_bottom))\n",
    "plt.colorbar(im, shrink=0.7, label=\"Elevation (m a.s.l.)\")\n",
    "ax.set_title(\"Figure 10: Final aquifer bottom elevation. \")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "# Overlay the buffered model boundary with proper legend handling\n",
    "boundary_patch = gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "# Create custom legend handle to avoid warnings\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Buffered Model Boundary')\n",
    "ax.legend(handles=[red_line])\n",
    "ax.set_title(\"Figure 10: Resampled DEM on Model Grid with Buffered Model Boundary\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6afc17a",
   "metadata": {},
   "source": [
    "#### 2.3.2 Visual check of updated model grid\n",
    "Now we update the structured grid object by replacing the dummy model top in the model object with our resampled DEM. This will ensure that the model top reflects the actual topography of the Limmat Valley. We visualize the final model grid with the top elevation (Figure 11) for verification.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new model top and bottom to the modelgrid\n",
    "modelgrid = StructuredGrid(\n",
    "    delr=delr_rotated,\n",
    "    delc=delc_rotated,\n",
    "    top=model_top,\n",
    "    botm=model_bottom,\n",
    "    nlay=nlay,\n",
    "    xoff=xmin_original, # Use the lower-left of the rotated extent\n",
    "    yoff=ymin_original, # Use the lower-left of the rotated extent\n",
    "    angrot=-grid_rotation_angle, # Apply the desired rotation to the grid\n",
    "    lenuni=2,  # Length unit code: 2 for meters\n",
    "    crs=gdf.crs.to_string() # Automatically get CRS from geopandas\n",
    ")\n",
    "\n",
    "# Plot the modelgrid to verify\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "im = pmv.plot_array(modelgrid.botm, vmin=np.nanmin(modelgrid.botm), \n",
    "                    vmax=np.nanmax(modelgrid.botm), cmap='terrain')\n",
    "plt.colorbar(im, shrink=0.7, label=\"Bottom Elevation (m a.s.l.)\")\n",
    "pmv.plot_grid()\n",
    "# Overlay the buffered model boundary with proper legend handling\n",
    "boundary_patch = gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "# Create custom legend handle to avoid warnings\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Buffered Model Boundary')\n",
    "ax.legend(handles=[red_line])\n",
    "\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.set_title(\"Figure 11: Final Model Grid with Bottom Elevation.\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b5021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882449c0",
   "metadata": {},
   "source": [
    "#### 2.4 Write the model geometry to DIS package\n",
    "Finally we save the model grid to the DIS package of our model. Please note that when defining the DIS package, we can also pass the temporal discretization parameters directly to the DIS package constructor (see code snippet below). We will start out with a steady state simulation, so we only need one stress period. If you have transient data, you would define multiple stress periods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ffabad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal discretization\n",
    "# We start out with a steady state simulation, so we only need one stress period.\n",
    "# If you have transient data, you would define multiple stress periods.\n",
    "# Here, we define a single stress period with a length of 1 day.\n",
    "# Please note that we hereby implicitly define the time unit of our model to be \n",
    "# days. We will need to be consistent with this throughout the model setup. \n",
    "nper = 1  # Number of stress periods\n",
    "perlen = [1.0]  # Length of each stress period in days\n",
    "nstp = [1.0]  # Number of time steps in each stress period (defaults to 1 for steady state) \n",
    "tsmult = [1.0]  # Time step multiplier (only used in transient simulations)\n",
    "steady = [True]  # Steady state flag for each stress period\n",
    "\n",
    "# Explicitly pass the grid parameters to the DIS package constructor.\n",
    "# This will correctly set the nrow, ncol, etc. on the mf object.\n",
    "# Note that, unfortunately, grid rotation is handled differently in the DIS package\n",
    "# than in the StructuredGrid object. In the DIS package, the rotation angle is\n",
    "# defined as counterclockwise from the x-axis, whereas in the StructuredGrid\n",
    "# object, it is defined as clockwise from the y-axis. Therefore, we need to\n",
    "# adjust the angle accordingly.\n",
    "# The point around which the grid is rotated is defined by xul and yul,\n",
    "# which are the coordinates of the upper-left corner of the grid.\n",
    "dis = flopy.modflow.ModflowDis(\n",
    "    mf,\n",
    "    nlay=nlay,\n",
    "    nrow=nrow_rotated,\n",
    "    ncol=ncol_rotated,\n",
    "    delr=delr_rotated,\n",
    "    delc=delc_rotated,\n",
    "    top=model_top,\n",
    "    botm=model_bottom,\n",
    "    xul=xmin_original,\n",
    "    yul=ymax_original,\n",
    "    angrot=grid_rotation_angle,  #  in degrees, counterclockwise from the x-axis\n",
    "    lenuni=2,\n",
    "    crs=gdf.crs.to_string(),  # Automatically get CRS from geopackage\n",
    "    nper=nper,\n",
    "    perlen=perlen,\n",
    "    nstp=nstp,\n",
    "    tsmult=tsmult,\n",
    "    steady=steady\n",
    ")\n",
    "\n",
    "# Plot the dis package to verify\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)  # Use modelgrid for rotation\n",
    "im = pmv.plot_array(mf.modelgrid.top, alpha=0.5, cmap='terrain')  # Visualize top defined in DIS package\n",
    "plt.colorbar(im, shrink=0.7, label=\"Elevation (m a.s.l.)\")\n",
    "pmv.plot_grid()\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Model Boundary')\n",
    "ax.legend(handles=[red_line], loc='upper right')\n",
    "ax.set_title(\"Figure 12: Model grid with top elevation and model boundary (red).\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "plt.show()\n",
    "\n",
    "# Save the model grid to a file for later use\n",
    "grid_file_path = os.path.join(workspace, 'model_grid.pkl')\n",
    "with open(grid_file_path, 'wb') as f:\n",
    "    pickle.dump(modelgrid, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf384efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbba56d4",
   "metadata": {},
   "source": [
    "## 3 Parameterization\n",
    "The discretized groundwater flow equation contains several parameters that need to be defined for the model. We will simplify the zonation described by Doppler and colleagues [\\[1\\]](#References). For this, we have defined zones of equal hydraulic conductivities in QGIS (See Figure 12). The paramter field is then saved to our model using the layer-property flow package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(\n",
    "    image_filename='parameters_zonation.png', \n",
    "    image_folder='4_model_implementation',\n",
    "    caption=\"Figure 12: Left: Zonation of hydraulic conductivities by Doppler and colleagues (roman numbers I to VI). Right: Simplified zonation of hydraulic conductivities in 2 zones (green, downstream & yellow, upstream) in the present study.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061032c3",
   "metadata": {},
   "source": [
    "### 3.1 Layer-Property Flow (LPF) Package\n",
    "\n",
    "The Layer-Property Flow (LPF) Package is where we specify the hydraulic properties of the aquifer. These properties determine how easily water moves through the subsurface and how the aquifer stores and releases water.\n",
    "\n",
    "- **Hydraulic Conductivity (K)**: Since we don’t have site-specific measurements, we will begin with a uniform value of 10 m/d, which is typical for gravel aquifers (see Notebook 2). Later, during model calibration, we may divide the model into zones with different values of K to better represent aquifer heterogeneity.  \n",
    "- **Storage Properties**: For this first version of the model, we assume uniform values:\n",
    "    - Specific storage (Ss): $1 \\times 10^{-4} \\, \\text{m}^{-1}$ (represents elastic storage, important in confined conditions).  \n",
    "    - Specific yield (Sy): 0.15 (represents drainable porosity, dominant in unconfined conditions).  \n",
    "- **Hydraulic Conductivity Field**: With these settings, the model currently uses a single uniform conductivity field (Figure 13).  \n",
    "- **Wetting Parameters**: The LPF package also contains options for wetting parameters, which control how model cells that become dry can re-wet during transient simulations. For simple steady-state or basic transient models these are not strictly necessary, but they become important in more advanced models that include significant water table fluctuations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cd299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from flopy.utils.gridintersect import GridIntersect\n",
    "\n",
    "# Assign hydraulic conductivity (hk) from polygon zones to a MODFLOW-2005 StructuredGrid (LPF)\n",
    "# - Uses parameter_zones polygons\n",
    "# - Applies uniform hk per zone across all layers\n",
    "# - Does NOT modify ibound\n",
    "\n",
    "# Define parameters\n",
    "# Typical for sandy gravel aquifers in Swiss valleys\n",
    "hk_zone1 = 25.0  # m/day - horizontal hydraulic conductivity\n",
    "hk_zone2 = 25.0   # m/day - horizontal hydraulic conductivity\n",
    "vk_multiplyer = 0.1   # - - vertical hydraulic conductivity (typically Kh/10)\n",
    "\n",
    "# Storage properties (uniform)\n",
    "sy = 0.15  # Specific yield (typical for unconfined sandy gravel aquifers)\n",
    "ss = 1e-4  # Specific storage (1/m) (typical value)\n",
    "\n",
    "# Layer type (0 = confined, 1 = convertible/unconfined)\n",
    "# Limmat valley aquifer is unconfined\n",
    "laytyp = 1\n",
    "\n",
    "# 1. Load zones\n",
    "zones_file = download_named_file('parameter_zones', data_type='limmat_valley_model')\n",
    "zones = gpd.read_file(zones_file)\n",
    "if zones.empty:\n",
    "    raise ValueError(\"parameter_zones dataset contains no features.\")\n",
    "\n",
    "# 2. Ensure a zone identifier column\n",
    "zone_col = None\n",
    "for c in zones.columns:\n",
    "    if c.lower() in {\"zone\", \"zones\", \"zone_id\", \"id\"}:\n",
    "        zone_col = c\n",
    "        break\n",
    "if zone_col is None:\n",
    "    zones = zones.copy()\n",
    "    zone_col = \"zone\"\n",
    "    zones[zone_col] = np.arange(1, len(zones) + 1)\n",
    "\n",
    "# 3. Zone → hk mapping (m/day). Adjust as needed.\n",
    "hk_map = {\n",
    "    1: hk_zone1,\n",
    "    2: hk_zone2,\n",
    "}\n",
    "background_hk = 0.0  # hk for cells not covered by specified zones\n",
    "\n",
    "# 4. Prepare hk array\n",
    "nlay, nrow, ncol = mf.dis.nlay, mf.dis.nrow, mf.dis.ncol\n",
    "hk_array = np.full((nlay, nrow, ncol), background_hk, dtype=float)\n",
    "\n",
    "# 5. Intersection helper\n",
    "grid = modelgrid  # Use the rotated modelgrid for consistency with polygons \n",
    "gx = GridIntersect(grid, method=\"vertex\")\n",
    "\n",
    "# 6. Assign hk values\n",
    "touched = set()\n",
    "for _, r in zones.iterrows():\n",
    "    geom = r.geometry\n",
    "    if geom is None or geom.is_empty:\n",
    "        continue\n",
    "    zid = r[zone_col]\n",
    "    if zid not in hk_map:\n",
    "        continue\n",
    "    res = gx.intersect(geom)\n",
    "    if len(res) == 0:\n",
    "        continue\n",
    "    for (i, j) in res[\"cellids\"]:\n",
    "        hk_array[:, i, j] = hk_map[zid]\n",
    "        touched.add((i, j))\n",
    "\n",
    "# 7. Attach/update LPF\n",
    "lpf = flopy.modflow.ModflowLpf(\n",
    "    mf, \n",
    "    hk=hk_array, \n",
    "    vka=hk_array*vk_multiplyer, \n",
    "    sy=sy, \n",
    "    ss=ss, \n",
    "    laytyp=laytyp,          # Layer type (1 = convertible/unconfined)\n",
    "    ipakcb=53,              # Unit number for cell-by-cell budget file\n",
    "    hdry=-999.99,           # Head assigned to dry cells\n",
    "    wetfct=0.2,             # Wetting factor\n",
    "    iwetit=2,               # Wetting iteration interval (outer iteration)\n",
    "    laywet=1,               # Flag indicating if wetting is active for each layer\n",
    "    wetdry=0.01             # Threshold for wetting (fraction of cell thickness)\n",
    ")\n",
    "\n",
    "# 8. Summary\n",
    "print(\"hk assignment complete\")\n",
    "print(f\"hk shape: {hk_array.shape}\")\n",
    "print(f\"Zones column: {zone_col}\")\n",
    "print(f\"Horizontal cells touched: {len(touched)} ({len(touched)/(nrow*ncol)*100:.1f}%)\")\n",
    "print(\"Zone → hk mapping:\")\n",
    "for k, v in hk_map.items():\n",
    "    print(f\"  {k}: {v} m/day\")\n",
    "print(f\"Background hk: {background_hk} m/day\")\n",
    "\n",
    "# Test that all hk values are reasonable\n",
    "hk_full = np.array(mf.lpf.hk.array)  # ensure concrete ndarray\n",
    "print(\"hk_full shape:\", hk_full.shape)\n",
    "print(\"Layer0 min/max/unique count:\",\n",
    "      float(np.nanmin(hk_full[0])), float(np.nanmax(hk_full[0])),\n",
    "      len(np.unique(hk_full[0])))\n",
    "\n",
    "nz = np.count_nonzero(hk_full[0])\n",
    "print(\"Non‑zero cells layer 0:\", nz)\n",
    "if nz == 0:\n",
    "    raise ValueError(\"All hk values are zero in layer 0.\")\n",
    "\n",
    "# 9. Optional quick plot (layer 1)\n",
    "# We're masking out zero values for better visualization.\n",
    "layer0 = mf.lpf.hk.array[0].astype(float)\n",
    "masked = np.ma.masked_equal(layer0, 0.0)\n",
    "\n",
    "cmap = plt.cm.viridis.copy()\n",
    "cmap.set_bad(alpha=0)   # masked -> transparent\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "im = pmv.plot_array(masked)\n",
    "pmv.plot_grid(alpha=0.25, linewidth=0.3)\n",
    "plt.colorbar(im, ax=ax, shrink=0.75, label=\"hk (m/day)\")\n",
    "ax.set_title(\"Hydraulic Conductivity (Layer 1)\")\n",
    "ax.set_aspect(\"equal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd8edfd",
   "metadata": {},
   "source": [
    "### 3.2 A note on assigning Parameter Fields\n",
    "A good first step is to assign uniform parameter values (e.g., a single hydraulic conductivity and storage value for the entire model domain) to keep the system simple and transparent. In reality, aquifer properties are heterogeneous, but beginning with uniform fields helps isolate structural issues before adding complexity. The modeler can then progressively introduce spatial variability and adjust parameter values to improve water balance closure and calibration performance. This staged approach reduces ambiguity and supports defensible model development. The following list shows you increasingly sophisticated methodologies to refine parameter fields: \n",
    " \n",
    "- Zonation – divide the model into regions (zones) where each zone has its own parameter value (e.g., sand vs. clay areas).\n",
    "\n",
    "- Interpolation (e.g., kriging, IDW) – use point measurements (e.g., from wells) to interpolate continuous parameter fields across the model grid.\n",
    "\n",
    "- Geostatistical/simulation methods – generate stochastic parameter fields that honor both measurements and spatial variability.\n",
    "\n",
    "- Pilot points / parameter estimation – assign parameters at selected control points and let calibration tools adjust them to fit observed data.\n",
    "\n",
    "👉 The choice depends on data availability, model purpose, and computational cost. For teaching, we start simple with uniform values, and later explore how to refine parameter distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c473974",
   "metadata": {},
   "source": [
    "**Example for uniform hydraulic conductivity setup (not executed here):**\n",
    "In your first iteration of the model implementation, if you don't \n",
    "have detailed zonation data, you can start with uniform hydraulic conductivity \n",
    "values across the entire model domain. This can help you get the model up and \n",
    "running quickly, allowing you to focus on other aspects of the model setup\n",
    "and calibration. Once you have a working model, you can then refine the\n",
    "hydraulic conductivity distribution based on more detailed data or zonation\n",
    "information as it becomes available.\n",
    "\n",
    "```python\n",
    "# Uniform hydraulic conductivity values\n",
    "# Typical for sandy gravel aquifers in Swiss valleys\n",
    "hk_uniform = 10.0  # m/day - horizontal hydraulic conductivity\n",
    "vk_uniform = 1.0   # m/day - vertical hydraulic conductivity (typically Kh/10)\n",
    " \n",
    "# Create uniform K arrays\n",
    "hk = np.ones((nlay, nrow_rotated, ncol_rotated)) * hk_uniform\n",
    "vk = np.ones((nlay, nrow_rotated, ncol_rotated)) * vk_uniform\n",
    "\n",
    "# Storage properties (uniform)\n",
    "sy = 0.15  # Specific yield (typical for unconfined sandy gravel aquifers)\n",
    "ss = 1e-4  # Specific storage (1/m) (typical value)\n",
    "\n",
    "# Layer type (0 = confined, 1 = convertible/unconfined)\n",
    "# Limmat valley aquifer is unconfined\n",
    "laytyp = 1\n",
    "\n",
    "# Create the LPF package\n",
    "lpf = flopy.modflow.ModflowLpf(\n",
    "    mf,\n",
    "    hk=hk,                  # Horizontal hydraulic conductivity\n",
    "    vka=vk,                 # Vertical hydraulic conductivity\n",
    "    sy=sy,                  # Specific yield\n",
    "    ss=ss,                  # Specific storage\n",
    "    laytyp=laytyp,          # Layer type (1 = convertible/unconfined)\n",
    "    ipakcb=53,              # Unit number for cell-by-cell budget file\n",
    "    hdry=-999.99,           # Head assigned to dry cells\n",
    "    wetfct=0.2,             # Wetting factor\n",
    "    iwetit=2,               # Wetting iteration interval (outer iteration)\n",
    "    laywet=1,                # Flag indicating if wetting is active for each layer\n",
    "    wetdry=0.01              # Threshold for wetting (fraction of cell thickness)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b0eda",
   "metadata": {},
   "source": [
    "## 4 Boundary & Initial Conditions\n",
    "Now that we have the model geometry and parameterization defined, we need to establish the boundary and initial conditions for the simulation. These correspond to the arrows in the perceptual model figure we discussed in Notebook 2, describing fluxes in and out of the model. \n",
    "\n",
    "### 4.1 Active Cells - Basic Package (BAS) \n",
    "\n",
    "The BAS package has the following responsibilities: \n",
    "- *Initial heads*: Starting conditions for the solver.\n",
    "- *IBOUND array*: Defines the active/inactive status of each cell.\n",
    "    - IBOUND > 0: Active cell\n",
    "    - IBOUND = 0: Inactive cell\n",
    "    - IBOUND < 0: Fixed-head cell\n",
    "\n",
    "We'll assume all cells within the aquifer boundary are active and that the initial head lies at 1 meter below the ground surface. \n",
    "\n",
    "Please follow the steps in the code cell below to create the Basic Package.\n",
    "\n",
    "#### 4.1.1 Identify Active Cells\n",
    "Modflow only solves the flow equation for active cells (IBOUND > 0). We need to create the IBOUND array based on the active cells identified in the model grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f566322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Data processing ---\n",
    "# Goal: Create IBOUND array to define active/inactive cells\n",
    "# Note: Active cells (1) are inside the model boundary, inactive cells (0) are \n",
    "# outside\n",
    "# Steps: \n",
    "# 1. Create an empty IBOUND array with all cells inactive (0)\n",
    "# 2. Use the original model boundary (not buffered) for IBOUND\n",
    "# 3. Assign active cells (1) based on the intersection with the boundary\n",
    "\n",
    "# Initialize IBOUND array with all cells inactive (0)\n",
    "ibound = np.zeros((nlay, nrow_rotated, ncol_rotated), dtype=int)\n",
    "\n",
    "# Using GridIntersect (recommended for complex boundaries and rotated grids)\n",
    "# Create a GridIntersect object\n",
    "ix = GridIntersect(modelgrid, method='vertex', rtree=True)\n",
    "\n",
    "# Get the intersection between the grid and the boundary polygon\n",
    "# This returns the cells that intersect with the polygon\n",
    "try:\n",
    "    result = ix.intersect(gdf.geometry.union_all())\n",
    "    \n",
    "    # Extract the row and column indices of cells inside the boundary\n",
    "    for idx, row in result.iterrows():\n",
    "        ibound[0, row['row'], row['col']] = 1\n",
    "        \n",
    "    print(\"Successfully created IBOUND using GridIntersect method\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"GridIntersect method failed: {e}\")\n",
    "    print(\"Falling back to cell center method...\")\n",
    "    \n",
    "    # Fallback Method: Using cell centers\n",
    "    # Get cell centers\n",
    "    xcenters = modelgrid.xcellcenters\n",
    "    ycenters = modelgrid.ycellcenters\n",
    "    \n",
    "    # Get the boundary polygon\n",
    "    boundary_polygon = gdf.geometry.union_all()\n",
    "    \n",
    "    # Check which cell centers are inside the boundary polygon\n",
    "    for i in range(nrow_rotated):\n",
    "        for j in range(ncol_rotated):\n",
    "            point = Point(xcenters[i, j], ycenters[i, j])\n",
    "            if boundary_polygon.contains(point):\n",
    "                ibound[0, i, j] = 1\n",
    "\n",
    "# Count active and inactive cells\n",
    "active_cells = np.sum(ibound == 1)\n",
    "inactive_cells = np.sum(ibound == 0)\n",
    "print(f\"\\nInitial IBOUND statistics:\")\n",
    "print(f\"Active cells: {active_cells}\")\n",
    "print(f\"Inactive cells: {inactive_cells}\")\n",
    "print(f\"Total cells: {active_cells + inactive_cells}\")\n",
    "print(f\"Percentage active: {active_cells / (active_cells + inactive_cells) * 100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bcbc0a",
   "metadata": {},
   "source": [
    "#### 4.1.2 Visualize IBOUND Array\n",
    "We visually check if the IBOUND array correctly represents the model domain by overlaying it on the aquifer thickness map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Visualization of IBOUND ---\n",
    "# Plot IBOUND array with custom colormap\n",
    "# Define discrete colormap: order must match categories [-1, 0, 1]\n",
    "# Colors: CHD = orange, Inactive = white, Active = blue\n",
    "cmap = mcolors.ListedColormap([\n",
    "    \"#1f77b4\",  # -1 CHD\n",
    "    \"#111111\",  # 0 inactive\n",
    "    \"#ffffff\"   # 1 active\n",
    "])\n",
    "# Boundaries define bins for the 3 categories\n",
    "bounds = [-1.5, -0.5, 0.5, 1.5]\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "im = pmv.plot_array(ibound[0], cmap=cmap, norm=norm)\n",
    "\n",
    "pmv.plot_grid(alpha=0.3, linewidth=0.5)\n",
    "\n",
    "# Overlay the original boundary for verification\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=1)\n",
    "\n",
    "# Colorbar with custom ticks & labels\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.7, ticks=[-1, 0, 1])\n",
    "cbar.ax.set_yticklabels([\"CHD (-1) (yet to be defined)\", \"Inactive (0)\", \"Active (1)\"])\n",
    "cbar.set_label(\"IBOUND code\")\n",
    "\n",
    "ax.set_title(f\"Figure 12: IBOUND array displaying active (white) and inactive (black) cells.\")\n",
    "ax.set_xlabel(\"X-coordinate (m)\")\n",
    "ax.set_ylabel(\"Y-coordinate (m)\")\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Create custom legend handles to avoid warnings\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Model Boundary')\n",
    "ax.legend(handles=[red_line])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5c762",
   "metadata": {},
   "source": [
    "We will now save the preliminary IBOUND array as geopackage so we can later conveniently select cells with specific properties (e.g. constant head cells) in QGIS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55cdaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the ibound array to a file for later use\n",
    "ibound_file_path = os.path.join(workspace, 'ibound.npy')\n",
    "np.save(ibound_file_path, ibound)\n",
    "\n",
    "# Save the ibound array to a GeoDataFrame for visualization\n",
    "ibound_cells = []\n",
    "for i in range(nrow_rotated):\n",
    "    for j in range(ncol_rotated):\n",
    "        cell_polygon = modelgrid.get_cell_vertices(i, j)\n",
    "        ibound_cells.append({\n",
    "            'row': i,\n",
    "            'col': j,\n",
    "            'cell_id': f\"{i}_{j}\",\n",
    "            'geometry': Polygon(cell_polygon),\n",
    "            'ibound': int(ibound[0, i, j]),\n",
    "            'x': modelgrid.xcellcenters[i, j],\n",
    "            'y': modelgrid.ycellcenters[i, j]\n",
    "        })  \n",
    "# Create GeoDataFrame\n",
    "ibound_gdf = gpd.GeoDataFrame(ibound_cells, crs=modelgrid.crs)  \n",
    "# Export to GeoPackage\n",
    "ibound_geopackage_path = os.path.join(workspace, 'ibound.gpkg')\n",
    "ibound_gdf.to_file(ibound_geopackage_path, driver='GPKG', layer='ibound')\n",
    "\n",
    "print(f\"IBOUND array exported to: {ibound_geopackage_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97eae08",
   "metadata": {},
   "source": [
    "#### 4.1.5 Identify Constant Head Cells\n",
    "Oh, but we are not done yet! In MODFLOW, we have to assign IBOUND=-1 to the outflow cells along the western boundary.\n",
    "\n",
    "The most straight forward way to select the cells with constant head is to load the IBOUND shape in QGIS and select the cells along the western boundary. See printscreen of QGIS in Figure 14. The selected features can then be exported as a shapefile and loaded into the notebook. The code below shows how to create the constant head boundary condition based on the selected cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(\n",
    "    image_filename='selection_of_cells_for_chd_boundary_qgis.png', \n",
    "    image_folder='4_model_implementation',\n",
    "    caption='Figure 14: Active cells of IBOUND layer in semi-transparent red. Background layer: OpenStreetMap. The orange cells indicate the selection of cells for the constant head boundary condition (CHD).'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab2395a",
   "metadata": {},
   "source": [
    "#### 4.1.4 Add Constant Head Cells to IBOUND and write to BAS Package\n",
    "Then, we load the cell selection to define the IBOUND cells we have to set to -1 (and visually check if the IBOUND cells are correctly identified, Figure 15). For these same cells, we later assign a constant head boundary condition with the CHD package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cell selection for the constant head boundary. \n",
    "chd_cells_path = download_named_file(\n",
    "    name='chd_cells', \n",
    "    data_type='limmat_valley_model'\n",
    ")\n",
    "\n",
    "# Load CHD selection layer (assumes it only contains desired CHD cells)\n",
    "chd_sel = gpd.read_file(chd_cells_path)\n",
    "chd_sel = chd_sel.to_crs(modelgrid.crs)\n",
    "\n",
    "# Get ibound array to dataframe format\n",
    "# Create GeoDataFrame\n",
    "ibound_cells = []\n",
    "for i in range(nrow_rotated):\n",
    "    for j in range(ncol_rotated):\n",
    "        cell_polygon = modelgrid.get_cell_vertices(i, j)\n",
    "        ibound_cells.append({\n",
    "            'row': i,\n",
    "            'col': j,\n",
    "            'cell_id': f\"{i}_{j}\",\n",
    "            'geometry': Polygon(cell_polygon),\n",
    "            'ibound': int(ibound[0, i, j]),\n",
    "            'x': modelgrid.xcellcenters[i, j],\n",
    "            'y': modelgrid.ycellcenters[i, j]\n",
    "        })  \n",
    "ibound_gdf = gpd.GeoDataFrame(ibound_cells, crs=modelgrid.crs)  \n",
    "\n",
    "# Ensure required columns\n",
    "required_cols = {'cell_id', 'row', 'col'}\n",
    "missing = required_cols - set(ibound_gdf.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"ibound_gdf is missing required columns: {missing}\")\n",
    "\n",
    "if 'cell_id' not in chd_sel.columns:\n",
    "    raise ValueError(\"CHD selection layer lacks 'cell_id'. Add it (e.g., from IBOUND export) and retry.\")\n",
    "\n",
    "# Normalize cell_id\n",
    "chd_sel['cell_id'] = chd_sel['cell_id'].astype(str).str.strip()\n",
    "ibound_gdf['cell_id'] = ibound_gdf['cell_id'].astype(str).str.strip()\n",
    "\n",
    "# Join on cell_id\n",
    "chd_join = chd_sel.merge(\n",
    "    ibound_gdf[['cell_id']],\n",
    "    on='cell_id',\n",
    "    how='inner',\n",
    "    validate='1:1'\n",
    ")\n",
    "\n",
    "if chd_join.empty:\n",
    "    raise ValueError(\"No matching cell_id between CHD layer and ibound_gdf.\")\n",
    "\n",
    "# Vector filter to active cells\n",
    "rows = chd_join['row'].astype(int).to_numpy()\n",
    "cols = chd_join['col'].astype(int).to_numpy()\n",
    "active_mask = ibound[0, rows, cols] == 1\n",
    "chd_active = chd_join.loc[active_mask].drop_duplicates(subset=['row', 'col'])\n",
    "\n",
    "if chd_active.empty:\n",
    "    raise ValueError(\"Selected CHD cells are not active (ibound==1).\")\n",
    "\n",
    "# Assign constant head value\n",
    "const_head_value = 390.0\n",
    "\n",
    "# Set ibound to -1 for CHD cells\n",
    "for r, c in zip(chd_active['row'].astype(int), chd_active['col'].astype(int)):\n",
    "    ibound[0, r, c] = -1\n",
    "\n",
    "# Update BAS package with modified ibound (recreate to be safe)\n",
    "bas = flopy.modflow.ModflowBas(\n",
    "    mf,\n",
    "    ibound=ibound,\n",
    "    strt=gw_elevations,  # Initial head from interpolated groundwater elevations\n",
    "    hnoflo=-999.99\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2454e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ibound to see if constant head cells are correctly identified\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mf.modelgrid, ax=ax)\n",
    "pmv.plot_ibound()\n",
    "ax.set_title(f\"Figure 15: IBOUND array displaying active (white) and inactive (black) cells, and constant head cells (blue).\")\n",
    "ax.set_xlabel(\"X-coordinate (m)\")\n",
    "ax.set_ylabel(\"Y-coordinate (m)\")\n",
    "ax.set_aspect('equal', adjustable='box')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3a4da",
   "metadata": {},
   "source": [
    "#### 4.1.5 Export IBOUND Array\n",
    "Finally, we export the IBOUND array to a binary file (as a backup) and to a geopackage so we can later use it in GIS applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18f3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Export IBOUND array ---\n",
    "# Save the ibound array to a file for later use\n",
    "ibound_file_path = os.path.join(workspace, 'ibound.npy')\n",
    "np.save(ibound_file_path, ibound)\n",
    "\n",
    "# Save the ibound array to a GeoDataFrame for visualization\n",
    "ibound_cells = []\n",
    "for i in range(nrow_rotated):\n",
    "    for j in range(ncol_rotated):\n",
    "        cell_polygon = modelgrid.get_cell_vertices(i, j)\n",
    "        ibound_cells.append({\n",
    "            'row': i,\n",
    "            'col': j,\n",
    "            'cell_id': f\"{i}_{j}\",\n",
    "            'geometry': Polygon(cell_polygon),\n",
    "            'ibound': int(ibound[0, i, j]),\n",
    "            'x': modelgrid.xcellcenters[i, j],\n",
    "            'y': modelgrid.ycellcenters[i, j]\n",
    "        })  \n",
    "# Create GeoDataFrame\n",
    "ibound_gdf = gpd.GeoDataFrame(ibound_cells, crs=modelgrid.crs)  \n",
    "# Export to GeoPackage\n",
    "ibound_geopackage_path = os.path.join(workspace, 'ibound.gpkg')\n",
    "ibound_gdf.to_file(ibound_geopackage_path, driver='GPKG', layer='ibound')\n",
    "\n",
    "print(f\"IBOUND array exported to: {ibound_geopackage_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1442a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb7e7d",
   "metadata": {},
   "source": [
    "### 4.2 Lateral outflow - Constant head (CHD) Package \n",
    "The Constant Head (CHD) Package is used to fix hydraulic head values at selected cells in the model. These cells act as boundaries where groundwater can freely flow in or out, depending on the head gradient between the fixed boundary and the interior of the model.\n",
    "\n",
    "**How it works**:\n",
    "- The model keeps the specified head constant during the simulation.\n",
    "- Water can leave (outflow) or enter (inflow) the model through these cells.\n",
    "- The amount of flow is calculated by MODFLOW based on the head difference with neighboring cells and the conductance between them.\n",
    "\n",
    "**Why we use it here**:\n",
    "In our model, we apply a CHD boundary at the outflow of the aquifer. This ensures that groundwater can discharge naturally from the system while keeping the downstream head fixed at a realistic value.\n",
    "\n",
    "👉 In practice: the CHD boundary represents a “hydraulic sink or source” that keeps the system open and allows water to move across the model boundary in a controlled way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21123ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CHD stress period data\n",
    "# Create list of constant head cells in the format required by FloPy\n",
    "chd_cells = [\n",
    "    [0, int(r), int(c), const_head_value, const_head_value]\n",
    "    for r, c in zip(chd_active['row'], chd_active['col'])\n",
    "]\n",
    "\n",
    "print(f\"Number of CHD cells (from selection layer): {len(chd_cells)}\")\n",
    "\n",
    "# Build stress period data for constant head\n",
    "chd = flopy.modflow.ModflowChd(\n",
    "    mf,\n",
    "    stress_period_data={0: chd_cells},\n",
    ")\n",
    "\n",
    "print(\"\\nConstant head boundary package created with constant heads:\")\n",
    "print(f\"Constant head value: {const_head_value} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196aadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-D visualization of model top, bottom, and CHD boundary heads (active domain only)\n",
    "fig = plot_interactive_model_domain_3d(\n",
    "    mf, bas=bas, chd=chd, engine=\"plotly\", exaggeration=20.0, \n",
    "    custom_title=\"Figure 15: 3D Model Domain Visualization.\"\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250fcb11",
   "metadata": {},
   "source": [
    "The model geometry is now consistent with the CHD boundary. We move on to the next boundary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d7865",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(4, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c27f72",
   "metadata": {},
   "source": [
    "### 4.3 Net Areal Recharge (RCH Package)\n",
    "\n",
    "Next, we tackle the **recharge from the top**: In the perceptual model chapter, we found that about 110 mm/year of net recharge is expected in the Limmat Valley. We will implement this as a uniform recharge across the model area. We defined the stress period length as 1 day, so we need to convert the annual recharge rate to a daily recharge rate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16094b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average net recharge value for the Limmat valley: 110 mm/year\n",
    "rech_value = 0.110 / 365.25  # m/day\n",
    "rech_array = np.full((nrow_rotated, ncol_rotated), rech_value, dtype=float)\n",
    "\n",
    "rch = flopy.modflow.ModflowRch(\n",
    "    mf, \n",
    "    rech=rech_array, \n",
    "    nrchop=3  # apply recharge to highest active cell in column\n",
    ")\n",
    "\n",
    "print(\"\\nAreal recharge package created with constant rate:\")\n",
    "print(f\"Recharge value: {rech_value:.6f} m/day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c6ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49da04a9",
   "metadata": {},
   "source": [
    "### 4.4 River Interaction (RIV Package)\n",
    "\n",
    "Now we implement the river. We go for the RIV Package which is used to represent several conditions of loosing and gaining, connected and disconnected streams that are often present in shallow river-valley aquifers.\n",
    "\n",
    "First, we get the river layer by the Canton of Zurich. we only keep the river layers in the model domain. We further discard the smaller rivers because we do not have any information about them and we assume that they are not contributing significantly to the groundwater flow in the Limmat Valley (see Figure 17). \n",
    "\n",
    "We'll further have to estimate a bottom elevation of the river as river profiles are not publicly available. We will linearly interpolate the river bottom elevation based an assumed average river depth for each river. \n",
    "\n",
    "Please note that in a paid project, you would optimally get access to more detailed river profile data. River profile data is available for the river stretches which are relevant for flood management. As a modeler, you will have to remember to ask your client for this data. However, in many parts of the world, river profile data is not available and you will have to make many assumptions about the river-aquifer interaction.   \n",
    "\n",
    "> **Implementing Surface-Water–Groundwater Interaction in MODFLOW**\n",
    "> \n",
    "> MODFLOW offers several ways to represent exchanges between rivers and aquifers. The choice depends on model goals, data availability, and desired level of detail:\n",
    ">\n",
    "> **Coarse**:  \n",
    "> - *Constant Head (CHD)*: fixes head along a river reach → simple representation of boundary influence, but no feedback with aquifer conditions.\n",
    ">\n",
    "> **Intermediate**:\n",
    ">\n",
    "> - *Drain (DRN)*: removes water when groundwater is above river stage → simulates discharge but not recharge.\n",
    ">\n",
    "> - *River (RIV)*: allows two-way exchange based on stage, aquifer head, and riverbed conductance → widely used for river–aquifer interaction.\n",
    ">\n",
    "> **Detailed**:\n",
    ">\n",
    "> - *Streamflow Routing (SFR/SFR2)*: represents channel network, flow routing, stream gains/losses, and interactions with aquifer.\n",
    ">\n",
    "> - *Lake (LAK)*: simulates dynamic lake–aquifer exchange with surface water balance.\n",
    ">\n",
    "> Unsaturated Zone Flow (UZF): can simulate seepage from rivers or canals through the vadose zone to groundwater.\n",
    ">\n",
    "> 👉 In practice, many studies start with the RIV package and move toward SFR or LAK if surface water dynamics are important.\n",
    "\n",
    "The following steps guide you through the rather complex process of implementing the RIV package in your MODFLOW model. But don't worry, we will break it down into manageable tasks.\n",
    "\n",
    "1. Define the river geometry: This includes the river centerline, width, and depth. You can use GIS data to extract this information or make reasonable assumptions based on similar rivers in the region.\n",
    "\n",
    "2. Assign riverbed elevations: Since we don't have detailed river profile data, we will need to make assumptions about the riverbed elevations. One approach is to use a digital elevation model (DEM) to estimate the riverbed elevation at each river cross-section.\n",
    "\n",
    "3. Specify river hydraulic properties: This includes the riverbed hydraulic conductivity and the river stage. The hydraulic conductivity can be estimated based on soil and sediment characteristics, while the river stage can be derived from observed water levels or assumed based on regional data.\n",
    "\n",
    "4. Implement the RIV package in MODFLOW: This involves defining the river cells in the model grid, specifying the river geometry and hydraulic properties, and setting up the necessary input files for MODFLOW.\n",
    "\n",
    "5. Calibrate the model: Once the RIV package is implemented, you will need to calibrate the model to ensure that it accurately represents the river-aquifer interaction. This may involve adjusting the river hydraulic properties, refining the river geometry, or incorporating additional data.\n",
    "\n",
    "6. Validate the model: Finally, you should validate the model by comparing the simulated river stages and flows with observed data. This will help ensure that the model is reliable and can be used for decision-making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b2629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the river shapes and to the boundary outline\n",
    "river_data_path = download_named_file(name='rivers', data_type='gis')\n",
    "boundary_path = download_named_file(name='model_boundary', data_type='gis')\n",
    "\n",
    "# Intersect the river data with the model grid and only keep the parts that are \n",
    "# inside the model boundary. \n",
    "river_gdf = gpd.read_file(river_data_path)\n",
    "boundary_gdf = gpd.read_file(boundary_path)\n",
    "# Ensure both GeoDataFrames are in the same CRS\n",
    "river_gdf = river_gdf.to_crs(modelgrid.crs)\n",
    "boundary_gdf = boundary_gdf.to_crs(modelgrid.crs)\n",
    "# Clip the river data to the model boundary\n",
    "river_clipped = gpd.clip(river_gdf, boundary_gdf)\n",
    "\n",
    "# Print the column names of the clipped river data to understand its structure\n",
    "print(\"Clipped river data columns:\")\n",
    "print(river_clipped.columns)\n",
    "# Print the unique values in the 'GEWAESSERNAME' column to understand the river names\n",
    "print(\"\\nUnique river names in the clipped data:\")\n",
    "print(river_clipped['GEWAESSERNAME'].unique())\n",
    "\n",
    "# We are interested in the river sections belonging to the rivers Sihl and Limmat. \n",
    "river_clipped = river_clipped[\n",
    "    (river_clipped['GEWAESSERNAME'].isin(['Sihl', 'Limmat'])) \n",
    "].copy()\n",
    "\n",
    "# Plot the clipped river data to verify\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "river_clipped.plot(ax=ax, color='blue', linewidth=2, label='Clipped River Data')\n",
    "blue_polygon = mpatches.Patch(facecolor='blue', linewidth=2, label='Clipped River Data')\n",
    "boundary_gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Model Boundary')\n",
    "ax.set_title(\"Figure 17: Clipped river data within the model boundary. \")\n",
    "ax.set_xlabel(\"X-coordinate\")\n",
    "ax.set_ylabel(\"Y-coordinate\")\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.legend(handles=[blue_polygon, red_line])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33d5ded",
   "metadata": {},
   "source": [
    "Now let's check if the elevation of the gauges on the river are consistent with the DEM. If the DEM is coarse and the river is narrow, the DEM might not capture the river elevation correctly. In this case, we might have to revert to a higher-resolution DEM that captures the river elevation better. If a higher-resolution DEM is not available, we can will have to carefully review the river elevation and adjust it manually if necessary. This will, in turn, make a bias correction of the river stage measurements necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e162d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summarizing river data ...\")\n",
    "\n",
    "# Load gauge locations\n",
    "gauges_path = download_named_file(name='gauges', data_type='gis')\n",
    "gauges_gdf = gpd.read_file(gauges_path, layer=\"GS_LIMNIGRAPHENSTATIONEN_P\")\n",
    "gauges_gdf = gauges_gdf.to_crs(modelgrid.crs)\n",
    "\n",
    "# Keep only the gauges in the model area\n",
    "gauges_gdf = gauges_gdf[gauges_gdf.geometry.within(gdf.union_all())]\n",
    "\n",
    "# print(\"\\nGauge information:\")\n",
    "# print(gauges_gdf[['LABEL', 'NAME']].head())\n",
    "\n",
    "# We extracted the average river stage values from the gauges in \n",
    "# `2_perceptual_model.ipynb`. Let's use these values to check if the river stage\n",
    "# is reasonable. The average river stage values are: \n",
    "river_data_path = download_named_file(\n",
    "    name='river_data', \n",
    "    data_type='time_series', \n",
    ")\n",
    "# Only keep the path without the filename\n",
    "river_data_path = os.path.dirname(river_data_path)\n",
    "river_data_path = os.path.join(river_data_path, 'river_data_summary.npy')\n",
    "river_stage_summary = np.load(river_data_path, allow_pickle=True).item()\n",
    "# Print the river stage summary to understand the values\n",
    "# print(\"\\nRiver stage summary:\")\n",
    "# print(river_stage_summary)\n",
    "# The river stage summary is a nested dictionary with river names as keys and \n",
    "# with names of statistics as secondary key. We replace the river names with the \n",
    "# gauge labels to make it easier to match with the gauges.\n",
    "# Create a mapping from river labels to river names in the river stage summary\n",
    "label_to_river = {\n",
    "    'LH  2099': 'limmat', \n",
    "    'LH  2176': 'sihl',\n",
    "}\n",
    "# Add 'mean' for each gauge to the gauges_gdf using the correct mapping\n",
    "gauges_gdf['mean_stage_masl'] = gauges_gdf['LABEL'].map(\n",
    "    lambda x: river_stage_summary.get(label_to_river.get(x, ''), {}).get('mean', np.nan)\n",
    ")\n",
    "# Round mean river stage values to 2 decimal places\n",
    "gauges_gdf['mean_stage_masl'] = gauges_gdf['mean_stage_masl'].round(2)\n",
    "\n",
    "# Print the updated gauges_gdf to verify\n",
    "# print(\"\\nUpdated gauges_gdf with mean river stage:\")\n",
    "# print(gauges_gdf[['LABEL', 'NAME', 'mean_stage_masl']])\n",
    "\n",
    "# print(\"\\nExtracting model_top values at gauge locations...\")\n",
    "# Check if gauges_gdf and mf.modelgrid have the same CRS\n",
    "if gauges_gdf.crs != modelgrid.crs:\n",
    "    print(\"Warning: CRS mismatch between gauges_gdf and modelgrid. Reprojecting...\")\n",
    "    gauges_gdf = gauges_gdf.to_crs(modelgrid.crs)\n",
    "# Print coordinates of gauges and model grid extent for debugging\n",
    "# print(\"\\nGauge coordinates:\")\n",
    "# for idx, gauge in gauges_gdf.iterrows():\n",
    "#     print(f\"Gauge {gauge['LABEL']} at ({gauge.geometry.centroid.x:.2f}, {gauge.geometry.centroid.y:.2f})\")\n",
    "# print(\"\\nModel grid extent:\")\n",
    "# print(f\"X range: {modelgrid.xcellcenters.min():.2f} to {modelgrid.xcellcenters.max():.2f}\")\n",
    "# print(f\"Y range: {modelgrid.ycellcenters.min():.2f} to {modelgrid.ycellcenters.max():.2f}\")\n",
    "\n",
    "# Check if each gauge is within the model grid extent\n",
    "# print(\"\\nChecking if each gauge is within model grid extent:\")\n",
    "for idx, gauge in gauges_gdf.iterrows():\n",
    "    gauge_x = gauge.geometry.x\n",
    "    gauge_y = gauge.geometry.y\n",
    "    \n",
    "    xlim = (gauge_x > modelgrid.xcellcenters.min()) & (gauge_x < modelgrid.xcellcenters.max())\n",
    "    ylim = (gauge_y > modelgrid.ycellcenters.min()) & (gauge_y < modelgrid.ycellcenters.max())\n",
    "    \n",
    "    within_bounds = xlim and ylim\n",
    "    if not within_bounds:\n",
    "        print(f\"  WARNING: Gauge {gauge['LABEL']} is outside the model grid extent!\")\n",
    "\n",
    "# Create a GridIntersect object\n",
    "ix = GridIntersect(modelgrid, method='vertex')\n",
    "\n",
    "# Get model top values at gauge locations\n",
    "model_top_at_gauges = []\n",
    "gauge_cell_info = []\n",
    "\n",
    "(\"\\nUsing nearest neighbor approach for all gauges:\")\n",
    "for idx, gauge in gauges_gdf.iterrows():\n",
    "    gauge_x, gauge_y = gauge.geometry.x, gauge.geometry.y\n",
    "    \n",
    "    # Calculate distances to all cell centers\n",
    "    x_centers = modelgrid.xcellcenters\n",
    "    y_centers = modelgrid.ycellcenters\n",
    "    \n",
    "    distances = np.sqrt((x_centers - gauge_x)**2 + (y_centers - gauge_y)**2)\n",
    "    \n",
    "    # Find the cell with minimum distance\n",
    "    min_row, min_col = np.unravel_index(distances.argmin(), distances.shape)\n",
    "    min_distance = distances[min_row, min_col]\n",
    "    \n",
    "    # Check if this cell is active\n",
    "    is_active = ibound[0, min_row, min_col] == 1\n",
    "    \n",
    "    # Get the model top value at this cell\n",
    "    top_value = modelgrid.top[min_row, min_col]\n",
    "    \n",
    "    # Add this to the dataframe\n",
    "    gauges_gdf.loc[idx, 'model_top_masl'] = top_value\n",
    "\n",
    "print(\"\\nUpdated gauges_gdf with model top:\")\n",
    "print(gauges_gdf[['LABEL', 'NAME', 'mean_stage_masl', 'model_top_masl']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e546c0",
   "metadata": {},
   "source": [
    "We see that the gauge level of the river Sihl is above the model top. The average elevation of the water level in the river is 412.35 m a.s.l. whereas the elevation of the grid cell is at 410 m a.s.l. For the river Limmat, we're ok. \n",
    "\n",
    "When you look for data to implement a numerical model, you will often encounter inconsistent data. This is a common issue in hydrological modeling, where different data sources may provide conflicting information about river stages, groundwater levels, and topography. You will have to factor in extra time to reconcile these discrepancies and ensure that your model is based on the best available data. Try to consult several independent data sources whenever possible.  \n",
    "\n",
    "In the present case, we have several options:   \n",
    "- Resample the model top from a higher-resolution DEM (way to go if a higher-resolution DEM is availble)\n",
    "- Manually bias-correct the time series of the river water level in the river Sihl to be consistent with the model top (tedious but doable)\n",
    "- Manually increase the DEM in the south-east corner of the model (last resort)\n",
    "\n",
    "In the case of the Limmat valley aquifer, a higher resolution DEM is indeed available. The swissALTI3D model from the Swiss Federal Office of Topography (swisstopo), see Figure 18. If you are interested in how to download the DEM and to merge the tiles, please refer to the `processing_DEM.ipynb` in `SUPPPORT_REPO/src/scripts/scripts_limmat_data_preprocessing/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24afba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the high-resolution DEM data\n",
    "dem_path = download_named_file(\n",
    "    name='dem_hres',\n",
    "    data_type='gis'\n",
    ")\n",
    "\n",
    "# Check CRS compatibility first\n",
    "with rasterio.open(dem_path) as src:\n",
    "    dem_crs = src.crs\n",
    "    print(f\"DEM CRS: {dem_crs}\")\n",
    "    print(f\"Model grid CRS: {modelgrid.crs}\")\n",
    "    \n",
    "    if str(dem_crs) != str(modelgrid.crs):\n",
    "        print(\"CRS transformation needed\")\n",
    "        \n",
    "        # Get the bounds of the model grid in its CRS\n",
    "        grid_bounds = modelgrid.extent\n",
    "        \n",
    "        # Transform model grid bounds to DEM CRS for cropping\n",
    "        dem_bounds = transform_bounds(\n",
    "            modelgrid.crs, dem_crs, \n",
    "            grid_bounds[0], grid_bounds[2], \n",
    "            grid_bounds[1], grid_bounds[3]\n",
    "        )\n",
    "        \n",
    "        # Read and crop the DEM data\n",
    "        window = src.window(*dem_bounds)\n",
    "        dem_data = src.read(1, window=window)\n",
    "        dem_transform = src.window_transform(window)\n",
    "        \n",
    "        # Now reproject the cropped DEM to match the model grid CRS\n",
    "        dst_crs = modelgrid.crs\n",
    "        dst_transform, dst_width, dst_height = rasterio.warp.calculate_default_transform(\n",
    "            dem_crs, dst_crs, dem_data.shape[1], dem_data.shape[0], *dem_bounds\n",
    "        )\n",
    "        \n",
    "        # Create output array\n",
    "        reprojected_dem = np.empty((dst_height, dst_width), dtype=dem_data.dtype)\n",
    "        \n",
    "        # Perform the reprojection\n",
    "        reproject(\n",
    "            dem_data,\n",
    "            reprojected_dem,\n",
    "            src_transform=dem_transform,\n",
    "            src_crs=dem_crs,\n",
    "            dst_transform=dst_transform,\n",
    "            dst_crs=dst_crs,\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "        \n",
    "        # Create a temporary raster file with the reprojected data\n",
    "        import tempfile\n",
    "        with tempfile.NamedTemporaryFile(suffix='.tif', delete=False) as tmp:\n",
    "            tmp_path = tmp.name\n",
    "            \n",
    "        with rasterio.open(\n",
    "            tmp_path, 'w',\n",
    "            driver='GTiff',\n",
    "            height=dst_height,\n",
    "            width=dst_width,\n",
    "            count=1,\n",
    "            dtype=reprojected_dem.dtype,\n",
    "            crs=dst_crs,\n",
    "            transform=dst_transform,\n",
    "        ) as dst:\n",
    "            dst.write(reprojected_dem, 1)\n",
    "        \n",
    "        # Now load with FloPy Raster\n",
    "        rio = Raster.load(tmp_path)\n",
    "        \n",
    "        # Clean up temporary file\n",
    "        import os\n",
    "        os.unlink(tmp_path)\n",
    "        \n",
    "    else:\n",
    "        print(\"CRS are compatible, no transformation needed\")\n",
    "        rio = Raster.load(dem_path)\n",
    "\n",
    "arr = rio.get_array(1)\n",
    "# Mask values below 0 and set them to NaN\n",
    "arr = np.where(arr <= 0, np.nan, arr)\n",
    "\n",
    "idx = np.isfinite(arr)\n",
    "\n",
    "vmin, vmax = arr[idx].min(), arr[idx].max()\n",
    "print(f\"DEM elevation range: {vmin:.1f} to {vmax:.1f} meters\")\n",
    "\n",
    "# Get the minimum and maximum coordinates of the DEM file\n",
    "dem_bounds = rio.bounds\n",
    "print(f\"DEM bounds: {dem_bounds}\")\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "\n",
    "# Create a masked array for plotting to handle NaN values properly\n",
    "masked_arr = np.ma.masked_invalid(arr)\n",
    "\n",
    "# Plot the raster with proper extent\n",
    "im = ax.imshow(masked_arr, extent=rio.bounds, vmin=vmin, vmax=vmax, cmap='terrain')\n",
    "plt.colorbar(im, shrink=0.7, label=\"Elevation (m)\")\n",
    "\n",
    "# Plot the model grid on top\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "pmv.plot_grid(lw=0.5, color=\"white\", alpha=0.7)\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "ax.set_title(\"Figure 18: High-resolution DEM with model grid overlay in grey and model boundary in red.\")\n",
    "ax.set_xlabel(\"X-coordinate (m)\")\n",
    "ax.set_ylabel(\"Y-coordinate (m)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e00ff",
   "metadata": {},
   "source": [
    "We resample the high-resolution DEM to our 50 m x 50 m grid (Figure 19).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8256398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Resample the high-resolution DEM ---\n",
    "# Verify CRS alignment\n",
    "print(\"Raster CRS:\", rio.crs)\n",
    "print(\"Grid CRS:  \", modelgrid.crs)\n",
    "\n",
    "# Depending on the resolution of the DEM, resampling can be computationally \n",
    "# intensive.\n",
    "t0 = time.time() # To log the time it takes to resample the DEM\n",
    "model_top_hres = rio.resample_to_grid(modelgrid, band=rio.bands[0], method=\"nearest\")\n",
    "resample_time = time.time() - t0\n",
    "\n",
    "# Build a valid-data mask (exclude nodata and non-finite)\n",
    "valid = np.isfinite(model_top_hres)\n",
    "for nod in (rio.nodatavals or []):\n",
    "    if nod is not None:\n",
    "        valid &= model_top_hres != nod\n",
    "\n",
    "# Also drop absurd magnitudes (typical float32 nodata)\n",
    "valid &= np.abs(model_top_hres) < 1e6\n",
    "\n",
    "# Drop values below 0\n",
    "valid &= model_top_hres > 0\n",
    "\n",
    "# We round to 10 centimeters to avoid having to store too many digits\n",
    "model_top_hres = np.round(model_top_hres, 1)\n",
    "\n",
    "# Compute robust vmin/vmax\n",
    "if np.any(valid):\n",
    "    vmin, vmax = np.nanmin(model_top_hres[valid]), np.nanmax(model_top_hres[valid])\n",
    "else:\n",
    "    raise RuntimeError(\"No valid DEM samples on the grid. Check CRS/projection.\")\n",
    "\n",
    "\n",
    "# Now to visualize using flopy and matplotlib\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "im = pmv.plot_array(model_top_hres, masked_values=rio.nodatavals, vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Overlay the buffered model boundary with proper legend handling\n",
    "boundary_patch = gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "\n",
    "plt.title(f\"Resample time, nearest neighbor: {resample_time:.3f} sec\")\n",
    "plt.colorbar(im, shrink=0.7, label=\"Elevation (m a.s.l.)\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "\n",
    "# Create custom legend handle to avoid warnings\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Buffered Model Boundary')\n",
    "ax.legend(handles=[red_line])\n",
    "ax.set_title(\"Figure 19: Resampled DEM on Model Grid with Buffered Model Boundary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6989b304",
   "metadata": {},
   "source": [
    "This is our new model top. We now get the elevation of the river bottom and make sure all our layers are consistent with the new top elevation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9afad97",
   "metadata": {},
   "source": [
    "#### 4.4.1 Delineating River Cells and Assigning Elevations\n",
    "With our model grid established, we now need to tell the model exactly where the rivers are located and define their physical properties. We'll use our model grid layer (IBOUND) and a Digital Elevation Model (DEM) to accomplish this. The goal is to create the key input for the River (RIV) Package: a list of active river cells and their corresponding bottom elevations (rbot).\n",
    "\n",
    "**1. Selecting River Cells from the Grid**\n",
    "The first step is to identify which specific grid cells represent the Sihl and Limmat rivers. We can overlay our river shapes with the model grid and select the intersecting cells.\n",
    "\n",
    "Action: We loaded the IBOUND grid layer into QGIS. Using the \"Select Features\" tool, we manually selected each cell that the Sihl and Limmat rivers flow through.\n",
    "\n",
    "Important Consideration: During selection, we ensured that the path of river cells was continuous. Each cell in the river is connected to the next one by sharing a cell face, not just a corner. This is best practice for the River (RIV) Package ensuring conceptual integrity and an absolute requirement for advanced packages like the Streamflow Routing (SFR) Package.\n",
    "\n",
    "Output: The selected cells were then saved as a new GeoPackage layer named river_cells.gpkg. This gives us a clean, isolated layer containing only the cells that will make up our rivers.\n",
    "\n",
    "**2. Extracting Riverbed Elevation (rbot)**\n",
    "Each river cell in the model needs a riverbed elevation (rbot). This value represents the bottom of the river channel and is used to determine whether the river is losing water to the aquifer or gaining water from it.\n",
    "\n",
    "Action: We used the Zonal Statistics tool in QGIS.\n",
    "\n",
    "Zones Layer: river_cells.gpkg\n",
    "\n",
    "Raster Layer: The project's high-resolution DEM.\n",
    "\n",
    "Statistic to calculate: Minimum\n",
    "\n",
    "Why the 'Minimum' Value? A single model cell (e.g., 50x50 meters) covers a significant area. The river channel within that cell will naturally occupy the lowest point. By extracting the minimum elevation from the DEM within each cell's boundary, we get a very good approximation of the true riverbed elevation.\n",
    "\n",
    "Figure 20 shows the output of the Zonal Statistics tool, with the extracted minimum elevations for each river cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c92c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(\n",
    "    image_filename='river_cells_qgis.png', \n",
    "    image_folder='4_model_implementation',\n",
    "    caption='Figure 20: Cells selected to represent the rivers. The active model cells are represented in grey. The background map is OpenStreetMap.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dceae28",
   "metadata": {},
   "source": [
    "**3. Quality Control and Manual Correction**\n",
    "Automated processes are powerful, but they aren't perfect and require a \"reality check.\" A river's elevation profile should consistently and smoothly decrease as it flows downstream—water doesn't flow uphill!\n",
    "\n",
    "Action: We inspected the minimum elevation values generated by Zonal Statistics. We discovered an issue near the Zürich Hauptbahnhof (main station). Here, the Sihl river flows through a tunnel beneath the railway tracks.\n",
    "\n",
    "The Problem: The DEM represents the surface elevation, which in this case is the top of the train station and tracks, not the hidden riverbed below. This resulted in artificially high rbot values.\n",
    "\n",
    "The Solution: We manually edited the attribute table for the river_cells layer, correcting these values based on known engineering plans or logical interpolation. This ensured we have a monotonically decreasing riverbed profile, which is physically realistic.\n",
    "\n",
    "With these steps complete, we now have a river_cells.gpkg file where each polygon represents a specific model cell and has a corrected attribute for its riverbed elevation. This is the perfect input for building our FloPy river package.\n",
    "\n",
    "Let's have a look at the river bottoms (rbot) we've extracted (Figure 21)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b20e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the riverbed elevations (rbot) from the river_cells layer\n",
    "river_cells_path = download_named_file(\n",
    "    name=\"river_cells\", \n",
    "    data_type=\"limmat_valley_model\"\n",
    "    )\n",
    "# Plot river cells over DEM with the same color scale\n",
    "# Load river cells and align CRS\n",
    "river_cells_gdf = gpd.read_file(river_cells_path)\n",
    "river_cells_gdf = river_cells_gdf.to_crs(modelgrid.crs)\n",
    "# Print the features of river_cells_gdf\n",
    "# print(river_cells_gdf)\n",
    "\n",
    "# Pick the riverbed elevation column (try common names)\n",
    "rbot_candidates = ['rbot', 'r_bottom', 'rbed', 'rbed_elev', 'rbot_m',\n",
    "                   'min', '_min', 'MIN', 'min_elev', 'z_min', 'Z_MIN']\n",
    "rbot_col = next((c for c in rbot_candidates if c in river_cells_gdf.columns), None)\n",
    "if rbot_col is None:\n",
    "    raise ValueError(f\"No riverbed elevation column found. Available columns: {list(river_cells_gdf.columns)}\")\n",
    "\n",
    "# Ensure row/col indices for placing values on the grid\n",
    "def _find_index_col(gdf, name_opts):\n",
    "    for n in name_opts:\n",
    "        if n in gdf.columns:\n",
    "            return n\n",
    "    return None\n",
    "\n",
    "row_col_name = _find_index_col(river_cells_gdf, ['row', 'ROW', 'i'])\n",
    "col_col_name = _find_index_col(river_cells_gdf, ['col', 'COL', 'j'])\n",
    "\n",
    "if row_col_name is None or col_col_name is None:\n",
    "    # Fallback: spatial join with ibound_gdf if available\n",
    "    if 'ibound_gdf' in globals():\n",
    "        joined = gpd.sjoin(river_cells_gdf, ibound_gdf[['cell_id','row','col','geometry']], how='left', predicate='intersects')\n",
    "        if joined[['row','col']].isna().any().any():\n",
    "            raise ValueError(\"Could not map all river cells to grid indices via ibound_gdf.\")\n",
    "        river_cells_gdf['row'] = joined['row'].astype(int)\n",
    "        river_cells_gdf['col'] = joined['col'].astype(int)\n",
    "        row_col_name, col_col_name = 'row', 'col'\n",
    "    else:\n",
    "        # Last resort: use GridIntersect\n",
    "        ix = GridIntersect(modelgrid, method='vertex', rtree=True)\n",
    "        rows_list, cols_list = [], []\n",
    "        for _, feat in river_cells_gdf.iterrows():\n",
    "            res = ix.intersect(feat.geometry)\n",
    "            if len(res) == 0:\n",
    "                rows_list.append(np.nan); cols_list.append(np.nan)\n",
    "            else:\n",
    "                # take the first intersecting cell (cells should be unique per feature)\n",
    "                rr = int(res.iloc[0]['row']); cc = int(res.iloc[0]['col'])\n",
    "                rows_list.append(rr); cols_list.append(cc)\n",
    "        river_cells_gdf['row'] = rows_list\n",
    "        river_cells_gdf['col'] = cols_list\n",
    "        if river_cells_gdf[['row','col']].isna().any().any():\n",
    "            raise ValueError(\"Could not map some river cells to grid indices (GridIntersect).\")\n",
    "        row_col_name, col_col_name = 'row', 'col'\n",
    "\n",
    "# Build an array of riverbed elevations on the model grid\n",
    "river_rbot_array = np.full((nrow_rotated, ncol_rotated), np.nan, dtype=float)\n",
    "for _, r in river_cells_gdf.iterrows():\n",
    "    i = int(r[row_col_name]); j = int(r[col_col_name])\n",
    "    if 0 <= i < nrow_rotated and 0 <= j < ncol_rotated:\n",
    "        river_rbot_array[i, j] = float(r[rbot_col])\n",
    "\n",
    "# Use the same color scale as model_top_hres\n",
    "valid_top = np.isfinite(model_top_hres) & (np.abs(model_top_hres) < 1e6)\n",
    "if not np.any(valid_top):\n",
    "    raise RuntimeError(\"model_top_hres has no valid values to define color scale.\")\n",
    "cmap = 'terrain'\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "\n",
    "# Base DEM (high‑res resampled)\n",
    "im = pmv.plot_array(model_top_hres, vmin=vmin, vmax=vmax, cmap=cmap, alpha=0.9)\n",
    "\n",
    "# Overlay river cells, colored by rbot, using the same vmin/vmax/cmap\n",
    "#pmv.plot_array(np.ma.masked_invalid(river_rbot_array), vmin=vmin, vmax=vmax, cmap=cmap, alpha=1.0)\n",
    "\n",
    "# Boundary outline\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2, label='Model boundary')\n",
    "\n",
    "# Colorbar reflects the shared scale\n",
    "cb = plt.colorbar(im, ax=ax, shrink=0.75, label=\"Elevation (m a.s.l.)\")\n",
    "\n",
    "ax.set_title(\"Figure 21: River cells (rbot) over model_top_hres (shared color scale)\")\n",
    "ax.set_xlabel(\"X-coordinate (m)\")\n",
    "ax.set_ylabel(\"Y-coordinate (m)\")\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de7ec6f",
   "metadata": {},
   "source": [
    "We see by the darker blue of the river in the downstream part that the river bottom elevation is below the surrounding DEM, as we expect. Let's see if in the river bottom is below the DEM of the river cells everywhere. We take the difference between the two (Figure 22)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdff871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth-to-riverbed on river cells: positive if riverbed is below ground, negative if inconsistent\n",
    "river_mask = np.isfinite(river_rbot_array) & np.isfinite(model_top_hres)\n",
    "if not np.any(river_mask):\n",
    "    raise RuntimeError(\"No valid river rbot values found to compute differences.\")\n",
    "\n",
    "depth_to_riverbed = model_top_hres - river_rbot_array\n",
    "depth_to_riverbed_masked = np.ma.masked_where(~river_mask, depth_to_riverbed)\n",
    "\n",
    "# Symmetric color scale around 0 to make inconsistencies visible\n",
    "absmax = np.nanmax(np.abs(depth_to_riverbed[river_mask]))\n",
    "vmin_diff, vmax_diff = -absmax, absmax if np.isfinite(absmax) and absmax > 0 else (-1, 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "# Show the model grid\n",
    "pmv.plot_grid(color=\"grey\", linewidth=0.3, alpha=0.25, zorder=0)\n",
    "\n",
    "# Plot only river cells with a diverging cmap centered at 0\n",
    "im = pmv.plot_array(\n",
    "    depth_to_riverbed_masked,\n",
    "    cmap=\"RdBu_r\",\n",
    "    vmin=vmin_diff,\n",
    "    vmax=vmax_diff,\n",
    "    alpha=0.95\n",
    ")\n",
    "\n",
    "# Boundary\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=1.5, label='Model boundary')\n",
    "\n",
    "cb = plt.colorbar(im, ax=ax, shrink=0.75, label=\"model_top_hres − rbot (m)\")\n",
    "ax.set_title(\"Figure 22: Depth to riverbed on river cells (positive = river below ground)\")\n",
    "ax.set_xlabel(\"X-coordinate (m)\")\n",
    "ax.set_ylabel(\"Y-coordinate (m)\")\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# Quick summary in console\n",
    "neg_cnt = np.sum(depth_to_riverbed[river_mask] < 0)\n",
    "print(f\"River cells: {river_mask.sum()} | negatives (rbot above ground): {neg_cnt}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acf43e1",
   "metadata": {},
   "source": [
    "We have consistently lower river bottom than model top. Now we define other parameters of the River (RIV) package.\n",
    "\n",
    "#### 4.4.2 Write RIV package \n",
    "The River (RIV) package represents rivers that can either gain water from or lose water to the aquifer, depending on the hydraulic gradient. Unlike the CHD package, which fixes heads, the RIV package simulates a dynamic head-dependent flux boundary.\n",
    "\n",
    "In Flopy, each active river cell requires three main parameters:\n",
    "\n",
    "1. **Stage** – the river water level (m).\n",
    "\n",
    "2. **Conductance** – the hydraulic connection between the river and the aquifer. It is usually computed as:\n",
    "\n",
    "$$𝐶=𝐾_{riverbed}⋅\\frac{𝑊⋅𝐿}{𝑀}$$\n",
    "\n",
    "where \n",
    "$K_{riverbed}$ = riverbed hydraulic conductivity,  \n",
    "$W$ = river width,  \n",
    "$L$ = river reach length,  \n",
    "$M$ = riverbed thickness.  \n",
    "\n",
    "3. **Riverbed Bottom Elevation** – the elevation of the base of the riverbed (m). This ensures that if the aquifer head drops below this level, no more seepage to the river occurs.\n",
    "\n",
    "Please have a look at the Section on the River-Aquifer Interaction in the second notebook on the Perceptual model to be reminded of how the flux is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dca51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RIV package\n",
    "# Parameters\n",
    "# Leakage coefficient as estimated in perceptual model chapter:\n",
    "q_riv_sihl = 1.3e-6 * 86400  # 1/day\n",
    "q_riv_limmat = 3.5e-6 * 86400  # 1/day\n",
    "\n",
    "riverbed_thickness = 0.5    # m, typical assumption\n",
    "riverbed_k_sihl = q_riv_sihl * riverbed_thickness  # m/d (hydraulic conductivity of riverbed)\n",
    "riverbed_k_limmat = q_riv_limmat * riverbed_thickness  # m/d (hydraulic conductivity of riverbed)\n",
    "\n",
    "# Average river depth estimated in perceptual model chapter:\n",
    "sihl_depth_mean = 0.3\n",
    "limmat_depth_mean = 0.7\n",
    "min_stage_clearance = 0.05  # m above rbot to avoid stage==rbot\n",
    "# Optional width by river name (if attribute present on river_cells_gdf)\n",
    "width_by_name = {\n",
    "    'Limmat': 30.0,  # m\n",
    "    'Sihl':   15.0,  # m\n",
    "}\n",
    "default_width = 15.0  # m (used if river name is not available)\n",
    "\n",
    "# Define conductance scaling factors by zone, useful to get a better match/stable model\n",
    "conductance_scaling = {\n",
    "    1: 100.0,   # Increase conductance by factor in zone 1\n",
    "    2: 0.7,    # Reduce conductance by factor in zone 2\n",
    "}\n",
    "default_scaling = 1.0  # No scaling for cells not in defined zones\n",
    "\n",
    "# Find a river name column, if any\n",
    "river_name_col = None\n",
    "for cand in ['GEWAESSERNAME', 'name', 'river', 'river_name', 'Name', 'gew_name']:\n",
    "    if cand in river_cells_gdf.columns:\n",
    "        river_name_col = cand\n",
    "        break\n",
    "\n",
    "# Optional: Scale conductance values in different parameter zones\n",
    "# Build RIV stress period data with zone-based scaling\n",
    "riv_spd = []  \n",
    "n_skipped = 0  \n",
    "\n",
    "# Create a zone lookup for river cells\n",
    "def get_zone_at_cell(i, j, zones_gdf, grid):\n",
    "    \"\"\"Get the zone ID for a given cell (i, j)\"\"\"\n",
    "    try:\n",
    "        # Get cell center coordinates\n",
    "        x_center = grid.xcellcenters[i, j]\n",
    "        y_center = grid.ycellcenters[i, j]\n",
    "        \n",
    "        # Check which zone polygon contains this point\n",
    "        from shapely.geometry import Point\n",
    "        point = Point(x_center, y_center)\n",
    "        \n",
    "        for _, zone_row in zones_gdf.iterrows():\n",
    "            if zone_row.geometry.contains(point):\n",
    "                return zone_row[zone_col]\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Exclude CHD cells from RIV\n",
    "chd_cells_set = set()\n",
    "if 'chd' in globals():\n",
    "    try:\n",
    "        chd_cells_set = {(int(c[1]), int(c[2])) for c in chd.stress_period_data[0]}\n",
    "    except Exception:\n",
    "        chd_cells_set = set()\n",
    "\n",
    "for _, rec in river_cells_gdf.iterrows():\n",
    "    i = int(rec['row'])\n",
    "    j = int(rec['col'])\n",
    "\n",
    "    # Skip if out of grid or not active\n",
    "    if not (0 <= i < nrow_rotated and 0 <= j < ncol_rotated):\n",
    "        n_skipped += 1\n",
    "        continue\n",
    "    if ibound[0, i, j] != 1:\n",
    "        n_skipped += 1\n",
    "        continue\n",
    "    if (i, j) in chd_cells_set:\n",
    "        n_skipped += 1\n",
    "        continue\n",
    "\n",
    "    # Assign river bottom elevation (rbot)\n",
    "    rbot = float(rec[rbot_col])\n",
    "    if not np.isfinite(rbot):\n",
    "        n_skipped += 1\n",
    "        continue\n",
    "\n",
    "    # Choose width (W)\n",
    "    if river_name_col is not None and isinstance(rec[river_name_col], str):\n",
    "        W = width_by_name.get(rec[river_name_col], default_width)\n",
    "    else:\n",
    "        W = default_width\n",
    "\n",
    "    # Approximate reach length (L)\n",
    "    L = float(min(delr_rotated[j], delc_rotated[i]))\n",
    "\n",
    "    # Base conductance calculation\n",
    "    if river_name_col is not None and isinstance(rec[river_name_col], str):\n",
    "        base_cond = (riverbed_k_limmat if rec[river_name_col] == 'Limmat' else riverbed_k_sihl) * (W * L) / riverbed_thickness\n",
    "    else:\n",
    "        base_cond = riverbed_k_sihl * (W * L) / riverbed_thickness\n",
    "\n",
    "    # Apply zone-based scaling to conductance\n",
    "    zone_id = get_zone_at_cell(i, j, zones, modelgrid)\n",
    "    scaling_factor = conductance_scaling.get(zone_id, default_scaling)\n",
    "    cond = base_cond * scaling_factor\n",
    "\n",
    "    # Stage calculation (unchanged)\n",
    "    if river_name_col is not None and isinstance(rec[river_name_col], str):\n",
    "        stage = rbot + (sihl_depth_mean if rec[river_name_col] == 'Sihl' else limmat_depth_mean)\n",
    "    else:\n",
    "        stage = rbot + sihl_depth_mean\n",
    "\n",
    "    # Optional cap to remain below ground\n",
    "    if 'model_top_hres' in globals() and np.isfinite(model_top_hres[i, j]):\n",
    "        stage = min(stage, model_top_hres[i, j] - min_stage_clearance)\n",
    "\n",
    "    # Ensure stage is above rbot\n",
    "    if stage <= rbot:\n",
    "        stage = rbot + min_stage_clearance\n",
    "\n",
    "    riv_spd.append([0, i, j, float(stage), float(cond), float(rbot)])\n",
    "\n",
    "print(f\"RIV cells prepared: {len(riv_spd)} (skipped: {n_skipped})\")\n",
    "\n",
    "# Print conductance scaling summary\n",
    "zone_counts = {}\n",
    "for _, rec in river_cells_gdf.iterrows():\n",
    "    i, j = int(rec['row']), int(rec['col'])\n",
    "    if 0 <= i < nrow_rotated and 0 <= j < ncol_rotated:\n",
    "        zone_id = get_zone_at_cell(i, j, zones, modelgrid)\n",
    "        zone_counts[zone_id] = zone_counts.get(zone_id, 0) + 1\n",
    "\n",
    "print(\"River conductance scaling summary:\")\n",
    "for zone_id, count in zone_counts.items():\n",
    "    if zone_id in conductance_scaling:\n",
    "        factor = conductance_scaling[zone_id]\n",
    "        print(f\"  Zone {zone_id}: {count} cells, conductance × {factor}\")\n",
    "    else:\n",
    "        print(f\"  Zone {zone_id}: {count} cells, no scaling\")\n",
    "\n",
    "# 3) Create/replace the RIV package\n",
    "riv = flopy.modflow.ModflowRiv(\n",
    "    mf,\n",
    "    stress_period_data={0: riv_spd},\n",
    "    ipakcb=53  # enable cbc output for river package\n",
    ")\n",
    "\n",
    "print(\"RIV package created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d713ff",
   "metadata": {},
   "source": [
    "#### 4.4.3 Update the DIS package\n",
    "We have to write the new model top to the DIS package. We further check if the model bottom is consistent with the river bottom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a862ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check if the model bottom is below the river bottom\n",
    "# Masks\n",
    "river_mask = np.isfinite(river_rbot_array)           # only river cells\n",
    "active_mask = ibound[0] != 0                         # exclude fully inactive cells\n",
    "check_mask = river_mask & active_mask\n",
    "\n",
    "# Print dimensions of model_bottom and river_rbot_array for debugging\n",
    "model_bottom = modelgrid.botm[0]  # assuming single layer model\n",
    "print(f\"Model bottom shape: {model_bottom.shape}\")\n",
    "print(f\"River rbot array shape: {river_rbot_array.shape}\")\n",
    "# Difference: botm - rbot\n",
    "diff = model_bottom - river_rbot_array\n",
    "problem_mask = check_mask & (diff > 0)\n",
    "# If problem_mask is 3D, squeeze to 2D\n",
    "if problem_mask.ndim == 3 and problem_mask.shape[0] == 1:\n",
    "    problem_mask = problem_mask[0]\n",
    "\n",
    "n_checked = int(np.nansum(check_mask))\n",
    "n_problem = int(np.nansum(problem_mask))\n",
    "print(f\"River cells checked: {n_checked}\")\n",
    "print(f\"Problem cells (botm > rbot): {n_problem}\")\n",
    "\n",
    "# Show top 10 violations\n",
    "if n_problem:\n",
    "    ii, jj = np.where(problem_mask)\n",
    "    violations = pd.DataFrame({\n",
    "        'row': ii,\n",
    "        'col': jj,\n",
    "        'botm': model_bottom[ii, jj],\n",
    "        'rbot': river_rbot_array[ii, jj],\n",
    "        'botm_minus_rbot': diff[ii, jj],\n",
    "    }).sort_values('botm_minus_rbot', ascending=False)\n",
    "    display(violations.head(10))\n",
    "\n",
    "# Plot map of problem cells (colored by botm - rbot)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "plot_arr = np.where(problem_mask, diff, np.nan)\n",
    "im = pmv.plot_array(plot_arr, cmap='Reds')\n",
    "pmv.plot_grid(alpha=0.2, linewidth=0.4)\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=1)\n",
    "ax.set_title(\"Figure 23: Cells where model bottom > riverbed (color = botm − rbot, m)\")\n",
    "ax.set_aspect('equal')\n",
    "plt.colorbar(im, ax=ax, shrink=0.7, label='botm − rbot (m)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd8d40d",
   "metadata": {},
   "source": [
    "Figure 23 shows that, at a few locations at the model boundary, the river bottom is below the model bottom. We will lower the model bottom to 2 m below the river bottom at these locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0dabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the model bottom where it is below the river bottom\n",
    "model_bottom[problem_mask] = river_rbot_array[problem_mask] - 2\n",
    "\n",
    "# With the new hres model top, we want to ensure that the aquifer thickness is \n",
    "# still at least 2 m of saturated thickness and a minimum of 2 m unsaturated \n",
    "# thickness. We choose 5 meters minimum thickness between model bottom and model \n",
    "# top.\n",
    "model_bottom = np.minimum(model_bottom, model_top_hres - 5.0)\n",
    "\n",
    "# Visual check\n",
    "# Difference: botm - rbot\n",
    "diff = model_bottom - river_rbot_array\n",
    "problem_mask = check_mask & (diff > 0)\n",
    "\n",
    "n_checked = int(np.nansum(check_mask))\n",
    "n_problem = int(np.nansum(problem_mask))\n",
    "print(f\"River cells checked: {n_checked}\")\n",
    "print(f\"Problem cells (botm > rbot): {n_problem}\")\n",
    "\n",
    "# Show top 10 violations\n",
    "if n_problem:\n",
    "    ii, jj = np.where(problem_mask)\n",
    "    violations = pd.DataFrame({\n",
    "        'row': ii,\n",
    "        'col': jj,\n",
    "        'botm': model_bottom[ii, jj],\n",
    "        'rbot': river_rbot_array[ii, jj],\n",
    "        'botm_minus_rbot': diff[ii, jj],\n",
    "    }).sort_values('botm_minus_rbot', ascending=False)\n",
    "    display(violations.head(10))\n",
    "\n",
    "# Plot map of problem cells (colored by botm - rbot)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "plot_arr = np.where(problem_mask, diff, np.nan)\n",
    "im = pmv.plot_array(plot_arr, cmap='Reds')\n",
    "pmv.plot_grid(alpha=0.2, linewidth=0.4)\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=1)\n",
    "ax.set_title(\"Figure 24: Cells where model bottom > riverbed (color = botm − rbot, m)\")\n",
    "ax.set_aspect('equal')\n",
    "plt.colorbar(im, ax=ax, shrink=0.7, label='botm − rbot (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c73516e",
   "metadata": {},
   "source": [
    "The river bed elevation is now consistent with the model bottom (Figure 24). Now we can update the DIS package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the DIS package\n",
    "# Remove existing DIS package\n",
    "if hasattr(mf, 'dis') and mf.dis is not None:\n",
    "    mf.remove_package('DIS')\n",
    "# Create a new DIS package with updated model bottom\n",
    "dis = flopy.modflow.ModflowDis(\n",
    "    mf,\n",
    "    nlay=nlay,\n",
    "    nrow=nrow_rotated,\n",
    "    ncol=ncol_rotated,\n",
    "    delr=delr_rotated,\n",
    "    delc=delc_rotated,\n",
    "    top=model_top_hres,\n",
    "    botm=model_bottom,\n",
    "    xul=xmin_original,\n",
    "    yul=ymax_original,\n",
    "    angrot=grid_rotation_angle,\n",
    "    lenuni=2,\n",
    "    nper=nper,\n",
    "    perlen=perlen,\n",
    "    nstp=nstp,\n",
    "    tsmult=tsmult,\n",
    "    steady=steady\n",
    ")\n",
    "\n",
    "# Check if model top and model bottom are less than 2 meters apart.\n",
    "if np.any(dis.top - dis.botm[0] < 2):\n",
    "    raise ValueError(\"Model top and bottom must be at least 2 meters apart.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91658f9",
   "metadata": {},
   "source": [
    "#### 4.4.4 Check if the CHD boundary is consistent with new model geometry\n",
    "We should now check if the CHD boundary conditions are consistent with the new model geometry. This includes verifying that the elevations of the CHD boundaries are within the updated model layer elevations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71440bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compare CHD shead values to model top & bottom at ibound == -1 cells ---\n",
    "# Safety checks\n",
    "if 'chd' not in globals():\n",
    "    raise RuntimeError(\"CHD package (chd) not found.\")\n",
    "if 'bas' not in globals():\n",
    "    raise RuntimeError(\"BAS package (bas) not found.\")\n",
    "if not hasattr(mf, 'dis'):\n",
    "    raise RuntimeError(\"DIS package not found on model (mf).\")\n",
    "\n",
    "# Get CHD stress period 0 data (recarray with fields k, i, j, shead, ehead)\n",
    "spd0 = chd.stress_period_data[0]\n",
    "k = spd0['k']\n",
    "i = spd0['i']\n",
    "j = spd0['j']\n",
    "shead = spd0['shead']  # initial (start) heads\n",
    "\n",
    "# Model top (2D) and bottom (first/only layer)\n",
    "top_2d = mf.dis.top.array\n",
    "botm_3d = mf.dis.botm.array\n",
    "botm_2d = botm_3d[0]  # single-layer model\n",
    "\n",
    "# IBOUND array\n",
    "ibound_arr = bas.ibound.array  # shape (nlay, nrow, ncol)\n",
    "\n",
    "# Ensure all listed CHD cells are actually flagged ibound == -1\n",
    "ibound_flags = ibound_arr[k, i, j]\n",
    "if not np.all(ibound_flags == -1):\n",
    "    mismatch_idx = np.where(ibound_flags != -1)[0]\n",
    "    print(f\"Warning: {len(mismatch_idx)} CHD cells are not ibound == -1. Showing first few:\")\n",
    "    print(pd.DataFrame({\n",
    "        'k': k[mismatch_idx],\n",
    "        'i': i[mismatch_idx],\n",
    "        'j': j[mismatch_idx],\n",
    "        'ibound': ibound_flags[mismatch_idx],\n",
    "        'shead': shead[mismatch_idx]\n",
    "    }).head())\n",
    "\n",
    "# Extract top & bottom at CHD cells\n",
    "top_at = top_2d[i, j]\n",
    "botm_at = botm_2d[i, j]\n",
    "\n",
    "# Tolerance for comparisons\n",
    "tol = 1e-6\n",
    "\n",
    "within_top = shead <= (top_at + tol)\n",
    "above_botm = shead >= (botm_at - tol)\n",
    "within_bounds = within_top & above_botm\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'k': k,\n",
    "    'i': i,\n",
    "    'j': j,\n",
    "    'shead': shead,\n",
    "    'top': top_at,\n",
    "    'botm': botm_at,\n",
    "    'above_botm': above_botm,\n",
    "    'below_top': within_top,\n",
    "    'within_bounds': within_bounds,\n",
    "})\n",
    "\n",
    "print(f\"Total CHD cells: {len(summary_df)}\")\n",
    "print(f\"Within (botm <= shead <= top): {within_bounds.sum()}\")\n",
    "print(f\"Above top: {(~within_top).sum()}\")\n",
    "print(f\"Below bottom: {(~above_botm).sum()}\")\n",
    "\n",
    "# Show any problem rows\n",
    "problem_rows = summary_df[~within_bounds]\n",
    "if not problem_rows.empty:\n",
    "    print(\"\\nCHD cells with inconsistent heads (showing all):\")\n",
    "    display(problem_rows)\n",
    "else:\n",
    "    print(\"All CHD heads lie between model bottom and top (within tolerance).\")\n",
    "\n",
    "# Optional: quick numeric ranges\n",
    "if len(summary_df):\n",
    "    print(f\"\\nRange shead: {shead.min():.3f} – {shead.max():.3f} m\")\n",
    "    print(f\"Range top  : {top_at.min():.3f} – {top_at.max():.3f} m\")\n",
    "    print(f\"Range botm : {botm_at.min():.3f} – {botm_at.max():.3f} m\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fe48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-D visualization of model top, bottom, and CHD boundary heads (active domain only)\n",
    "fig = plot_interactive_model_domain_3d(\n",
    "    mf, bas=bas, chd=chd, riv=riv, engine=\"plotly\", exaggeration=20.0, \n",
    "    custom_title=\"Figure 16: 3D Model Domain Visualization with Increased Model Depth.\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86398c68",
   "metadata": {},
   "source": [
    "#### 4.4.5 Check initial heads in BAS package\n",
    "We should also check if the initial heads in the BAS package are consistent with the new model geometry. This includes verifying that the initial heads are within the updated model layer elevations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763bc9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and fix starting heads (strt) above top\n",
    "top = mf.dis.top.array\n",
    "botm = mf.dis.botm.array\n",
    "strt = mf.bas6.strt.array\n",
    "\n",
    "# Ensure 3D arrays\n",
    "if strt.ndim == 2:\n",
    "    strt = strt[np.newaxis, ...]\n",
    "if top.ndim == 2:\n",
    "    top = top[np.newaxis, ...]\n",
    "if botm.ndim == 2:\n",
    "    botm = botm[np.newaxis, ...]\n",
    "\n",
    "# Find where strt > top\n",
    "above_top = (strt > top)\n",
    "n_viol_top = int(np.sum(above_top))\n",
    "print(f\"Cells where strt > top: {n_viol_top}\")\n",
    "\n",
    "# Set strt to top - 1 where above top\n",
    "strt[above_top] = top[above_top] - 1\n",
    "\n",
    "# Recheck\n",
    "above_top_after = (strt > top)\n",
    "below_botm_after = (strt < botm)\n",
    "n_viol_top_after = int(np.sum(above_top_after))\n",
    "n_viol_botm_after = int(np.sum(below_botm_after))\n",
    "\n",
    "print(f\"After correction:\")\n",
    "print(f\"Cells where strt > top: {n_viol_top_after}\")\n",
    "print(f\"Cells where strt < botm: {n_viol_botm_after}\")\n",
    "\n",
    "# Optionally, update the model's strt\n",
    "mf.bas6.strt = strt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d33de",
   "metadata": {},
   "source": [
    "#### 4.4.6 Update LFP package\n",
    "To make sure we don't have any old information in the LPF package, we can use the `rebuild_lpf_preserve_transmissivity` function defined below. This function will update the LPF package with the new hydraulic conductivity values while preserving transmissivity if the old thickness is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8154ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_lpf_preserve_transmissivity(\n",
    "    mf,\n",
    "    min_thickness=0.5,\n",
    "    hk_min=1e-4,\n",
    "    hk_max=1e4,\n",
    "    preserve_T=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Rebuild LPF so hydraulic conductivity fields stay consistent after geometry (DIS) changes.\n",
    "    If preserve_T and old_thickness is available (same shape), transmissivity is preserved:\n",
    "        T_old = hk_old * old_thickness  -> hk_new = T_old / new_thickness\n",
    "    Otherwise hk_old is kept.\n",
    "    Vertical K is rebuilt from preserved anisotropy ratio (kv/kh) where possible.\n",
    "    Requirements:\n",
    "        - Existing LPF package already attached to model (to read prior hk/vka).\n",
    "        - Updated DIS already present (new top/botm).\n",
    "        - (Optional) old_thickness in globals with shape (nrow, ncol).\n",
    "    \"\"\"\n",
    "    lpf_old = mf.get_package(\"LPF\")\n",
    "    if lpf_old is None:\n",
    "        raise RuntimeError(\"No existing LPF package found.\")\n",
    "\n",
    "    # Current geometry\n",
    "    top = mf.dis.top.array\n",
    "    botm0 = mf.dis.botm.array[0]\n",
    "    new_thk = top - botm0\n",
    "    if (new_thk <= 0).any():\n",
    "        raise ValueError(\"Found non-positive thickness cells after DIS update.\")\n",
    "\n",
    "    # Old property arrays\n",
    "    hk_old = np.array(lpf_old.hk.array[0], dtype=float)  # (nrow, ncol)\n",
    "    vka_old = np.array(lpf_old.vka.array[0], dtype=float)\n",
    "\n",
    "    # Try to preserve transmissivity if old_thickness provided\n",
    "    use_T = False\n",
    "    if preserve_T and 'old_thickness' in globals():\n",
    "        if isinstance(old_thickness, np.ndarray) and old_thickness.shape == hk_old.shape:\n",
    "            old_T = hk_old * np.maximum(old_thickness, min_thickness)\n",
    "            hk_new = old_T / np.maximum(new_thk, min_thickness)\n",
    "            use_T = True\n",
    "        else:\n",
    "            hk_new = hk_old.copy()\n",
    "    else:\n",
    "        hk_new = hk_old.copy()\n",
    "\n",
    "    # Bound hk\n",
    "    hk_new = np.clip(hk_new, hk_min, hk_max)\n",
    "\n",
    "    # Preserve anisotropy ratio (kv/kh) safely\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ratio = np.where(hk_old > 0, vka_old / hk_old, np.nan)\n",
    "    # Fallback ratio where invalid\n",
    "    default_ratio = np.nanmedian(ratio[np.isfinite(ratio)]) if np.isfinite(ratio).any() else 0.1\n",
    "    ratio[~np.isfinite(ratio)] = default_ratio\n",
    "    vka_new = hk_new * ratio\n",
    "    vka_new = np.clip(vka_new, hk_min, hk_max)\n",
    "\n",
    "    # Rebuild LPF (remove old first for cleanliness)\n",
    "    mf.remove_package('LPF')\n",
    "    new_lpf = flopy.modflow.ModflowLpf(\n",
    "        mf,\n",
    "        hk=hk_new[np.newaxis, ...],\n",
    "        vka=vka_new[np.newaxis, ...],\n",
    "        sy=lpf_old.sy.array if lpf_old.sy is not None else 0.15,\n",
    "        ss=lpf_old.ss.array if lpf_old.ss is not None else 1e-4,\n",
    "        laytyp=lpf_old.laytyp.array if lpf_old.laytyp is not None else 1,\n",
    "        ipakcb=lpf_old.ipakcb,\n",
    "        hdry=lpf_old.hdry,\n",
    "        wetfct=lpf_old.wetfct,\n",
    "        iwetit=lpf_old.iwetit,\n",
    "        laywet=lpf_old.laywet.array if lpf_old.laywet is not None else 1,\n",
    "        wetdry=getattr(lpf_old, 'wetdry', 0.01)\n",
    "    )\n",
    "\n",
    "    print(\"LPF rebuilt.\")\n",
    "    print(f\"  Preserved transmissivity: {use_T}\")\n",
    "    print(f\"  Thickness (m): min {new_thk.min():.2f} | mean {new_thk.mean():.2f} | max {new_thk.max():.2f}\")\n",
    "    print(f\"  hk_new (m/d):  min {hk_new.min():.3g} | mean {hk_new.mean():.3g} | max {hk_new.max():.3g}\")\n",
    "    print(f\"  vka_new (m/d): min {vka_new.min():.3g} | mean {vka_new.mean():.3g} | max {vka_new.max():.3g}\")\n",
    "    return new_lpf\n",
    "\n",
    "\n",
    "# Define old_thickness for transmissivity preservation\n",
    "old_thickness = model_top_hres - (mf.dis.botm.array[0] if hasattr(mf.dis, 'botm') else model_bottom_hres)\n",
    "\n",
    "print(\"old_thickness shape:\", old_thickness.shape)\n",
    "print(\"hk_old shape:\", mf.get_package(\"LPF\").hk.array[0].shape)\n",
    "\n",
    "# Run rebuild\n",
    "lpf = rebuild_lpf_preserve_transmissivity(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d9aa66",
   "metadata": {},
   "source": [
    "### 4.5 Groundwater Pumping & Lateral Inflow - Well (WEL) Package\n",
    "\n",
    "Next we tackle the **lateral inflows from the north and the south** of the model. We will implement these as recharge wells with specified rates. In Chapter 2 - Perceptual Model, we estimate the lateral inflows to be about 20% of the annual precipiation of 1100 mm/year on an area of 11 km2 in the north and 15 km2 in the south. These amounts have to be distributed along the northern and southern boundaries of the model. We will do the same trick with the selection of cells for in QGIS as for the constant head boundary condition. The code below shows how to create the lateral inflow boundary condition based on the selected cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa10e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define zone-based scaling factors for lateral inflow, scaling is optional but \n",
    "# can help to get a better match/stable model\n",
    "inflow_scaling = {\n",
    "    1: 1.0,   # Option to scale inflow in zone 1 by a factor\n",
    "    2: 1.0,    # Option to scale inflow in zone 2 by a factor\n",
    "}\n",
    "default_inflow_scaling = 1.0  # No scaling for cells not in defined zones\n",
    "\n",
    "# Function to get zone for a cell (reuse from river code)\n",
    "def get_zone_at_cell(i, j, zones_gdf, grid):\n",
    "    \"\"\"Get the zone ID for a given cell (i, j)\"\"\"\n",
    "    try:\n",
    "        # Get cell center coordinates\n",
    "        x_center = grid.xcellcenters[i, j]\n",
    "        y_center = grid.ycellcenters[i, j]\n",
    "        \n",
    "        # Check which zone polygon contains this point\n",
    "        from shapely.geometry import Point\n",
    "        point = Point(x_center, y_center)\n",
    "        \n",
    "        for _, zone_row in zones_gdf.iterrows():\n",
    "            if zone_row.geometry.contains(point):\n",
    "                return zone_row[zone_col]\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Each selected boundary cell receives an equal share of the total inflow\n",
    "# Positive WEL rates inject water (MODFLOW convention)\n",
    "inflow_north = 0.2 * 1.100 * 11000000 / 365.25  # m3/day\n",
    "inflow_south = 0.2 * 1.100 * 15000000 / 365.25  # m3/day\n",
    "\n",
    "wells_north_path = download_named_file(\n",
    "    name='wells_north', \n",
    "    data_type='limmat_valley_model'\n",
    ")\n",
    "wells_south_path = download_named_file(\n",
    "    name='wells_south', \n",
    "    data_type='limmat_valley_model'\n",
    ")\n",
    "\n",
    "# Load selections\n",
    "wells_north_gdf = gpd.read_file(wells_north_path).to_crs(modelgrid.crs)\n",
    "wells_south_gdf = gpd.read_file(wells_south_path).to_crs(modelgrid.crs)\n",
    "ibound_gdf = gpd.read_file(os.path.join(workspace, 'ibound.gpkg'))\n",
    "\n",
    "if 'ibound_gdf' not in globals():\n",
    "    raise RuntimeError(\"ibound_gdf not in scope. Run IBOUND section first.\")\n",
    "\n",
    "for need in ['cell_id', 'row', 'col', 'ibound']:\n",
    "    if need not in ibound_gdf.columns:\n",
    "        raise ValueError(f\"ibound_gdf missing column: {need}\")\n",
    "\n",
    "for g in (wells_north_gdf, wells_south_gdf):\n",
    "    if 'cell_id' not in g.columns:\n",
    "        raise ValueError(\"Boundary well selection layers must contain 'cell_id' (export from ibound layer).\")\n",
    "\n",
    "# Normalize identifiers\n",
    "ibound_gdf['cell_id'] = ibound_gdf['cell_id'].astype(str).str.strip()\n",
    "wells_north_gdf['cell_id'] = wells_north_gdf['cell_id'].astype(str).str.strip()\n",
    "wells_south_gdf['cell_id'] = wells_south_gdf['cell_id'].astype(str).str.strip()\n",
    "\n",
    "def prepare_boundary(df_sel, label):\n",
    "    print(f\"\\nDebugging {label} boundary:\")\n",
    "    print(f\"df_sel columns: {df_sel.columns.tolist()}\")\n",
    "    print(f\"ibound_gdf columns: {ibound_gdf.columns.tolist()}\")\n",
    "    \n",
    "    joined = df_sel.merge(\n",
    "        ibound_gdf[['cell_id', 'row', 'col', 'ibound']],\n",
    "        on=['cell_id', 'row', 'col', 'ibound'],\n",
    "        how='inner',\n",
    "        validate='1:1'\n",
    "    )\n",
    "    \n",
    "    print(f\"After merge columns: {joined.columns.tolist()}\")\n",
    "    print(f\"Joined shape: {joined.shape}\")\n",
    "    \n",
    "    if joined.empty:\n",
    "        raise ValueError(f\"No matching cell_id for {label} boundary selection.\")\n",
    "    \n",
    "    # Check if 'ibound' column exists after merge\n",
    "    if 'ibound' not in joined.columns:\n",
    "        print(\"Available columns after merge:\", joined.columns.tolist())\n",
    "        raise ValueError(f\"'ibound' column missing after merge for {label}\")\n",
    "    \n",
    "    # Keep active (ibound==1) only (exclude inactive and CHD cells)\n",
    "    joined = joined.loc[joined['ibound'] == 1].drop_duplicates(subset=['row','col'])\n",
    "    joined['row'] = joined['row'].astype(int)\n",
    "    joined['col'] = joined['col'].astype(int)\n",
    "    return joined\n",
    "\n",
    "north_cells = prepare_boundary(wells_north_gdf, \"north\")\n",
    "south_cells = prepare_boundary(wells_south_gdf, \"south\")\n",
    "\n",
    "n_north = len(north_cells)\n",
    "n_south = len(south_cells)\n",
    "\n",
    "if n_north == 0:\n",
    "    raise ValueError(\"North boundary selection has no active non-CHD cells.\")\n",
    "if n_south == 0:\n",
    "    raise ValueError(\"South boundary selection has no active non-CHD cells.\")\n",
    "\n",
    "# For north boundary: uniform distribution (no zone scaling)\n",
    "q_north_each = inflow_north / n_north\n",
    "\n",
    "# For south boundary: apply zone-based scaling\n",
    "# First, determine zones for each south cell and calculate total scaling factor\n",
    "south_zone_info = []\n",
    "total_scaling_factor = 0.0\n",
    "\n",
    "for _, r in south_cells.iterrows():\n",
    "    zone_id = get_zone_at_cell(r.row, r.col, zones, modelgrid)\n",
    "    scaling_factor = inflow_scaling.get(zone_id, default_inflow_scaling)\n",
    "    south_zone_info.append({\n",
    "        'row': r.row,\n",
    "        'col': r.col,\n",
    "        'zone_id': zone_id,\n",
    "        'scaling_factor': scaling_factor\n",
    "    })\n",
    "    total_scaling_factor += scaling_factor\n",
    "\n",
    "# Distribute south inflow proportionally to scaling factors\n",
    "wel_spd = []\n",
    "\n",
    "# North cells: uniform distribution\n",
    "for _, r in north_cells.iterrows():\n",
    "    wel_spd.append([0, r.row, r.col, q_north_each])\n",
    "\n",
    "# South cells: zone-proportional distribution\n",
    "for cell_info in south_zone_info:\n",
    "    # Each cell gets base flow × its scaling factor / total scaling factor\n",
    "    q_south_cell = inflow_south * cell_info['scaling_factor'] / total_scaling_factor\n",
    "    wel_spd.append([0, cell_info['row'], cell_info['col'], q_south_cell])\n",
    "\n",
    "# Calculate totals and print summary\n",
    "total_north = sum(w[3] for w in wel_spd if w[1] in [r.row for _, r in north_cells.iterrows()])\n",
    "total_south = sum(w[3] for w in wel_spd if w[1] in [info['row'] for info in south_zone_info])\n",
    "\n",
    "print(f\"Lateral inflow north total: {total_north:.2f} m3/d over {n_north} cells \"\n",
    "      f\"(each {q_north_each:.3f} m3/d)\")\n",
    "print(f\"Lateral inflow south total: {total_south:.2f} m3/d over {n_south} cells\")\n",
    "\n",
    "# Print zone-specific south boundary summary\n",
    "zone_summary = {}\n",
    "for cell_info in south_zone_info:\n",
    "    zone_id = cell_info['zone_id']\n",
    "    if zone_id not in zone_summary:\n",
    "        zone_summary[zone_id] = {'count': 0, 'total_flow': 0.0, 'scaling': cell_info['scaling_factor']}\n",
    "    zone_summary[zone_id]['count'] += 1\n",
    "    zone_summary[zone_id]['total_flow'] += inflow_south * cell_info['scaling_factor'] / total_scaling_factor\n",
    "\n",
    "print(\"South boundary inflow by zone:\")\n",
    "for zone_id, summary in zone_summary.items():\n",
    "    avg_flow = summary['total_flow'] / summary['count']\n",
    "    print(f\"  Zone {zone_id}: {summary['count']} cells, total {summary['total_flow']:.2f} m3/d, \"\n",
    "          f\"avg {avg_flow:.3f} m3/d/cell, scaling factor {summary['scaling']}\")\n",
    "\n",
    "total_assigned = sum(w[3] for w in wel_spd)\n",
    "print(f\"Combined injected via WEL: {total_assigned:.2f} m3/d\")\n",
    "\n",
    "# Create / replace WEL package\n",
    "wel = flopy.modflow.ModflowWel(\n",
    "    mf,\n",
    "    stress_period_data={0: wel_spd},\n",
    "    ipakcb=53\n",
    ")\n",
    "\n",
    "print(\"WEL package created for lateral inflows with zone-based scaling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ec076",
   "metadata": {},
   "source": [
    "In Figure 26, we see the locations of the wells representing the lateral inflow from the hillsides. Now we add the groundwater abstractions in the Limmat valley. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the wells geopackage\n",
    "# Get the path to the well locations\n",
    "well_data_path = download_named_file(name='wells', data_type='gis')\n",
    "\n",
    "# Read the geopackage into a geopandas dataframe\n",
    "wells_gdf = gpd.read_file(well_data_path, layer='GS_GRUNDWASSERFASSUNGEN_OGD_P').to_crs(modelgrid.crs)\n",
    "\n",
    "# 1. Normalize / helper columns\n",
    "wells_gdf['GWR_PREFIX'] = (\n",
    "    wells_gdf['GWR_ID']\n",
    "    .astype(str)\n",
    "    .str.split('_', n=1).str[0]\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "wells_gdf['FASSBEZ_CLEAN'] = (\n",
    "    wells_gdf['FASSBEZ']\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# 2. Target ID prefixes (lowercase)\n",
    "target_ids = {'b010071', 'b010020', 'b010063'}\n",
    "mask_prefix = wells_gdf['GWR_PREFIX'].isin(target_ids)\n",
    "\n",
    "# 3. Location / construction type logic\n",
    "# Hardhof (substring match, case-insensitive) AND Horizontalbrunnen\n",
    "mask_hard = (\n",
    "    wells_gdf['FASSBEZ_CLEAN'].str.contains(r'hardhof brunnen', case=False, na=False)\n",
    "    & wells_gdf['FASSART'].str.contains('Horizontalbrunnen', case=False, na=False)\n",
    ")\n",
    "\n",
    "# Lochergut or Schlachthof (substring match) AND Vertikalbrunnen\n",
    "mask_loch_schl = (\n",
    "    wells_gdf['FASSBEZ_CLEAN'].str.contains('lochergut|schlachthof', case=False, na=False)\n",
    "    & wells_gdf['FASSART'].str.contains('Vertikalbrunnen', case=False, na=False)\n",
    ")\n",
    "\n",
    "# 4. Combine\n",
    "mask_final = mask_prefix & (mask_hard | mask_loch_schl)\n",
    "\n",
    "selected_wells = wells_gdf.loc[mask_final].copy()\n",
    "\n",
    "print(f\"Total wells: {len(wells_gdf)}\")\n",
    "print(f\"Matched target prefixes: {mask_prefix.sum()}\")\n",
    "print(f\"Hardhof horizontal matches: {mask_hard.sum()}\")\n",
    "print(f\"Lochergut/Schlachthof vertical matches: {mask_loch_schl.sum()}\")\n",
    "print(f\"Selected wells (final): {len(selected_wells)}\")\n",
    "\n",
    "display(\n",
    "    selected_wells[\n",
    "        ['GWR_ID','GWR_PREFIX','FASSBEZ','FASSART','FASSBEZ_CLEAN']\n",
    "    ].sort_values('GWR_ID')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e365de1",
   "metadata": {},
   "source": [
    "Now we assign the pumping rates to these selected wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a195c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define annual volumes (m3/year)\n",
    "hardhof_total_year = 7_000_000   # distributed over 4 Hardhof horizontal wells\n",
    "vertical_total_year = 600_000    # distributed over 2 vertical wells (Lochergut + Schlachthof)\n",
    "\n",
    "# Identify groups\n",
    "mask_hardhof = (\n",
    "    selected_wells['FASSBEZ_CLEAN'].str.contains('hardhof', case=False, na=False) &\n",
    "    selected_wells['FASSART'].str.contains('Horizontalbrunnen', case=False, na=False)\n",
    ")\n",
    "\n",
    "mask_vertical = (\n",
    "    selected_wells['FASSBEZ_CLEAN'].str.contains('lochergut|schlachthof', case=False, na=False) &\n",
    "    selected_wells['FASSART'].str.contains('Vertikalbrunnen', case=False, na=False)\n",
    ")\n",
    "\n",
    "n_hardhof = mask_hardhof.sum()\n",
    "n_vertical = mask_vertical.sum()\n",
    "\n",
    "# Expected counts (for even split)\n",
    "expected_hardhof = 4\n",
    "expected_vertical = 2\n",
    "\n",
    "if n_hardhof != expected_hardhof:\n",
    "    print(f\"Warning: Detected {n_hardhof} Hardhof horizontal wells (expected {expected_hardhof}). Rates still assigned evenly over detected count.\")\n",
    "\n",
    "if n_vertical != expected_vertical:\n",
    "    print(f\"Warning: Detected {n_vertical} vertical wells (expected {expected_vertical}). Rates still assigned evenly over detected count.\")\n",
    "\n",
    "# Per-well annual volumes (fallback to detected counts to avoid division by zero)\n",
    "hardhof_per_well_year = hardhof_total_year / (n_hardhof if n_hardhof else 1)\n",
    "vertical_per_well_year = vertical_total_year / (n_vertical if n_vertical else 1)\n",
    "\n",
    "# If during model run, cells run dry, try to reduce pumping rates by a percentage  \n",
    "# to test model stability. Uncomment if desired but don't keep amounts at reduced \n",
    "# levels unless corroborated with data.\n",
    "hardhof_per_well_year *= 0.5\n",
    "vertical_per_well_year *= 0.5\n",
    "\n",
    "# Convert to daily (365.25 days/year)\n",
    "hardhof_per_well_day = round(hardhof_per_well_year / 365.25)\n",
    "vertical_per_well_day = round(vertical_per_well_year / 365.25)\n",
    "\n",
    "# Initialize abstraction column (m3/day, negative = pumping)\n",
    "selected_wells['abstraction_m3_d'] = 0.0\n",
    "selected_wells.loc[mask_hardhof, 'abstraction_m3_d'] = -hardhof_per_well_day\n",
    "selected_wells.loc[mask_vertical, 'abstraction_m3_d'] = -vertical_per_well_day\n",
    "\n",
    "# Summary\n",
    "print(\"Assigned abstraction (m3/day per well):\")\n",
    "print(f\"  Hardhof horizontals: {hardhof_per_well_day:,.2f} (negative sign denotes pumping)\")\n",
    "print(f\"  Vertical (Lochergut/Schlachthof): {vertical_per_well_day:,.2f}\")\n",
    "\n",
    "display(\n",
    "    selected_wells[\n",
    "        ['GWR_ID','FASSBEZ','FASSART','abstraction_m3_d']\n",
    "    ].sort_values('GWR_ID')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f53527",
   "metadata": {},
   "source": [
    "Now we intersect the selected wells with the model grid to assign them to the appropriate grid cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38182213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: assign each well to (row,col) with robust handling of GridIntersect output\n",
    "ix = GridIntersect(modelgrid, method='vertex', rtree=True)\n",
    "\n",
    "# Pre-build KDTree for nearest-cell fallback (cell centers)\n",
    "xc = modelgrid.xcellcenters\n",
    "yc = modelgrid.ycellcenters\n",
    "centers_flat = np.column_stack([xc.ravel(), yc.ravel()])\n",
    "kdtree = cKDTree(centers_flat)\n",
    "\n",
    "def _extract_rc_from_intersect(res, ncol):\n",
    "    \"\"\"\n",
    "    Accepts possible return types from GridIntersect:\n",
    "      - numpy recarray with fields (row,col) or (cellids)\n",
    "      - pandas DataFrame with columns\n",
    "      - list/tuple of cellids\n",
    "    Returns (r, c) or raises ValueError.\n",
    "    \"\"\"\n",
    "    if res is None:\n",
    "        raise ValueError(\"Intersection result is None.\")\n",
    "    # Numpy structured / recarray\n",
    "    if isinstance(res, np.recarray):\n",
    "        names = res.dtype.names or ()\n",
    "        if len(res) == 0:\n",
    "            raise ValueError(\"Empty recarray.\")\n",
    "        if 'row' in names and 'col' in names:\n",
    "            return int(res['row'][0]), int(res['col'][0])\n",
    "        if 'cellids' in names:\n",
    "            cellid = int(res['cellids'][0])\n",
    "            r, c = divmod(cellid, ncol)\n",
    "            return r, c\n",
    "        # Fallback first numeric value\n",
    "        cellid = int(res[0])\n",
    "        r, c = divmod(cellid, ncol)\n",
    "        return r, c\n",
    "    # Pandas DataFrame\n",
    "    try:\n",
    "        import pandas as _pd\n",
    "        if isinstance(res, _pd.DataFrame):\n",
    "            if len(res) == 0:\n",
    "                raise ValueError(\"Empty DataFrame.\")\n",
    "            cols = res.columns\n",
    "            if 'row' in cols and 'col' in cols:\n",
    "                return int(res.iloc[0]['row']), int(res.iloc[0]['col'])\n",
    "            if 'cellids' in cols:\n",
    "                cellid = int(res.iloc[0]['cellids'])\n",
    "                r, c = divmod(cellid, ncol)\n",
    "                return r, c\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Iterable of cellids\n",
    "    if hasattr(res, '__iter__'):\n",
    "        seq = list(res)\n",
    "        if len(seq):\n",
    "            cellid = int(seq[0])\n",
    "            r, c = divmod(cellid, ncol)\n",
    "            return r, c\n",
    "    raise ValueError(\"Could not parse row/col from intersection result.\")\n",
    "\n",
    "well_cell_records = []\n",
    "skipped_inactive = 0\n",
    "skipped_chd = 0\n",
    "skipped_missing_rate = 0\n",
    "skipped_intersection = 0\n",
    "\n",
    "for _, w in selected_wells.iterrows():\n",
    "    geom = w.geometry\n",
    "    if geom is None or geom.is_empty:\n",
    "        continue\n",
    "\n",
    "    res = ix.intersect(geom)  # point intersection\n",
    "    try:\n",
    "        if res is None or len(res) == 0:\n",
    "            raise ValueError(\"Empty intersection\")\n",
    "        r, c = _extract_rc_from_intersect(res, modelgrid.ncol)\n",
    "    except Exception:\n",
    "        # Fallback: nearest cell center\n",
    "        dist, idx_flat = kdtree.query([geom.x, geom.y])\n",
    "        r, c = np.unravel_index(idx_flat, xc.shape)\n",
    "        skipped_intersection += 1\n",
    "\n",
    "    # Pumping rate\n",
    "    if 'abstraction_m3_d' not in w or pd.isna(w['abstraction_m3_d']):\n",
    "        skipped_missing_rate += 1\n",
    "        continue\n",
    "    flux = float(w['abstraction_m3_d'])\n",
    "\n",
    "    flag = ibound[0, r, c]\n",
    "    if flag == 0:\n",
    "        skipped_inactive += 1\n",
    "        continue\n",
    "    if flag == -1:\n",
    "        skipped_chd += 1\n",
    "        continue\n",
    "\n",
    "    well_cell_records.append((0, r, c, flux, w.get('GWR_ID', None)))\n",
    "\n",
    "print(f\"Wells mapped: {len(well_cell_records)}\")\n",
    "if skipped_intersection:  print(f\"  Used nearest-cell fallback: {skipped_intersection}\")\n",
    "if skipped_inactive:      print(f\"  Skipped inactive cells: {skipped_inactive}\")\n",
    "if skipped_chd:           print(f\"  Skipped CHD cells: {skipped_chd}\")\n",
    "if skipped_missing_rate:  print(f\"  Skipped missing rate: {skipped_missing_rate}\")\n",
    "\n",
    "# Merge with existing WEL (lateral inflows)\n",
    "existing_spd = wel.stress_period_data[0]\n",
    "combined = {}\n",
    "for rec in existing_spd:\n",
    "    key = (int(rec['k']), int(rec['i']), int(rec['j']))\n",
    "    combined[key] = combined.get(key, 0.0) + float(rec['flux'])\n",
    "\n",
    "for k, r, c, flux, wid in well_cell_records:\n",
    "    key = (k, r, c)\n",
    "    combined[key] = combined.get(key, 0.0) + flux\n",
    "\n",
    "new_wel_spd = [[k, r, c, f] for (k, r, c), f in combined.items()]\n",
    "\n",
    "mf.remove_package('WEL')\n",
    "wel = flopy.modflow.ModflowWel(\n",
    "    mf,\n",
    "    stress_period_data={0: new_wel_spd},\n",
    "    ipakcb=53\n",
    ")\n",
    "\n",
    "print(f\"Total WEL cells (inflow + pumping): {len(new_wel_spd)}\")\n",
    "total_injection = sum(f for _,_,_,f in new_wel_spd if f > 0)\n",
    "total_pumping  = sum(f for _,_,_,f in new_wel_spd if f < 0)\n",
    "print(f\"  Injection total (m3/d): {total_injection:,.2f}\")\n",
    "print(f\"  Pumping   total (m3/d): {total_pumping:,.2f}\")\n",
    "\n",
    "# Quick plot of pumping vs injection cells\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mf.modelgrid, ax=ax)\n",
    "pmv.plot_grid(alpha=0.15, linewidth=0.4)\n",
    "pmv.plot_ibound()\n",
    "pmv.plot_bc(package=wel)\n",
    "ax.set_title(\"Figure 27: WEL cells: Lateral inflow and pumping (red). IBOUND with inactive (black), active (white) and CHD (blue) boundaries.\")\n",
    "ax.set_xlabel(\"X (m)\")\n",
    "ax.set_ylabel(\"Y (m)\")\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301d6982",
   "metadata": {},
   "source": [
    "Figure 27 shows the finished plot of WEL cells, illustrating the spatial distribution of lateral inflow and pumping cells within the model domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b9e63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c4aa1d",
   "metadata": {},
   "source": [
    "## 5 Solver and Output Control (PCG & OC Packages)\n",
    "\n",
    "We need to tell MODFLOW how to solve the system of equations. The **Preconditioned Conjugate-Gradient (PCG)** package is a robust and commonly used solver. We also need to specify what results we want to save using the **Output Control (OC)** package. We are interested in saving the head and budget results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc696cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Solver and Output Control ---\n",
    "# Add the PCG solver\n",
    "pcg = flopy.modflow.ModflowPcg(\n",
    "    mf, \n",
    "    mxiter=200,  # Maximum number of iterations\n",
    "    iter1=100,  # Number of iterations for the first stage\n",
    "    hclose = 0.01,  # Head change convergence criterion\n",
    "    rclose = 1.0,  # Residual convergence criterion\n",
    "    relax=0.98,  # Relaxation factor\n",
    "    damp=0.7  # Damping factor\n",
    ")\n",
    "\n",
    "# Specify output control\n",
    "oc = flopy.modflow.ModflowOc(\n",
    "    mf, \n",
    "    # Save head and budget at the end of each stress period\n",
    "    stress_period_data={(0, 0): ['save head', 'save budget']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d37f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b024aaf9",
   "metadata": {},
   "source": [
    "## 6 Run the model\n",
    "Now that we have defined all the necessary packages, we can run the model. We will use the `write_input` method to write all the input files and then use the `run_model` method to execute the simulation.\n",
    "\n",
    "### 6.1 Write and inspect input files\n",
    "We start by writing the input files using the `write_input` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write input files\n",
    "mf.write_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aba007",
   "metadata": {},
   "source": [
    "Please find the newly created files in your working directory. You should see a list of files called limmat_valley_model with different file endings, reflecting the package structure of a MODFLOW model, for example: \n",
    "- .nam\n",
    "- .dis\n",
    "- .bas\n",
    "- .lpf\n",
    "- .pcg\n",
    "- .oc\n",
    "All of the above files can be opened in your default text editor. Since flopy conveniently handles reading and writing of these files for us, we will not go into detail about the contents of each package. We do, however, want to highlight the importance of the following file for debugging your model:\n",
    "\n",
    "#### .nam file\n",
    "The .nam file is the name file for the MODFLOW model. It contains the names of all the input files that MODFLOW will use during the simulation. This file is essential for running the model, as it tells MODFLOW where to find the necessary input data.  \n",
    "\n",
    "You can check if all the required input files are listed in the .nam file by opening it in a text editor and verifying the file names.\n",
    "\n",
    "### 6.2 Check if the modflow model setup is consistent\n",
    "Modflow has a model check utility that can be used to verify the consistency of the model setup. This utility checks for common errors and inconsistencies in the model input files, such as missing or misconfigured packages, and provides helpful error messages to guide the user in fixing any issues.\n",
    "\n",
    "Be prepared to address any errors or warnings that the utility may find before proceeding with the model simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run FloPy's built-in input checker (prints a summary)\n",
    "chk = mf.check(f=None, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3069312",
   "metadata": {},
   "source": [
    "You might encounter errors and warnings in the model check. For example if the starting heads are below the new bottom elevations plus the clearance, this will trigger a warning. Or if hydraulic parameters are not properly defined. You will then have to follow up on these issues before proceeding.\n",
    "\n",
    "### 6.3 Model Simulation (WORK IN PROGRESS)\n",
    "We now attempt a forward simulation to observe the model behavior over time. run_model will produce an output file that contains the simulation results (.list). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e766ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "success, buff = mf.run_model(silent=True, report=True)\n",
    "\n",
    "# We print the last lines of the listing file in case the model run fails.\n",
    "if not success:\n",
    "    print(\"Model did not run successfully. Reading listing file tail...\")\n",
    "    lst_path = os.path.join(workspace, f\"{model_name}.list\")\n",
    "    if os.path.exists(lst_path):\n",
    "        with open(lst_path, \"r\", errors=\"ignore\") as f:\n",
    "            lst_tail = f.read().splitlines()[-200:]\n",
    "        print(\"---- tail of listing (.list) ----\")\n",
    "        print(\"\\n\".join(lst_tail))\n",
    "    else:\n",
    "        print(f\"Listing file not found at: {lst_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7307825",
   "metadata": {},
   "source": [
    "Our model ran dry and the model did not run successfully! We need to investigate the model setup, particularly the initial conditions and the boundary conditions applied to the constant head cells. Let's see which cells went dry during the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b01df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_cells = mvu.fix_dry_cell_extraction(\n",
    "    os.path.join(workspace, f\"{model_name}.list\"))\n",
    "\n",
    "# Plot dry_cells on map\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mf.modelgrid, ax=ax)\n",
    "pmv.plot_grid(alpha=0.2, linewidth=0.4)\n",
    "if dry_cells:\n",
    "    rows, cols = zip(*dry_cells)\n",
    "    ax.scatter(\n",
    "        mf.modelgrid.xcellcenters[rows, cols],\n",
    "        mf.modelgrid.ycellcenters[rows, cols],\n",
    "        c='red', s=20, edgecolors='k', linewidths=0.4, label='Dry cell'\n",
    "    )\n",
    "pmv.plot_ibound()\n",
    "ax.set_title(\"Figure 28: Dry cells detected during the model run (red). IBOUND with inactive (black), active (white) and CHD (blue) boundaries.\")\n",
    "ax.set_xlabel(\"X (m)\")\n",
    "ax.set_ylabel(\"Y (m)\")\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f832bd",
   "metadata": {},
   "source": [
    "Pumping in the Hardhof well field is too high in the current setup and the model runs dry. \n",
    "\n",
    "The Hardhof well field is in reality quite more complex than represented in our model. Water, that is abstracted in the well field is first pumped in river-bank filtration wells, recharged to the aquifer and then abstracted in production wells. In our simple model, we abstract water directly from the aquifer. \n",
    "\n",
    "Let's have a look at the head distribution in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2972db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the heads and budget files\n",
    "headobj = flopy.utils.HeadFile(os.path.join(workspace, f\"{model_name}.hds\"))\n",
    "head = headobj.get_data(totim=1.0)  # Get heads at end of first stress period\n",
    "\n",
    "import flopy.utils as fu\n",
    "# Create a head difference array (head - top)\n",
    "head_diff = head - mf.dis.top.array\n",
    "# Plot the head difference\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mf.modelgrid, ax=ax)\n",
    "im = pmv.plot_array(head_diff, cmap='RdBu', vmin=-5, vmax=5)\n",
    "pmv.plot_grid(alpha=0.2, linewidth=0.4)\n",
    "pmv.plot_ibound()\n",
    "ax.set_title(\"Figure 29: Head difference (head - top) at end of first stress period (m). IBOUND with inactive (black) and CHD (blue) boundaries.\")\n",
    "ax.set_xlabel(\"X (m)\")\n",
    "ax.set_ylabel(\"Y (m)\")\n",
    "ax.set_aspect('equal')\n",
    "plt.colorbar(im, ax=ax, shrink=0.3, label='Head - Top (m)')\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded22bbc",
   "metadata": {},
   "source": [
    "The groundwater levels rise above the model top in the blue areas. Notoriously, this happens along the southern boundary where we have very shallow cells, so lower transmissivity than in the eastern part of the model.\n",
    "\n",
    "Also in this picture, we see the dominant effect of the pumping in the Hardhof well field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9859829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the cell-by-cell budget terms at the last time step of the first stress period\n",
    "budgobj = flopy.utils.CellBudgetFile(os.path.join(workspace, f\"{model_name}.cbc\"))\n",
    "times = budgobj.get_times()\n",
    "# print(f\"Budget file times: {times}\")\n",
    "kstpkper = budgobj.get_kstpkper()\n",
    "# print(f\"Budget file kstpkper: {kstpkper}\")\n",
    "if len(kstpkper):\n",
    "    cbc = budgobj.get_data(kstpkper=kstpkper[-1])[0]  # Last time step of last stress period\n",
    "    print(f\"Budget terms available: {list(cbc.dtype.names)}\")\n",
    "else:\n",
    "    cbc = None\n",
    "    print(\"No budget data found.\")\n",
    "\n",
    "if budgobj is not None:\n",
    "    # Extract flow right face and flow front face\n",
    "    frf = budgobj.get_data(text=\"FLOW RIGHT FACE\", totim=times[-1])[0]\n",
    "    fff = budgobj.get_data(text=\"FLOW FRONT FACE\", totim=times[-1])[0]\n",
    "\n",
    "# Get heads at the same time\n",
    "if headobj is not None:\n",
    "    head = headobj.get_data(totim=times[-1])[0]\n",
    "    # Mask head array where ibound == 0\n",
    "    head_masked = np.where(ibound == 0, np.nan, head)\n",
    "\n",
    "# Plot flow vectors\n",
    "if budgobj is not None and headobj is not None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    pmv = flopy.plot.PlotMapView(modelgrid=mf.modelgrid, ax=ax)\n",
    "    pmv.plot_ibound()\n",
    "    pmv.plot_grid(alpha=0.2, linewidth=0.4)\n",
    "    # Head contours\n",
    "    cont = pmv.contour_array(head_masked)\n",
    "    plt.clabel(cont, inline=1, fontsize=10, fmt=\"%1.1f\")\n",
    "    # Quiver plot of flow vectors\n",
    "    quiver = pmv.plot_vector(frf, fff, scale=1e5, headwidth=3, headlength=5, headaxislength=4.5, color='blue')\n",
    "    ax.set_title(\"Figure 30: Flow vectors at end of first stress period (m3/day). IBOUND with inactive (black) and CHD (blue) boundaries.\")\n",
    "    ax.set_xlabel(\"X (m)\")\n",
    "    ax.set_ylabel(\"Y (m)\")\n",
    "    ax.set_aspect('equal')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7abb38",
   "metadata": {},
   "source": [
    "The lines of equal head (contours) show that the flow is generally from the south-east to the west, as we expect. The massive pumping rates in the Hardhof well field create a strong cone of depression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa3acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick budget check for your model\n",
    "try:\n",
    "    # Read budget from list file\n",
    "    list_budget = flopy.utils.MfListBudget(\n",
    "        os.path.join(workspace, 'limmat_valley_model.list'))\n",
    "    budget = list_budget.get_budget()[-1]  # Last time step\n",
    "    \n",
    "    df = pd.DataFrame(budget).T\n",
    "\n",
    "    # Identify _IN, _OUT, and summary rows\n",
    "    in_rows = df.index[df.index.str.endswith('_IN')]\n",
    "    out_rows = df.index[df.index.str.endswith('_OUT')]\n",
    "    summary_rows = df.index[~(df.index.str.endswith('_IN') | df.index.str.endswith('_OUT'))]\n",
    "\n",
    "    # Concatenate in desired order\n",
    "    df_reordered = pd.concat([df.loc[in_rows], df.loc[out_rows], df.loc[summary_rows]])\n",
    "\n",
    "    print(\"Your model's water budget:\")\n",
    "    print(df_reordered)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error reading budget: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b943c",
   "metadata": {},
   "source": [
    "What we could do (and what is also in line with the literature, e.g. Doppler et al. 2019) is to increase the river leakage in the upstream part of the model to compensate for the high abstraction rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448a0946",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5beb0a01",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a815ddb5",
   "metadata": {},
   "source": [
    "In our current setup with MODFLOW-2005 and the LPF package, some boundary inflow cells run dry, which makes the model unstable and difficult to converge. To test whether this can be improved, we switch to MODFLOW-NWT together with the UPW (Upstream Weighting) package. MODFLOW-NWT applies a Newton–Raphson nonlinear solver that is designed to handle drying and rewetting more robustly, while UPW replaces LPF with a formulation that works seamlessly with this solver. By doing so, we hope the model can better handle the drying of inflow cells and achieve more reliable convergence.\n",
    "\n",
    "Here is a comparison of the two model versions: \n",
    "\n",
    "| Aspect                    | Classic MODFLOW-2005                                                                 | MODFLOW-NWT (+ ModflowNwt)                                                                                      |\n",
    "|---------------------------|--------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|\n",
    "| Nonlinearity handling     | Picard-style (successive substitution) + LPF/HUF wetting options (WETFCT, IWETIT, etc.) | Newton–Raphson nonlinear solve; UPW flow package; generally no wetting heuristics needed                        |\n",
    "| Linear solver             | SIP, SOR, PCG2, GMG (ModflowSip, ModflowPcg, ModflowGmg)                            | PCG or GMRES internal to NWT (set via linmeth)                                                                  |\n",
    "| Drying/rewetting stability| Can struggle; oscillations, non-convergence in unconfined cells                     | Much more robust; fewer “stuck dry” cells                                                                       |\n",
    "| When faster               | Simple/near-linear problems                                                         | Hard nonlinear problems (water table movement, perched zones, drains/streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lpf_to_nwt_utils as ltn\n",
    "\n",
    "# Convert your existing model\n",
    "mf_nwt = ltn.convert_modflow2005_to_nwt(mf)\n",
    "\n",
    "# Apply thin layer optimizations\n",
    "ltn.optimize_nwt_for_thin_layers(mf_nwt)\n",
    "\n",
    "ltn.optimize_nwt_for_thin_layers(mf_nwt)\n",
    "\n",
    "# Write and run\n",
    "mf_nwt.write_input()\n",
    "\n",
    "# Check input\n",
    "mf_nwt.check(f=None, verbose=True)\n",
    "\n",
    "# Run the NWT model\n",
    "success, buff = mf_nwt.run_model()\n",
    "# We print the last lines of the listing file in case the model run fails.\n",
    "if not success:\n",
    "    print(\"NWT Model did not run successfully. Reading listing file tail...\")\n",
    "    lst_path = os.path.join(workspace, f\"{model_name}.list\")\n",
    "    if os.path.exists(lst_path):\n",
    "        with open(lst_path, \"r\", errors=\"ignore\") as f:\n",
    "            lst_tail = f.read().splitlines()[-200:]\n",
    "        print(\"---- tail of listing (.list) ----\")\n",
    "        print(\"\\n\".join(lst_tail))\n",
    "    else:\n",
    "        print(f\"Listing file not found at: {lst_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a2e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32ffbd87",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce690b82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc60254d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2e521f9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's try reducing the hydraulic conductivities in the model by a factor of 10 and see if that resolves the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f7d2d",
   "metadata": {},
   "source": [
    "### 6.4 Typical run-time issues in MODFLOW (with Flopy) — and how to fix them\n",
    "Don't despair if your model doesn't run successfully (this is the default). Here are some common issues and strategies of how to fix them:\n",
    "\n",
    "- Geometry conflicts (negative thickness / inverted layers): top < botm or botm(k-1) < botm(k) causes aborts.\n",
    "Fix: enforce a minimum thickness, repair ordering top→bottom, deactivate outcrops; add assertions after building arrays.\n",
    "\n",
    "- Dry/oscillating heads: cells go dry near rivers/wells or heads bounce and won’t converge.\n",
    "Fix: enable LPF wetting (IWETIT, WETFCT), reduce time-step size (smaller DELT/nper), moderate boundary conductances, refine grid or smooth parameter contrasts.\n",
    "\n",
    "- Convergence failures (solver): “failed to converge” with large mass-balance errors.\n",
    "Fix: tighten or relax tolerances sensibly (HCLOSE, RCLOSE), increase iteration limits (MXITER, ITER1), switch/improve solver (e.g., PCG→GMG if available), reduce parameter contrasts, shorten stress periods.\n",
    "\n",
    "- Units & magnitudes off: m/s vs m/d, recharge too large, conductance orders-of-magnitude high.\n",
    "Fix: decide on a consistent unit system (m, days), back-calc plausible ranges (e.g., riv conductance), sanity-check budgets.\n",
    "\n",
    "- Bad/stale stress data: stage below riverbed, wells in inactive cells, missing data in later stress periods.\n",
    "Fix: validate every SP: river stage > rbot, stresses only on active cells, explicitly provide or carry forward data for each period.\n",
    "\n",
    "- Package/grid size mismatches: array shapes don’t match nlay/nrow/ncol.\n",
    "Fix: check shapes before write_input(), broadcast carefully, and inspect warnings in the .lst.\n",
    "\n",
    "- Executable & workspace issues: wrong exe_name, files not written, or running in another folder.\n",
    "Fix: call m.write_input(), verify m.exe_name, set a clean model_ws, then success, buff = m.run_model(report=True).\n",
    "\n",
    "**Diagnosing quickly**: always read the list file for the first failing step, check water budget residuals, and plot heads/budgets after each run to see where issues originate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407cd8ba",
   "metadata": {},
   "source": [
    "## 7 Visualize results for first sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c74f40",
   "metadata": {},
   "source": [
    "## References\n",
    "[\\[1\\]](#3-Parameterization) Doppler, T., Hendricks Franssen, H.-J., Kaiser H.-P., Kuhlman U., Stauffer, F. (2007): Field evidence of a dynamic leakage coefficient for modelling river–aquifer interactions. Journal of Hydrology, Volume 347, Issues 1–2, DOI: https://doi.org/10.1016/j.jhydrol.2007.09.017.    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gw_course_students",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
