{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "995914ca",
   "metadata": {},
   "source": [
    "Groundwater | Case Study\n",
    "\n",
    "# Topic 4 : From Concept to Code: Implementing the Limmat Valley Model\n",
    "\n",
    "Dr. Xiang-Zhao Kong & Dr. Beatrice Marti & Louise Noël du Payrat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de7418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "from shapely.ops import unary_union, linemerge\n",
    "from shapely.affinity import rotate, translate, scale\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.spatial import cKDTree\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling, transform_bounds\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import flopy\n",
    "import flopy.plot as fpl\n",
    "from flopy.discretization import StructuredGrid\n",
    "from flopy.utils import Raster, GridIntersect\n",
    "\n",
    "# Add the support repo to the path\n",
    "sys.path.append('../SUPPORT_REPO/src')\n",
    "sys.path.append('../SUPPORT_REPO/src/scripts/scripts_exercises')\n",
    "\n",
    "# Import local modules\n",
    "from data_utils import (\n",
    "    download_named_file, \n",
    "    get_default_data_folder, \n",
    "    fast_resample_dem_to_modelgrid\n",
    ")\n",
    "from print_images import display_image\n",
    "from progress_tracking import (\n",
    "    create_model_implementation_progress_tracker, \n",
    "    create_nested_step_completion_marker, \n",
    ")\n",
    "from grid_utils import build_grid_gdf_and_ibound\n",
    "from river_utils import compute_medial_centerlines\n",
    "from map_utils import plot_interactive_model_domain_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f1e22",
   "metadata": {},
   "source": [
    "In the previous steps, we defined our modeling objectives and developed a perceptual model of the Limmat Valley aquifer. We gathered data on the aquifer's geometry, its boundaries, and the key hydrological processes like recharge and river interaction.\n",
    "\n",
    "Now, we will translate this perceptual understanding into a numerical groundwater model using **MODFLOW 2005** and the Python package **FloPy**. This means we describe the aquifer with numbers and grids, so a computer can simulate water movement. This process involves several key steps:\n",
    "\n",
    "1.  **Discretization:** Defining the model grid (layers, rows, columns) that will represent our aquifer in space.\n",
    "2.  **Parameterization:** Assigning hydraulic properties (like conductivity and storage) to the grid cells.\n",
    "3.  **Boundary Conditions:** Implementing the physical boundaries of our system, such as rivers, recharge, and wells.\n",
    "4.  **Solving:** Choosing a numerical solver and running the simulation.\n",
    "5.  **Post-processing:** Visualizing and analyzing the initial results.\n",
    "\n",
    "You can use the checklist below to keep track of your progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b98df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_implementation_progress_tracker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711ca6e",
   "metadata": {},
   "source": [
    "## 1 Workspace Setup\n",
    "Let's begin by setting up our model workspace. This involves creating a flopy workspace that we will fill with the model grid, boundary conditions, and other necessary components as we progress through the case study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a1598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of our model and the workspace where files will be stored.\n",
    "# We'll create a directory in your default data folder for this course to keep \n",
    "# things organized. \n",
    "model_name = 'limmat_valley_model'\n",
    "workspace = os.path.join(get_default_data_folder(), model_name)\n",
    "\n",
    "# Create the workspace directory if it doesn't exist\n",
    "os.makedirs(workspace, exist_ok=True)\n",
    "\n",
    "# Define the path to the MODFLOW executable\n",
    "# We assume it's in a standard location accessible from the system's PATH.\n",
    "executable = 'mf2005' \n",
    "\n",
    "# Create the MODFLOW model object\n",
    "# The model object is the main object in FloPy that represents the MODFLOW model.\n",
    "# It manages all the information about the model, including the grid, boundary \n",
    "# conditions, and other settings.\n",
    "# We'll fill it with the necessary components as we go along.\n",
    "mf = flopy.modflow.Modflow(\n",
    "    modelname=model_name, \n",
    "    model_ws=workspace, \n",
    "    exe_name=executable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782cbac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d9758d",
   "metadata": {},
   "source": [
    "## 2 Discretization (DIS) Package\n",
    "The DIS package defines the geometry and time discretization of a MODFLOW model. It tells MODFLOW how the model domain is divided into layers, rows, and columns, and how time is represented in stress periods.\n",
    "\n",
    "Key inputs are:  \n",
    "- Spatial discretization:  \n",
    "    - nlay, nrow, ncol – number of layers, rows, and columns.  \n",
    "    - delr, delc – cell sizes in the row and column directions.  \n",
    "    - top – array of top elevations of the model domain.  \n",
    "    - botm – arrays of bottom elevations for each layer.  \n",
    "- Temporal discretization:  \n",
    "    - nper – number of stress periods.  \n",
    "    - perlen – length of each stress period.  \n",
    "    - nstp – number of time steps per stress period.  \n",
    "    - tsmult – time step multiplier (controls time-step progression).  \n",
    "    - steady – flag indicating whether a period is steady-state or transient.  \n",
    "\n",
    "The DIS package is the foundation of the model: all other packages (boundary conditions, hydraulic properties, solute transport) build on the grid and time discretization it defines.\n",
    "\n",
    "### 2.1 Model Grid\n",
    "\n",
    "The first step is to define the spatial domain of our model. Based on our perceptual model, we will create a single-layer model. A single-layer model is a 2D model. This 2D model can still represent thickness and vertical flows. For this reason, people sometimes call it quasi-3D or 2.5D. \n",
    "\n",
    "We choose a grid size of 50 meters by 50 meters to start with. This means that each grid cell will represent a 50m x 50m area in the real world. This is a compromise between detail and computational efficiency. It will not allow us to capture small-scale features, but it will provide a good overview of the aquifer's behavior. We can refine the grid later in the modelling process if needed and we can assess the impact of the model resolution on the results in the sensitivity analysis.\n",
    "\n",
    "We start with an initial grid and then rotate it to align with the flow direction. This will help us reduce the number of model cells and speed up the model run time.\n",
    "\n",
    "#### 2.1.1 Data processing: Build the model grid\n",
    "This cell creates a simple, uniform structured grid aligned to the case-study boundary. It reads the boundary polygon, derives grid dimensions from a chosen cell size, and instantiates a FloPy `StructuredGrid` with a defined origin and an initial rotation (set to 0° here for a clean baseline). Use this as a starting point before refining rotation or replacing the dummy elevations.  \n",
    "\n",
    "- Inputs: `boundary_path` (GeoPackage/GeoJSON), `cell_size` (m)\n",
    "- Steps: (1) load boundary, (2) compute grid extent and `nrow`/`ncol`, (3) build uniform `delr`/`delc` and the grid,\n",
    "- Outputs: `modelgrid` (FloPy `StructuredGrid`) with origin, CRS, and rotation set,\n",
    "\n",
    "Note: Rotation is initially 0° to verify alignment. After inspection, update the angle (or use the rotation-iteration helper) and recompute the grid artifacts so downstream visualization, MODFLOW setup, and exports use the chosen rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Compute a structured grid aligned to the model boundary. \n",
    "# Inputs: \n",
    "# - Path to the model boundary polygon `boundary_path` (string)\n",
    "# - Desired cell size `cell_size` (float)\n",
    "# Steps:\n",
    "# 1. Get the model boundary polygon\n",
    "# 2. Compute the grid dimensions based on the boundary and cell size\n",
    "# 3. Create the structured grid\n",
    "# Outputs: \n",
    "# - Structured grid object `modelgrid` (FloPy StructuredGrid)\n",
    "\n",
    "# --- 0. Inputs --- \n",
    "# Path to the model boundary polygon\n",
    "boundary_path = download_named_file(\n",
    "    name='model_boundary',\n",
    "    data_type='gis'\n",
    ")\n",
    "\n",
    "# Desired cell size\n",
    "cell_size = 50  # meters\n",
    "\n",
    "# --- 1. Get the model boundary polygon --- \n",
    "gdf = gpd.read_file(boundary_path)\n",
    "\n",
    "# --- 2. Compute the grid dimensions based on the boundary and cell size ---\n",
    "# Get the bounding box of the geometry in your GeoPackage\n",
    "# Assuming you want to use the total bounds of all geometries in the GeoPackage\n",
    "xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "\n",
    "# Rotation of the grid to minimize the number of cells. The grid is rotated \n",
    "# around the lower left corner (xll, yll).\n",
    "rotation = 0  # degrees, let's first see how it looks without rotation.\n",
    "\n",
    "# Calculate number of rows and columns\n",
    "ncol = int(np.ceil((xmax - xmin) / cell_size))\n",
    "nrow = int(np.ceil((ymax - ymin) / cell_size))\n",
    "\n",
    "# Define delr and delc (cell widths along rows and columns)\n",
    "# Delr and delc are the widths of the grid cells in the x and y directions, respectively.\n",
    "# Here, we assume a uniform grid, so we can use the same cell size for all cells.\n",
    "# If you have varying cell sizes, you would need to define them accordingly.\n",
    "# For a non-uniform grid, you would typically provide arrays of varying sizes.\n",
    "# Here, we use np.full to create arrays filled with the cell_size value.\n",
    "# For a regular grid, these will be arrays of the cell_size\n",
    "delr = np.full(ncol, cell_size)\n",
    "delc = np.full(nrow, cell_size)\n",
    "\n",
    "# Define the origin of the grid (lower-left corner)\n",
    "# FloPy by default assumes the origin (xll, yll) is the lower-left corner\n",
    "xll = xmin\n",
    "yll = ymin\n",
    "\n",
    "# We define the number of layers in the model.\n",
    "nlay = 1\n",
    "\n",
    "# We use dummy data for the top and the bottom elevation for now. We'll replace \n",
    "# these with actual data later.\n",
    "top = np.ones((nrow, ncol)) * 100 # Dummy top elevation\n",
    "botm = np.ones((nlay, nrow, ncol)) * 50 # Dummy bottom elevation\n",
    "\n",
    "# Create the structured grid object\n",
    "# The StructuredGrid object is used to define the grid structure in FloPy.\n",
    "# Check out the documentation for more details: \n",
    "# https://flopy.readthedocs.io/en/stable/source/flopy.discretization.structuredgrid.html\n",
    "modelgrid = StructuredGrid(\n",
    "    delr=delr,\n",
    "    delc=delc,\n",
    "    top=top,\n",
    "    botm=botm,\n",
    "    xoff=xll,\n",
    "    yoff=yll,\n",
    "    angrot=rotation,\n",
    "    lenuni=2,  # Length unit code: 2 for meters\n",
    "    crs=gdf.crs.to_string() # Automatically get CRS from geopackage\n",
    ")\n",
    "print(\"Model grid created with the following parameters:\")\n",
    "print(modelgrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca541a6",
   "metadata": {},
   "source": [
    "#### 2.1.2 Visualization: Quick grid quality assessment\n",
    "Overlay the FloPy grid on the case-study boundary to verify extent, rotation, and coverage (Figure 1). Grid lines are drawn, and a legend highlights the boundary. The cell also prints the total number of model cells (nlay × nrow × ncol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: visually check extent, rotation, and active cells. \n",
    "# Inputs: \n",
    "# - modelgrid\n",
    "# - gdf\n",
    "# Plots: Boundary and grid overlay. \n",
    "# No side effects in this cell.\n",
    "\n",
    "# Plotting the grid \n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10)) # Adjusted figsize to be more square if needed\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax) # Pass ax directly\n",
    "pc = pmv.plot_array(modelgrid.top, alpha=0.5, cmap='terrain') # Added cmap for better visualization\n",
    "pmv.plot_grid()\n",
    "\n",
    "# Plot the GeoPackage boundary on top for verification\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "# Add a legend for the boundary\n",
    "boundary_legend = mlines.Line2D([], [], color='red', label='Model Boundary')\n",
    "ax.legend(handles=[boundary_legend], loc='upper right')\n",
    "\n",
    "ax.set_title(\"Figure 1: Initial FloPy Grid with GeoPackage Boundary (red).\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "plt.show()\n",
    "\n",
    "# Build grid polygons, tag active cells (≥50% inside), and get IBOUND\n",
    "grid_gdf, ibound = build_grid_gdf_and_ibound(\n",
    "    modelgrid=modelgrid,\n",
    "    boundary_gdf=gdf,        # your boundary GeoDataFrame\n",
    "    frac_threshold=0.5,      # change if needed\n",
    "    nlay=nlay                 # use your model's nlay\n",
    ")\n",
    "\n",
    "# Count the number of cells in the grid\n",
    "total_cells = ncol * nrow * nlay\n",
    "print(f\"Total number of cells in the grid: {total_cells}\")\n",
    "\n",
    "# Count the number of active cells\n",
    "active_cells = ibound[ibound > 0].sum()\n",
    "print(f\"Total number of active cells in the grid: {active_cells}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544731a3",
   "metadata": {},
   "source": [
    "Congratulation! You have successfully set up your first model grid and display it in Figure 1. The grid is a fundamental part of the model, as it defines the spatial resolution and extent of the simulation.  \n",
    "\n",
    "You will notice, that the main flow direction is diagonal to the cells orientation. There are a few reasons why this is sub-optimal: \n",
    "\n",
    "1. A diagonal flow direction can lead to *numerical dispersion* and other artifacts in the simulation results. As you might know from other lectures, the finite-difference method used in MODFLOW, calculates flow across the faces of the grid cells. It cannot directly compute flow diagonally across a single cell. Instead, it approximates a diagonal path as a series or orthogonal, \"stair-step\" movements from one cell to the next. We therefore try to allign the x-axis of the model grid along the main flow direction of a groundwater body. \n",
    "2. We also try to align the grid with major hydrogeological features and boundaries to avoid creating jagged, \"stair-step\" boundaries.\n",
    "3. Because Modflow2005 only includes active model cells (inside the model boundary) in the simulation, the number of active model cells matters. It is the most important factor in the model design that determines the computational speed of the simulation. \n",
    "\n",
    "#### 2.1.3 Typically necessary iterations \n",
    "Creating a model grid is rarely a one-shot process. After the first attempt, visualization often reveals mismatches that require adjustment. Common iterations include:\n",
    "\n",
    "- Rotation and alignment – adjusting the grid angle so that rows/columns follow the main axis of the model domain (e.g., a river valley).  \n",
    "- Extent and origin – shifting or expanding the grid so the boundary fits cleanly within the grid cells.  \n",
    "- Cell size – refining or coarsening resolution to balance accuracy with computational cost.\n",
    "\n",
    "Such iterations are a normal part of model development. We visualize, adjust parameters, and regenerate the grid until it represents the case study domain well enough for the next steps. Here, we demonstrate one such iteration: rotating the grid to better align with the flow direction and buffering the model boundary to ensure full coverage.\n",
    "\n",
    "##### Grid Rotation and Buffering\n",
    "We rotate the model grid to align it with the model boundary. We will also buffer the model boundary to ensure that the grid cells cover the entire area of interest. The easiest way to do that are by following the steps below, each step is accompanied by visual checks: \n",
    "1. Rotate the model boundary polygon to align with the main flow direction and major hydrogeological features. \n",
    "2. Buffer the rotated model boundary polygon to ensure that the grid cells cover the entire area of interest.\n",
    "3. Create a new grid based on the buffered polygon and apply the rotation to the structured grid.\n",
    "\n",
    "We start with the rotation of the model boundary polygon. It should be rotated to minimize the number of grid cells outside the model boundary. Optimally, the grid cells should be aligned with the main flow direction.  \n",
    "\n",
    "The rotation angle (variable `grid_rotation_angle` in code below) can be adjusted by trial and error to find the best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fb4aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Rotation of the model boundary --- \n",
    "# To generate a rotated grid in FloPy, the easiest way is to create a regular \n",
    "# grid and then apply a rotation transformation to it. \n",
    "# We first rotate the model boundary polygon to the desired angle. From there, \n",
    "# we can create a regular grid and then apply the rotation to the grid in the \n",
    "# structured grid object.\n",
    "# This approach allows us to maintain the integrity of the grid while applying\n",
    "# the desired rotation.\n",
    "# Every step includes visual checks.\n",
    "\n",
    "# Buffer the model boundary gdf\n",
    "gdf['geometry'] = gdf['geometry'].buffer(10)\n",
    "\n",
    "# Define the rotation angle in degrees\n",
    "grid_rotation_angle = 30  # degrees, identified by trial and error, you can adjust this angle to minimize the number of cells outside the boundary\n",
    "origin_rotation = Point(0, 0)  # Origin for rotation, can be adjusted as needed\n",
    "# Rotate the model boundary polygon\n",
    "gdf_rotated = gdf.copy()\n",
    "\n",
    "gdf_rotated['geometry'] = gdf_rotated['geometry'].apply(\n",
    "    lambda geom: rotate(geom, grid_rotation_angle, origin=origin_rotation)\n",
    ")\n",
    "# Get the bounding box of the rotated geometry\n",
    "xmin_rotated, ymin_rotated, xmax_rotated, ymax_rotated = gdf_rotated.total_bounds\n",
    "# Plot the rotated boundary to verify\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "gdf_rotated.plot(ax=ax, facecolor='none', edgecolor='blue', linewidth=2)\n",
    "ax.set_title(\"Figure 2: Rotated Model Boundary.\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f2518",
   "metadata": {},
   "source": [
    "Figure 2 shows the rotated model boundary. An angle of 30 degrees seems to be suitable for the Limmat Valley model. In the next step, we will create a new grid based on this rotated model boundary (see Figure 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Creation of a new Model Grid based on the rotated Model Boundary ---\n",
    "# We now have new bounding box coordinates for the rotated model boundary. \n",
    "# These we need to rotate back to the original coordinate system to create a\n",
    "# regular grid that fits the rotated boundary.\n",
    "# We use the rotated bounding box to define the grid dimensions.\n",
    "# Calculate the new grid dimensions based on the rotated bounding box\n",
    "width_rotated = xmax_rotated - xmin_rotated\n",
    "height_rotated = ymax_rotated - ymin_rotated\n",
    "\n",
    "# Calculate the number of rows and columns based on the rotated bounding box\n",
    "ncol_rotated = int(np.ceil(width_rotated / cell_size)) - 1 # Based on visual inspection of rotated grid.\n",
    "nrow_rotated = int(np.ceil(height_rotated / cell_size))\n",
    "\n",
    "# Compare number of rows and columns with the original grid\n",
    "print(f\"Original Grid: {ncol} columns, {nrow} rows\")\n",
    "print(f\"Rotated Grid: {ncol_rotated} columns, {nrow_rotated} rows\")\n",
    "\n",
    "# Define the delr and delc for the rotated grid\n",
    "delr_rotated = np.full(ncol_rotated, cell_size)\n",
    "delc_rotated = np.full(nrow_rotated, cell_size) \n",
    "\n",
    "# Plot the rotated grid and the rotated boundary to verify\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "# Create a new StructuredGrid with the rotated dimensions\n",
    "rotated_grid = StructuredGrid(\n",
    "    delr=delr_rotated,\n",
    "    delc=delc_rotated,\n",
    "    top=np.ones((nrow_rotated, ncol_rotated)) * 100,  # Example top elevation\n",
    "    botm=np.ones((nlay, nrow_rotated, ncol_rotated)) * 50,  # Example bottom elevation\n",
    "    xoff=xmin_rotated,  # Use the lower-left of the rotated extent\n",
    "    yoff=ymin_rotated,  # Use the lower-left of the rotated extent\n",
    "    angrot=0,  # We are currently in the rotated coordinate system, so no additional rotation is needed\n",
    "    lenuni=2,  # Length unit code: 2 for meters\n",
    "    crs=gdf_rotated.crs.to_string()  # Automatically get CRS from geopackage\n",
    ")\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=rotated_grid, ax=ax)\n",
    "pc = pmv.plot_array(rotated_grid.top, alpha=0.5, cmap='terrain')\n",
    "pmv.plot_grid()\n",
    "ax.set_aspect('equal', adjustable='box') # Ensure correct aspect ratio\n",
    "ax.set_title(\"Figure 3: Rotated FloPy Grid with Rotated Boundary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4dbd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Rotation of the new Model Grid in the CH Coordinate System ---\n",
    "# Now we need to rotate the lower-left corner of the rotated grid back to the \n",
    "# original coordinate system.\n",
    "# The lower-left corner of the rotated bounding box\n",
    "# Create points from the rotated bounding box coordinates\n",
    "min_point_rotated = Point(xmin_rotated, ymin_rotated)\n",
    "max_point_rotated = Point(xmax_rotated, ymax_rotated)\n",
    "\n",
    "# Apply inverse rotation (negative angle) around the same origin\n",
    "min_point_original = rotate(min_point_rotated, -grid_rotation_angle, \n",
    "                            origin=origin_rotation)\n",
    "max_point_original = rotate(max_point_rotated, -grid_rotation_angle, \n",
    "                            origin=origin_rotation)\n",
    "\n",
    "# Extract the coordinates\n",
    "xmin_original = min_point_original.x\n",
    "ymin_original = min_point_original.y\n",
    "xmax_original = max_point_original.x\n",
    "ymax_original = max_point_original.y\n",
    "\n",
    "print(f\"Original coordinates after inverse rotation:\")\n",
    "print(f\"xmin: {xmin_original:.2f}, ymin: {ymin_original:.2f}\")\n",
    "print(f\"xmax: {xmax_original:.2f}, ymax: {ymax_original:.2f}\")\n",
    "\n",
    "xll = xmin_original\n",
    "yll = ymin_original\n",
    "\n",
    "print(f\"Corrected grid lower-left corner:\")\n",
    "print(f\"xll = {xll:.2f}\")\n",
    "print(f\"yll = {yll:.2f}\")\n",
    "print(f\"Number of cells in the rotated grid: {nrow_rotated * ncol_rotated * nlay}\")\n",
    "print(f\"Number of cells in the original grid: {nrow * ncol * nlay}\")\n",
    "print(f\"The rotated grid has {round(((nrow * ncol * nlay) - (nrow_rotated * ncol_rotated * nlay))/(nrow * ncol * nlay)*100)} % less cells than the initial grid.\")\n",
    "\n",
    "# Update the top and bottom elevation arrays\n",
    "# For simplicity, we keep the dummy elevations. They are reset later.\n",
    "top = np.ones((nrow_rotated, ncol_rotated)) * 100  # Example top elevation\n",
    "botm = np.ones((nlay, nrow_rotated, ncol_rotated)) * 50  # Example bottom elevation\n",
    "\n",
    "# Create the FloPy structured grid with the rotated bounding box\n",
    "modelgrid = StructuredGrid(\n",
    "    delr=delr_rotated,\n",
    "    delc=delc_rotated,\n",
    "    top=top,\n",
    "    botm=botm,\n",
    "    xoff=xmin_original,  # Use the lower-left of the rotated extent\n",
    "    yoff=ymin_original,  # Use the lower-left of the rotated extent\n",
    "    angrot=-grid_rotation_angle,  # Apply the desired rotation to the grid\n",
    "    lenuni=2,  # Length unit code: 2 for meters\n",
    "    crs=gdf.crs.to_string()  # Automatically get CRS from geopackage\n",
    ")\n",
    "\n",
    "# Update grid polygons, tag active cells (≥50% inside), and get IBOUND\n",
    "grid_gdf, ibound = build_grid_gdf_and_ibound(\n",
    "    modelgrid=modelgrid,\n",
    "    boundary_gdf=gdf,        # your boundary GeoDataFrame\n",
    "    frac_threshold=0.5,      # change if needed\n",
    "    nlay=nlay                 # use your model's nlay\n",
    ")\n",
    "# Count the number of active cells\n",
    "active_cells = ibound[ibound > 0].sum()\n",
    "print(f\"Total number of active cells in the grid: {active_cells}\")\n",
    "\n",
    "print(\"Model grid created with the following parameters:\")\n",
    "print(modelgrid)\n",
    "# Add the modelgrid to the MODFLOW model\n",
    "mf.modelgrid = modelgrid\n",
    "\n",
    "# Plot the rotated grid and the model_boundary to check alignment\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mf.modelgrid, ax=ax)\n",
    "pc = pmv.plot_array(mf.modelgrid.top, alpha=0.5, cmap='terrain')\n",
    "pmv.plot_grid() \n",
    "\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Model Boundary')\n",
    "ax.legend(handles=[red_line], loc='upper right')\n",
    "ax.set_title(\"Figure 4: Correctly Rotated Grid with Model Boundaries\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "plt.show()\n",
    "ax.set_aspect('equal', adjustable='box') # Ensure correct aspect ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb5ef7",
   "metadata": {},
   "source": [
    "After rotating the grid, the number of cells increases slightly because the rotated extent no longer fits as tightly around the model boundary. We accept this trade-off, since aligning the grid with the main groundwater flow direction reduces numerical dispersion and improves the accuracy of simulated flow paths.\n",
    "\n",
    "You might wonder why we care about numerical dispersion, given the large uncertainties involved in groundwater flow modelling. Even though groundwater flow models involve many uncertainties (hydraulic properties, recharge estimates, boundary conditions), we still want to minimize numerical errors such as numerical dispersion. The reason is simple: uncertainties are part of the real system and can be reduced with better data or calibration, but numerical errors are artificial and only come from how we discretize and solve the equations.\n",
    "\n",
    "Numerical dispersion can smear sharp flow patterns, mix solutes unrealistically, or dampen hydraulic gradients. If we can reduce this error (e.g., by aligning the grid with the main flow direction), the model output better reflects the true hydrogeological processes, and we can focus on the real uncertainties that matter for decision-making.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c7101",
   "metadata": {},
   "source": [
    "#### 2.1.4 Save model grid for external use\n",
    "Let's export the model grid to a shapefile in case we want to use it for visualizations outside flopy. Visualizing it in a different context, e.g. in QGIS, is a good sanity check. This will help us to verify that the grid is correctly aligned with the model boundary and that the cells are not too large or too small (see Figure 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model grid to shapefile\n",
    "# Create a list to store grid cell polygons\n",
    "grid_cells = []\n",
    "\n",
    "# Get grid cell vertices using FloPy's grid functionality\n",
    "for i in range(modelgrid.nrow):\n",
    "    for j in range(modelgrid.ncol):\n",
    "        # Get cell vertices\n",
    "        cell_vertices = modelgrid.get_cell_vertices(i, j)\n",
    "        \n",
    "        # Create polygon from vertices\n",
    "        cell_polygon = Polygon(cell_vertices)\n",
    "        \n",
    "        # Store cell information\n",
    "        grid_cells.append({\n",
    "            'row': i,\n",
    "            'col': j,\n",
    "            'cell_id': f\"{i}_{j}\",\n",
    "            'geometry': cell_polygon,\n",
    "            'x': modelgrid.xcellcenters[i, j],\n",
    "            'y': modelgrid.ycellcenters[i, j]\n",
    "        })\n",
    "\n",
    "# Create GeoDataFrame\n",
    "grid_gdf = gpd.GeoDataFrame(grid_cells, crs=modelgrid.crs)\n",
    "\n",
    "# Export to GeoPackage\n",
    "grid_geopackage_path = os.path.join(workspace, 'model_grid.gpkg')\n",
    "grid_gdf.to_file(grid_geopackage_path, driver='GPKG', layer='model_grid')\n",
    "\n",
    "print(f\"Model grid exported to: {grid_geopackage_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(\n",
    "    image_filename='model_grid_on_openstreetmap.png', \n",
    "    image_folder='4_model_implementation',\n",
    "    caption='Figure 5: Model grid (grey) overlaid on OpenStreetMap background. The grid is rotated to minimize the number of cells while maintaining alignment with the model boundary (red). '\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551d7fb",
   "metadata": {},
   "source": [
    "We now have a regular grid that fits the rotated boundary. The grid is defined by its origin, the number of rows and columns, and the cell size. The grid is a fundamental part of the model, as it defines the spatial resolution and extent of the simulation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d271cb",
   "metadata": {},
   "source": [
    "> **Optional Challenge:**   \n",
    "> Try to find a better rotation angle by adjusting the `grid_rotation_angle` variable in the code above. You can also try to change the `cell_size` to see how it affects the number of cells inside the model boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e07d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29cb3f9",
   "metadata": {},
   "source": [
    "### 2.2 Model Top\n",
    "Now that we have the model grid, let's define the top of the model. The top of the model will be defined by the DEM, which we will use to create a single layer model. \n",
    "\n",
    "#### 2.2.1 Data processing: Resample DEM to model grid\n",
    "We derive the model top elevation from the DEM. These are the steps to achieve this:\n",
    "\n",
    "1. Resample the DEM to the model grid.\n",
    "2. Extract the elevation values at the model grid locations.\n",
    "3. Assign these values to the model top layer.\n",
    "\n",
    "Let's have a look at our DEM in the model area (Figure 6). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Inspect the DEM ---\n",
    "# Get the DEM data from the server\n",
    "dem_path = download_named_file(\n",
    "    name='dem',\n",
    "    data_type='gis'\n",
    ")\n",
    "\n",
    "# Load it into object rio\n",
    "rio = Raster.load(dem_path)\n",
    "\n",
    "# Get the DEM array and its valid index\n",
    "arr = rio.get_array(1)\n",
    "idx = np.isfinite(arr)\n",
    "\n",
    "# Get the min and max values for plotting\n",
    "vmin, vmax = arr[idx].min(), arr[idx].max()\n",
    "\n",
    "# Plot the DEM\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "ax = rio.plot(ax=ax, vmin=vmin, vmax=vmax)\n",
    "plt.colorbar(ax.images[0], shrink=0.7)\n",
    "# pmv.plot_grid(ax=ax, lw=0.5, color=\"white\")\n",
    "ax.set_title(\"Figure 6: DEM in original resolution in the model area.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53385c00",
   "metadata": {},
   "source": [
    "The resolution of the DEM does not match the model grid resolution, so we will resample the DEM to fit the model grid. We will use the `rio.resample_to_grid` function to resample the DEM to the model grid resolution. This will create a new raster that matches the model grid resolution and can be used as the model top (Figure 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff44a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Resample the DEM ---\n",
    "# Depending on the resolution of the DEM, resampling can be computationally \n",
    "# intensive.\n",
    "t0 = time.time() # To log the time it takes to resample the DEM\n",
    "model_top = rio.resample_to_grid(modelgrid, band=rio.bands[0], method=\"nearest\")\n",
    "resample_time = time.time() - t0\n",
    "\n",
    "# We round to 10 centimeters to avoid having to store too many digits\n",
    "model_top = np.round(model_top, 1)\n",
    "\n",
    "# Update vmin and vmax based on the resampled data\n",
    "vmin, vmax = model_top.min(), model_top.max()\n",
    "\n",
    "# Now to visualize using flopy and matplotlib\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "im = pmv.plot_array(model_top, masked_values=rio.nodatavals, vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Overlay the buffered model boundary with proper legend handling\n",
    "boundary_patch = gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "\n",
    "plt.title(f\"Resample time, nearest neighbor: {resample_time:.3f} sec\")\n",
    "plt.colorbar(im, shrink=0.7, label=\"Elevation (m a.s.l.)\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "\n",
    "# Create custom legend handle to avoid warnings\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Buffered Model Boundary')\n",
    "ax.legend(handles=[red_line])\n",
    "ax.set_title(\"Figure 7: Resampled DEM on Model Grid with Buffered Model Boundary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d216a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Save the model top layer to a file for later use\n",
    "# This step makes sense if resampling is slow. Instead of repeating the \n",
    "# resampling every time you run the notebook, you can just load the\n",
    "# precomputed file.\n",
    "top_file_path = os.path.join(workspace, 'model_top.npy')\n",
    "np.save(top_file_path, model_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bdb87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7da4d4",
   "metadata": {},
   "source": [
    "### 2.3 Model Bottom\n",
    "\n",
    "Next we tackle the bottom layer. The groundwater map of the canton of Zurich shows contour lines of the thickness of the aquifer for the deeper zones but for the shallower zones we see the range of the aquifer thickness. We calculate the bottom of the model by subtracting the aquifer thickness from the model top. \n",
    "\n",
    "$$ \\text{Bottom of the model} = \\text{Top of the model} - \\text{Aquifer thickness}$$\n",
    "\n",
    "We'll walk you through the steps to create the bottom layer of the model in the following code cells.\n",
    "\n",
    "#### 2.3.1 Data processing: Interpolate aquifer thickness to model grid\n",
    "We'll start by displaying the contours of aquifer thickness in the model area (Figure 8). This will help us visualize the aquifer thickness and understand how it varies across the model area. Please note that the aquifer thickness is very thin in parts of the model area. Cells in this region may run dry during the simulation, which is a common occurrence in groundwater models of shallow unconfined aquifers. By default, cells that run dry become impermeable in modflow but we can set rewetting parameters which allow the model to iteratively re-activate dry cells. This can, however, lead to numerical instability. We'll have to keep an eye on this during the simulation and adjust the model parameters for re-wetting if necessary. \n",
    "\n",
    "A summary of the steps:\n",
    "1. Visualize the aquifer thickness contours.\n",
    "2. Interpolate the aquifer thickness to the model grid.\n",
    "3. Subtract the aquifer thickness from the model top to obtain the model bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc573a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Visualize available aquifer bottom data ---\n",
    "# Load the polygon layers with information about aquifer thickness.\n",
    "gw_map_path = download_named_file(\n",
    "    name='groundwater_map_norm', \n",
    "    data_type='gis', \n",
    ")\n",
    "\n",
    "deep_contours_gdf = gpd.read_file(gw_map_path, layer=\"GS_GW_MAECHTIGKEIT_L\")\n",
    "shallow_gdf = gpd.read_file(gw_map_path, layer=\"GS_GW_LEITER_F\") \n",
    "\n",
    "# Reproject the GeoDataFrames to match the model grid CRS\n",
    "deep_contours_gdf = deep_contours_gdf.to_crs(modelgrid.crs)\n",
    "shallow_gdf = shallow_gdf.to_crs(modelgrid.crs)\n",
    "\n",
    "# For the deep contours, the aquifer thickness in meters is in the field \n",
    "# \"LABEL\". For the shallow contours, we have the field \"GWLTYP\" which corresponds \n",
    "# to a range of aquifer thickness. We have to manually assign a label attribute \n",
    "# here, using the GIS-Broswer as reference. \n",
    "# type_labels maps GWLTYP to the corresponding aquifer thickness in meters.\n",
    "type_labels = {\n",
    "        1: 2, \n",
    "        2: 2,\n",
    "        4: 10,\n",
    "        6: 20,\n",
    "    }\n",
    "# Create a new column 'aquifer_thickness' in shallow_gdf\n",
    "shallow_gdf['aquifer_thickness'] = shallow_gdf['GWLTYP'].map(type_labels)\n",
    "\n",
    "# Create a new column 'aquifer_thickness' in deep_contours_gdf\n",
    "deep_contours_gdf['aquifer_thickness'] = deep_contours_gdf['LABEL'].astype(float)\n",
    "\n",
    "# Discard rows in the shallow_gdf where aquifer_thickness is NaN\n",
    "shallow_gdf = shallow_gdf.dropna(subset=['aquifer_thickness'])\n",
    "\n",
    "# Now we need to make sure all shapes are available as lines. \n",
    "# Convert shallow polygons to contour lines by taking their boundaries\n",
    "shallow_contours_gdf = shallow_gdf.copy()\n",
    "shallow_contours_gdf.geometry = shallow_contours_gdf.geometry.boundary\n",
    "\n",
    "# Define the buffered model boundary as a contour with 5m thickness (2 meters \n",
    "# is very shallow and will quickly lead to cells drying).\n",
    "boundary_contour_gdf = gdf.copy()\n",
    "boundary_contour_gdf['aquifer_thickness'] = 5.0\n",
    "\n",
    "# View the first few rows of the deep contours and shallow contours\n",
    "# print(\"Deep contours (aquifer thickness in meters):\")\n",
    "# print(deep_contours_gdf[['LABEL', 'aquifer_thickness']].head())\n",
    "# print(\"\\nShallow contours (aquifer thickness in meters):\")\n",
    "# print(shallow_gdf[['GWLTYP', 'aquifer_thickness']].head())\n",
    "\n",
    "# Combine all contour dataframes into one\n",
    "# We select only the 'aquifer_thickness' and 'geometry' columns to ensure consistency\n",
    "all_contours_gdf = gpd.GeoDataFrame(\n",
    "    pd.concat([\n",
    "        deep_contours_gdf[['aquifer_thickness', 'geometry']],\n",
    "        shallow_contours_gdf[['aquifer_thickness', 'geometry']],\n",
    "        boundary_contour_gdf[['aquifer_thickness', 'geometry']]\n",
    "    ], ignore_index=True),\n",
    "    crs=gdf.crs\n",
    ")\n",
    "\n",
    "# Clip the contours to the model boundary polygon\n",
    "clipped_gdf = gpd.clip(all_contours_gdf, gdf)\n",
    "\n",
    "# Now we can plot the combined contours\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "clipped_gdf.plot(ax=ax, column='aquifer_thickness', cmap='viridis',\n",
    "                 legend=True, legend_kwds={'label': \"Aquifer Thickness (m)\"})\n",
    "ax.set_title(\"Figure 8: Contours of aquifer thickness in the model area.\")\n",
    "ax.set_xlabel(\"X-coordinate\")\n",
    "ax.set_ylabel(\"Y-coordinate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c507e7c",
   "metadata": {},
   "source": [
    "Now we need to subtract the aquifer thickness from the top of the model to define the bottom of the model. \n",
    "\n",
    "For this, we interpolate the contour lines of the aquifer thickness to the model grid (Figure 9). This will create a new raster that matches the model grid resolution which we can subtract from the top of the model to obtain the bottom elevation (Figure 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497fea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Interpolate the aquifer thickness on the model grid and calculate \n",
    "# aquifer thickness\n",
    "\n",
    "# ---    Interpolate aquifer thickness to model grid ---\n",
    "# Extract all points from the combined contour lines for interpolation\n",
    "points_for_interp = []\n",
    "for idx, row in clipped_gdf.iterrows():\n",
    "    if row.geometry is None or row.geometry.is_empty:\n",
    "        continue\n",
    "    if row.geometry.geom_type == 'MultiLineString':\n",
    "        for line in row.geometry.geoms:\n",
    "            for x, y in line.coords:\n",
    "                points_for_interp.append((x, y, row['aquifer_thickness']))\n",
    "    elif row.geometry.geom_type == 'LineString':\n",
    "        for x, y in row.geometry.coords:\n",
    "            points_for_interp.append((x, y, row['aquifer_thickness']))\n",
    "\n",
    "points_for_interp = np.array(points_for_interp)\n",
    "\n",
    "# --- PLOT: Points for Interpolation of Aquifer Thickness on Model Grid ---\n",
    "# Uncomment the following lines to visualize the points used for interpolation\n",
    "# fig, ax = plt.subplots(figsize=(12, 12))\n",
    "# sc = ax.scatter(points_for_interp[:, 0], points_for_interp[:, 1], c=points_for_interp[:, 2], cmap='viridis', s=5)\n",
    "# plt.colorbar(sc, label='Aquifer Thickness (m)')\n",
    "# ax.set_title(\"Step 1. Points from All Contours for Interpolation\")\n",
    "# ax.set_xlabel(\"X-coordinate\")\n",
    "# ax.set_ylabel(\"Y-coordinate\")\n",
    "# ax.set_aspect('equal', adjustable='box')\n",
    "# plt.show()\n",
    "\n",
    "# Interpolate directly onto the model grid cell centers\n",
    "grid_x, grid_y = modelgrid.xcellcenters, modelgrid.ycellcenters\n",
    "\n",
    "# First, use linear interpolation. This creates a smooth surface between contours.\n",
    "aquifer_thickness_linear = griddata(\n",
    "    points_for_interp[:, :2], \n",
    "    points_for_interp[:, 2],\n",
    "    (grid_x, grid_y), \n",
    "    method='linear'\n",
    ")\n",
    "\n",
    "# Linear interpolation leaves NaNs outside the convex hull of the data.\n",
    "# Second, fill these NaNs using nearest neighbor interpolation to cover the whole grid.\n",
    "nan_indices = np.isnan(aquifer_thickness_linear)\n",
    "aquifer_thickness_resampled = griddata(\n",
    "    points_for_interp[:, :2], \n",
    "    points_for_interp[:, 2],\n",
    "    (grid_x[nan_indices], grid_y[nan_indices]), \n",
    "    method='nearest'\n",
    ")\n",
    "aquifer_thickness_linear[nan_indices] = aquifer_thickness_resampled\n",
    "\n",
    "# The final resampled grid\n",
    "aquifer_thickness_resampled = aquifer_thickness_linear\n",
    "\n",
    "# Save aquifer thickness to a file for later use\n",
    "aquifer_thickness_file_path = os.path.join(workspace, 'aquifer_thickness.npy')\n",
    "np.save(aquifer_thickness_file_path, aquifer_thickness_resampled)\n",
    "\n",
    "# --- PLOT: Resampled Grid on Model Grid ---\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "im = pmv.plot_array(aquifer_thickness_resampled)\n",
    "plt.colorbar(im, shrink=0.7, label=\"Aquifer Thickness (m)\")\n",
    "ax.set_title(\"Figure 9: Aquifer thickness resampled to model grid.\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.show()\n",
    "\n",
    "# --- 3. Calculate the aquifer bottom ---\n",
    "# Subtract the aquifer thickness from the top of the model to define the bottom\n",
    "model_bottom = model_top - aquifer_thickness_resampled\n",
    "\n",
    "# Ensure the model bottom is a 3d array (nlay, nrow_rotated, ncol_rotated)\n",
    "if model_bottom.ndim == 2:\n",
    "    model_bottom = model_bottom[np.newaxis, :, :]  # Add a new axis for layers\n",
    "\n",
    "# --- PLOT: Final Aquifer Bottom ---\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "im = pmv.plot_array(model_bottom, vmin=np.nanmin(model_bottom), \n",
    "                    vmax=np.nanmax(model_bottom))\n",
    "plt.colorbar(im, shrink=0.7, label=\"Elevation (m a.s.l.)\")\n",
    "ax.set_title(\"Figure 10: Final aquifer bottom elevation. \")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "# Overlay the buffered model boundary with proper legend handling\n",
    "boundary_patch = gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "# Create custom legend handle to avoid warnings\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Buffered Model Boundary')\n",
    "ax.legend(handles=[red_line])\n",
    "ax.set_title(\"Figure 10: Resampled DEM on Model Grid with Buffered Model Boundary\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6afc17a",
   "metadata": {},
   "source": [
    "#### 2.3.2 Visual check of updated model grid\n",
    "Now we update the structured grid object by replacing the dummy model top in the model object with our resampled DEM. This will ensure that the model top reflects the actual topography of the Limmat Valley. We visualize the final model grid with the top elevation (Figure 11) for verification.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new model top and bottom to the modelgrid\n",
    "modelgrid = StructuredGrid(\n",
    "    delr=delr_rotated,\n",
    "    delc=delc_rotated,\n",
    "    top=model_top,\n",
    "    botm=model_bottom,\n",
    "    nlay=nlay,\n",
    "    xoff=xmin_original, # Use the lower-left of the rotated extent\n",
    "    yoff=ymin_original, # Use the lower-left of the rotated extent\n",
    "    angrot=-grid_rotation_angle, # Apply the desired rotation to the grid\n",
    "    lenuni=2,  # Length unit code: 2 for meters\n",
    "    crs=gdf.crs.to_string() # Automatically get CRS from geopackage\n",
    ")\n",
    "\n",
    "# Update the modelgrid in the MODFLOW model\n",
    "mf.modelgrid = modelgrid\n",
    "\n",
    "# Plot the mf modelgrid to verify\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mf.modelgrid, ax=ax)\n",
    "im = pmv.plot_array(mf.modelgrid.botm, vmin=np.nanmin(mf.modelgrid.botm), \n",
    "                    vmax=np.nanmax(mf.modelgrid.botm), cmap='terrain')\n",
    "plt.colorbar(im, shrink=0.7, label=\"Bottom Elevation (m a.s.l.)\")\n",
    "pmv.plot_grid()\n",
    "# Overlay the buffered model boundary with proper legend handling\n",
    "boundary_patch = gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "# Create custom legend handle to avoid warnings\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Buffered Model Boundary')\n",
    "ax.legend(handles=[red_line])\n",
    "\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.set_title(\"Figure 11: Final Model Grid with Bottom Elevation.\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b5021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882449c0",
   "metadata": {},
   "source": [
    "#### 2.4 Write the model geometry to DIS package\n",
    "Finally we save the model grid to the DIS package of our model. Please note that when defining the DIS package, we can also pass the temporal discretization parameters directly to the DIS package constructor (see code snippet below). We will start out with a steady state simulation, so we only need one stress period. If you have transient data, you would define multiple stress periods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ffabad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal discretization\n",
    "# We start out with a steady state simulation, so we only need one stress period.\n",
    "# If you have transient data, you would define multiple stress periods.\n",
    "# Here, we define a single stress period with a length of 1 day.\n",
    "# Please note that we hereby implicitly define the time unit of our model to be \n",
    "# days. We will need to be consistent with this throughout the model setup. \n",
    "nper = 1  # Number of stress periods\n",
    "perlen = [1.0]  # Length of each stress period in days\n",
    "nstp = [1.0]  # Number of time steps in each stress period (defaults to 1 for steady state) \n",
    "tsmult = [1.0]  # Time step multiplier (only used in transient simulations)\n",
    "steady = [True]  # Steady state flag for each stress period\n",
    "\n",
    "# Explicitly pass the grid parameters to the DIS package constructor.\n",
    "# This will correctly set the nrow, ncol, etc. on the mf object.\n",
    "dis = flopy.modflow.ModflowDis(\n",
    "    mf,\n",
    "    nlay=nlay,\n",
    "    nrow=nrow_rotated,\n",
    "    ncol=ncol_rotated,\n",
    "    delr=delr_rotated,\n",
    "    delc=delc_rotated,\n",
    "    top=model_top,\n",
    "    botm=model_bottom,\n",
    "    xoff=xmin_original,\n",
    "    yoff=ymin_original,\n",
    "    angrot=-grid_rotation_angle,\n",
    "    lenuni=2,\n",
    "    crs=gdf.crs.to_string(),  # Automatically get CRS from geopackage\n",
    "    nper=nper,\n",
    "    perlen=perlen,\n",
    "    nstp=nstp,\n",
    "    tsmult=tsmult,\n",
    "    steady=steady\n",
    ")\n",
    "\n",
    "# Save the model grid to a file for later use\n",
    "grid_file_path = os.path.join(workspace, 'model_grid.pkl')\n",
    "with open(grid_file_path, 'wb') as f:\n",
    "    pickle.dump(modelgrid, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf384efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbba56d4",
   "metadata": {},
   "source": [
    "## 3 Parameterization\n",
    "The discretized groundwater flow equation contains several parameters that need to be defined for the model. We use the layer-property flow package to specify these parameters.\n",
    "\n",
    "### 3.1 Layer-Property Flow (LPF) Package\n",
    "\n",
    "The Layer-Property Flow (LPF) Package is where we specify the hydraulic properties of the aquifer. These properties determine how easily water moves through the subsurface and how the aquifer stores and releases water.\n",
    "\n",
    "- **Hydraulic Conductivity (K)**: Since we don’t have site-specific measurements, we will begin with a uniform value of 10 m/d, which is typical for gravel aquifers (see Notebook 2). Later, during model calibration, we may divide the model into zones with different values of K to better represent aquifer heterogeneity.  \n",
    "- **Storage Properties**: For this first version of the model, we assume uniform values:\n",
    "    - Specific storage (Ss): $1 \\times 10^{-4} \\, \\text{m}^{-1}$ (represents elastic storage, important in confined conditions).  \n",
    "    - Specific yield (Sy): 0.15 (represents drainable porosity, dominant in unconfined conditions).  \n",
    "- **Hydraulic Conductivity Field**: With these settings, the model currently uses a single uniform conductivity field (Figure 13).  \n",
    "- **Wetting Parameters**: The LPF package also contains options for wetting parameters, which control how model cells that become dry can re-wet during transient simulations. For simple steady-state or basic transient models these are not strictly necessary, but they become important in more advanced models that include significant water table fluctuations.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c473974",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting up Layer Properties (LPF) Package with uniform values...\")\n",
    "\n",
    "# Uniform hydraulic conductivity values\n",
    "# Typical for sandy gravel aquifers in Swiss valleys\n",
    "hk_uniform = 10.0  # m/day - horizontal hydraulic conductivity\n",
    "vk_uniform = 1.0   # m/day - vertical hydraulic conductivity (typically Kh/10)\n",
    "\n",
    "# Create uniform K arrays\n",
    "hk = np.ones((nlay, nrow_rotated, ncol_rotated)) * hk_uniform\n",
    "vk = np.ones((nlay, nrow_rotated, ncol_rotated)) * vk_uniform\n",
    "\n",
    "# Storage properties (uniform)\n",
    "sy = 0.15  # Specific yield (typical for unconfined sandy gravel aquifers)\n",
    "ss = 1e-4  # Specific storage (1/m) (typical value)\n",
    "\n",
    "# Layer type (0 = confined, 1 = convertible/unconfined)\n",
    "# Limmat valley aquifer is unconfined\n",
    "laytyp = 1\n",
    "\n",
    "# Create the LPF package\n",
    "lpf = flopy.modflow.ModflowLpf(\n",
    "    mf,\n",
    "    hk=hk,                  # Horizontal hydraulic conductivity\n",
    "    vka=vk,                 # Vertical hydraulic conductivity\n",
    "    sy=sy,                  # Specific yield\n",
    "    ss=ss,                  # Specific storage\n",
    "    laytyp=laytyp,          # Layer type (1 = convertible/unconfined)\n",
    "    ipakcb=53,              # Unit number for cell-by-cell budget file\n",
    "    hdry=-999.99,           # Head assigned to dry cells\n",
    "    wetfct=0.2,             # Wetting factor\n",
    "    iwetit=2,               # Wetting iteration interval (outer iteration)\n",
    "    laywet=1,                # Flag indicating if wetting is active for each layer\n",
    "    wetdry=0.01              # Threshold for wetting (fraction of cell thickness)\n",
    ")\n",
    "\n",
    "print(\"\\nLPF package created successfully with uniform properties:\")\n",
    "print(f\"Horizontal hydraulic conductivity: {hk_uniform} m/day\")\n",
    "print(f\"Vertical hydraulic conductivity: {vk_uniform} m/day\")\n",
    "print(f\"Specific yield: {sy}\")\n",
    "print(f\"Specific storage: {ss} 1/m\")\n",
    "print(f\"Layer type: {'Convertible (unconfined)' if laytyp == 1 else 'Confined'}\")\n",
    "\n",
    "# Quick visualization of the uniform K field\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(16, 6))\n",
    "\n",
    "# Plot horizontal K\n",
    "pmv1 = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax1)\n",
    "im1 = pmv1.plot_array(hk[0], masked_values=[0])\n",
    "#pmv1.plot_inactive(ibound[0], color='gray', alpha=0.8)\n",
    "pmv1.plot_grid(alpha=0.3, linewidth=0.5)\n",
    "gdf.plot(ax=ax1, facecolor='none', edgecolor='red', linewidth=2)\n",
    "cb1 = plt.colorbar(im1, ax=ax1, shrink=0.7)\n",
    "cb1.set_label(\"Horizontal K (m/day)\")\n",
    "ax1.set_title(f\"Figure 13: Initial horizontal hydraulic conductivity (uniform = {hk_uniform} m/day)\")\n",
    "ax1.set_xlabel(\"X-coordinate (m)\")\n",
    "ax1.set_ylabel(\"Y-coordinate (m)\")\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the uniform K field for reference\n",
    "np.save(os.path.join(workspace, 'uniform_hk_field.npy'), hk)\n",
    "np.save(os.path.join(workspace, 'uniform_vk_field.npy'), vk)\n",
    "print(f\"\\nUniform K fields saved to {workspace}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a50d1a",
   "metadata": {},
   "source": [
    "#### 3.2 A note on assigning Parameter Fields\n",
    "In our first model setup, we use uniform parameter values (e.g., one hydraulic conductivity and storage value for the entire aquifer). This is a common starting point because it keeps the model simple and easy to interpret.\n",
    "\n",
    "In practice, however, parameter fields are rarely uniform. If measurements or maps are available, we can use different approaches to assign more realistic values:\n",
    "\n",
    "- Zonation – divide the model into regions (zones) where each zone has its own parameter value (e.g., sand vs. clay areas).\n",
    "\n",
    "- Interpolation (e.g., kriging, IDW) – use point measurements (e.g., from wells) to interpolate continuous parameter fields across the model grid.\n",
    "\n",
    "- Geostatistical/simulation methods – generate stochastic parameter fields that honor both measurements and spatial variability.\n",
    "\n",
    "- Pilot points / parameter estimation – assign parameters at selected control points and let calibration tools adjust them to fit observed data.\n",
    "\n",
    "👉 The choice depends on data availability, model purpose, and computational cost. For teaching, we start simple with uniform values, and later explore how to refine parameter distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b0eda",
   "metadata": {},
   "source": [
    "## 4 Boundary & Initial Conditions\n",
    "Now that we have the model geometry and parameterization defined, we need to establish the boundary and initial conditions for the simulation. These correspond to the arrows in the perceptual model figure we discussed in Notebook 2, describing fluxes in and out of the model. \n",
    "\n",
    "### 4.1 Active Cells - Basic Package (BAS) \n",
    "\n",
    "The BAS package has the following responsibilities: \n",
    "- *Initial heads*: Starting conditions for the solver.\n",
    "- *IBOUND array*: Defines the active/inactive status of each cell.\n",
    "    - IBOUND > 0: Active cell\n",
    "    - IBOUND = 0: Inactive cell\n",
    "    - IBOUND < 0: Fixed-head cell\n",
    "\n",
    "We'll assume all cells within the aquifer boundary are active and that the initial head lies at 1 meter below the ground surface. \n",
    "\n",
    "Please follow the steps in the code cell below to create the Basic Package.\n",
    "\n",
    "#### 4.1.1 Identify Active Cells\n",
    "Modflow only solves the flow equation for active cells (IBOUND > 0). We need to create the IBOUND array based on the active cells identified in the model grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f566322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Data processing ---\n",
    "# Goal: Create IBOUND array to define active/inactive cells\n",
    "# Note: Active cells (1) are inside the model boundary, inactive cells (0) are \n",
    "# outside\n",
    "# Steps: \n",
    "# 1. Create an empty IBOUND array with all cells inactive (0)\n",
    "# 2. Use the original model boundary (not buffered) for IBOUND\n",
    "# 3. Assign active cells (1) based on the intersection with the boundary\n",
    "\n",
    "# Initialize IBOUND array with all cells inactive (0)\n",
    "ibound = np.zeros((nlay, nrow_rotated, ncol_rotated), dtype=int)\n",
    "\n",
    "# Using GridIntersect (recommended for complex boundaries and rotated grids)\n",
    "# Create a GridIntersect object\n",
    "ix = GridIntersect(modelgrid, method='vertex', rtree=True)\n",
    "\n",
    "# Get the intersection between the grid and the boundary polygon\n",
    "# This returns the cells that intersect with the polygon\n",
    "try:\n",
    "    result = ix.intersect(gdf.geometry.union_all())\n",
    "    \n",
    "    # Extract the row and column indices of cells inside the boundary\n",
    "    for idx, row in result.iterrows():\n",
    "        ibound[0, row['row'], row['col']] = 1\n",
    "        \n",
    "    print(\"Successfully created IBOUND using GridIntersect method\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"GridIntersect method failed: {e}\")\n",
    "    print(\"Falling back to cell center method...\")\n",
    "    \n",
    "    # Fallback Method: Using cell centers\n",
    "    # Get cell centers\n",
    "    xcenters = modelgrid.xcellcenters\n",
    "    ycenters = modelgrid.ycellcenters\n",
    "    \n",
    "    # Get the boundary polygon\n",
    "    boundary_polygon = gdf.geometry.union_all()\n",
    "    \n",
    "    # Check which cell centers are inside the boundary polygon\n",
    "    for i in range(nrow_rotated):\n",
    "        for j in range(ncol_rotated):\n",
    "            point = Point(xcenters[i, j], ycenters[i, j])\n",
    "            if boundary_polygon.contains(point):\n",
    "                ibound[0, i, j] = 1\n",
    "\n",
    "# Count active and inactive cells\n",
    "active_cells = np.sum(ibound == 1)\n",
    "inactive_cells = np.sum(ibound == 0)\n",
    "print(f\"\\nInitial IBOUND statistics:\")\n",
    "print(f\"Active cells: {active_cells}\")\n",
    "print(f\"Inactive cells: {inactive_cells}\")\n",
    "print(f\"Total cells: {active_cells + inactive_cells}\")\n",
    "print(f\"Percentage active: {active_cells / (active_cells + inactive_cells) * 100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bcbc0a",
   "metadata": {},
   "source": [
    "#### 4.1.2 Visualize IBOUND Array\n",
    "We visually check if the IBOUND array correctly represents the model domain by overlaying it on the aquifer thickness map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Visualization of IBOUND ---\n",
    "# Plot IBOUND array with custom colormap\n",
    "# Define discrete colormap: order must match categories [-1, 0, 1]\n",
    "# Colors: CHD = orange, Inactive = white, Active = blue\n",
    "cmap = mcolors.ListedColormap([\n",
    "    \"#1f77b4\",  # -1 CHD\n",
    "    \"#111111\",  # 0 inactive\n",
    "    \"#ffffff\"   # 1 active\n",
    "])\n",
    "# Boundaries define bins for the 3 categories\n",
    "bounds = [-1.5, -0.5, 0.5, 1.5]\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "im = pmv.plot_array(ibound[0], cmap=cmap, norm=norm)\n",
    "\n",
    "pmv.plot_grid(alpha=0.3, linewidth=0.5)\n",
    "\n",
    "# Overlay the original boundary for verification\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=1)\n",
    "\n",
    "# Colorbar with custom ticks & labels\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.7, ticks=[-1, 0, 1])\n",
    "cbar.ax.set_yticklabels([\"CHD (-1) (yet to be defined)\", \"Inactive (0)\", \"Active (1)\"])\n",
    "cbar.set_label(\"IBOUND code\")\n",
    "\n",
    "ax.set_title(f\"Figure 12: IBOUND array displaying active (white) and inactive (black) cells.\")\n",
    "ax.set_xlabel(\"X-coordinate (m)\")\n",
    "ax.set_ylabel(\"Y-coordinate (m)\")\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Create custom legend handles to avoid warnings\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Model Boundary')\n",
    "ax.legend(handles=[red_line])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5c762",
   "metadata": {},
   "source": [
    "We will write the IBOUND array once we have defined the constant head boundaries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97eae08",
   "metadata": {},
   "source": [
    "#### 4.1.5 Identify Constant Head Cells\n",
    "Oh, but we are not done yet! In MODFLOW, we have to assign IBOUND=-1 to the outflow cells along the western boundary.\n",
    "\n",
    "The most straight forward way to select the cells with constant head is to load the IBOUND shape in QGIS and select the cells along the western boundary. See printscreen of QGIS in Figure 14. The selected features can then be exported as a shapefile and loaded into the notebook. The code below shows how to create the constant head boundary condition based on the selected cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(\n",
    "    image_filename='selection_of_cells_for_chd_boundary_qgis.png', \n",
    "    image_folder='4_model_implementation',\n",
    "    caption='Figure 14: Active cells of IBOUND layer in semi-transparent red. Background layer: OpenStreetMap. The orange cells indicate the selection of cells for the constant head boundary condition (CHD).'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab2395a",
   "metadata": {},
   "source": [
    "#### 4.1.4 Add Constant Head Cells to IBOUND and write to BAS Package\n",
    "Then, we load the cell selection to define the IBOUND cells we have to set to -1 (and visually check if the IBOUND cells are correctly identified, Figure 15). For these same cells, we later assign a constant head boundary condition with the CHD package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cell selection for the constant head boundary. \n",
    "chd_cells_path = download_named_file(\n",
    "    name='chd_cells', \n",
    "    data_type='limmat_valley_model'\n",
    ")\n",
    "\n",
    "# Load CHD selection layer (assumes it only contains desired CHD cells)\n",
    "chd_sel = gpd.read_file(chd_cells_path)\n",
    "chd_sel = chd_sel.to_crs(modelgrid.crs)\n",
    "\n",
    "# Get ibound array to dataframe format\n",
    "# Create GeoDataFrame\n",
    "ibound_cells = []\n",
    "for i in range(nrow_rotated):\n",
    "    for j in range(ncol_rotated):\n",
    "        cell_polygon = modelgrid.get_cell_vertices(i, j)\n",
    "        ibound_cells.append({\n",
    "            'row': i,\n",
    "            'col': j,\n",
    "            'cell_id': f\"{i}_{j}\",\n",
    "            'geometry': Polygon(cell_polygon),\n",
    "            'ibound': int(ibound[0, i, j]),\n",
    "            'x': modelgrid.xcellcenters[i, j],\n",
    "            'y': modelgrid.ycellcenters[i, j]\n",
    "        })  \n",
    "ibound_gdf = gpd.GeoDataFrame(ibound_cells, crs=modelgrid.crs)  \n",
    "\n",
    "# Ensure required columns\n",
    "required_cols = {'cell_id', 'row', 'col'}\n",
    "missing = required_cols - set(ibound_gdf.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"ibound_gdf is missing required columns: {missing}\")\n",
    "\n",
    "if 'cell_id' not in chd_sel.columns:\n",
    "    raise ValueError(\"CHD selection layer lacks 'cell_id'. Add it (e.g., from IBOUND export) and retry.\")\n",
    "\n",
    "# Normalize cell_id\n",
    "chd_sel['cell_id'] = chd_sel['cell_id'].astype(str).str.strip()\n",
    "ibound_gdf['cell_id'] = ibound_gdf['cell_id'].astype(str).str.strip()\n",
    "\n",
    "# Join on cell_id\n",
    "chd_join = chd_sel.merge(\n",
    "    ibound_gdf[['cell_id']],\n",
    "    on='cell_id',\n",
    "    how='inner',\n",
    "    validate='1:1'\n",
    ")\n",
    "\n",
    "if chd_join.empty:\n",
    "    raise ValueError(\"No matching cell_id between CHD layer and ibound_gdf.\")\n",
    "\n",
    "# Vector filter to active cells\n",
    "rows = chd_join['row'].astype(int).to_numpy()\n",
    "cols = chd_join['col'].astype(int).to_numpy()\n",
    "active_mask = ibound[0, rows, cols] == 1\n",
    "chd_active = chd_join.loc[active_mask].drop_duplicates(subset=['row', 'col'])\n",
    "\n",
    "if chd_active.empty:\n",
    "    raise ValueError(\"Selected CHD cells are not active (ibound==1).\")\n",
    "\n",
    "# Assign constant head value\n",
    "const_head_value = 390.0\n",
    "\n",
    "# Set ibound to -1 for CHD cells\n",
    "for r, c in zip(chd_active['row'].astype(int), chd_active['col'].astype(int)):\n",
    "    ibound[0, r, c] = -1\n",
    "\n",
    "# Update BAS package with modified ibound (recreate to be safe)\n",
    "bas = flopy.modflow.ModflowBas(\n",
    "    mf,\n",
    "    ibound=ibound,\n",
    "    strt=model_top,\n",
    "    hnoflo=-999.99\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2454e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ibound to see if constant head cells are correctly identified\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mf.modelgrid, ax=ax)\n",
    "pmv.plot_ibound()\n",
    "ax.set_title(f\"Figure 15: IBOUND array displaying active (white) and inactive (black) cells, and constant head cells (blue).\")\n",
    "ax.set_xlabel(\"X-coordinate (m)\")\n",
    "ax.set_ylabel(\"Y-coordinate (m)\")\n",
    "ax.set_aspect('equal', adjustable='box')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3a4da",
   "metadata": {},
   "source": [
    "#### 4.1.5 Export IBOUND Array\n",
    "Finally, we export the IBOUND array to a binary file (as a backup) and to a geopackage so we can later use it in GIS applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18f3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Export IBOUND array ---\n",
    "# Save the ibound array to a file for later use\n",
    "ibound_file_path = os.path.join(workspace, 'ibound.npy')\n",
    "np.save(ibound_file_path, ibound)\n",
    "\n",
    "# Save the ibound array to a GeoDataFrame for visualization\n",
    "ibound_cells = []\n",
    "for i in range(nrow_rotated):\n",
    "    for j in range(ncol_rotated):\n",
    "        cell_polygon = modelgrid.get_cell_vertices(i, j)\n",
    "        ibound_cells.append({\n",
    "            'row': i,\n",
    "            'col': j,\n",
    "            'cell_id': f\"{i}_{j}\",\n",
    "            'geometry': Polygon(cell_polygon),\n",
    "            'ibound': int(ibound[0, i, j]),\n",
    "            'x': modelgrid.xcellcenters[i, j],\n",
    "            'y': modelgrid.ycellcenters[i, j]\n",
    "        })  \n",
    "# Create GeoDataFrame\n",
    "ibound_gdf = gpd.GeoDataFrame(ibound_cells, crs=modelgrid.crs)  \n",
    "# Export to GeoPackage\n",
    "ibound_geopackage_path = os.path.join(workspace, 'ibound.gpkg')\n",
    "ibound_gdf.to_file(ibound_geopackage_path, driver='GPKG', layer='ibound')\n",
    "\n",
    "print(f\"IBOUND array exported to: {ibound_geopackage_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1442a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb7e7d",
   "metadata": {},
   "source": [
    "### 4.2 Lateral outflow - Constant head (CHD) Package \n",
    "The Constant Head (CHD) Package is used to fix hydraulic head values at selected cells in the model. These cells act as boundaries where groundwater can freely flow in or out, depending on the head gradient between the fixed boundary and the interior of the model.\n",
    "\n",
    "**How it works**:\n",
    "- The model keeps the specified head constant during the simulation.\n",
    "- Water can leave (outflow) or enter (inflow) the model through these cells.\n",
    "- The amount of flow is calculated by MODFLOW based on the head difference with neighboring cells and the conductance between them.\n",
    "\n",
    "**Why we use it here**:\n",
    "In our model, we apply a CHD boundary at the outflow of the aquifer. This ensures that groundwater can discharge naturally from the system while keeping the downstream head fixed at a realistic value.\n",
    "\n",
    "👉 In practice: the CHD boundary represents a “hydraulic sink or source” that keeps the system open and allows water to move across the model boundary in a controlled way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21123ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CHD stress period data\n",
    "# Create list of constant head cells in the format required by FloPy\n",
    "chd_cells = [\n",
    "    [0, int(r), int(c), const_head_value, const_head_value]\n",
    "    for r, c in zip(chd_active['row'], chd_active['col'])\n",
    "]\n",
    "\n",
    "print(f\"Number of CHD cells (from selection layer): {len(chd_cells)}\")\n",
    "\n",
    "# Build stress period data for constant head\n",
    "chd = flopy.modflow.ModflowChd(\n",
    "    mf,\n",
    "    stress_period_data={0: chd_cells},\n",
    ")\n",
    "\n",
    "print(\"\\nConstant head boundary package created with constant heads:\")\n",
    "print(f\"Constant head value: {const_head_value} m\")\n",
    "\n",
    "# Visual check of constant head boundaries in the context of the model geometry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196aadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-D visualization of model top, bottom, and CHD boundary heads (active domain only)\n",
    "fig = plot_interactive_model_domain_3d(\n",
    "    mf, bas=bas, chd=chd, engine=\"plotly\", exaggeration=20.0, \n",
    "    custom_title=\"Figure 15: 3D Model Domain Visualization.\"\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5854286",
   "metadata": {},
   "source": [
    "In Figure 15, you can see the constant head boundary cells in blue. The cells are set to a fixed head value of 390 m a.s.l. as suggested by the groundwater map of the Canton of Zurich.  \n",
    "\n",
    "We further see that the CHD boundary is not consistent with the model bottom we derived based on the geological information and the groundwater map. We have to further lower the bottom elevation near the outflow boundary. We might further want to raise the CHD bounday in the north of the river Limmat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deepen shallow cells: ensure any cell with thickness < 5 m is deepened so thickness >= target_thickness.\n",
    "# New bottom = min(current bottom, model_top_hres - target_thickness)\n",
    "# Then rebuild DIS and adjust starting heads if needed.\n",
    "\n",
    "import numpy as np\n",
    "import flopy\n",
    "import pandas as pd\n",
    "\n",
    "# --- Parameters ---\n",
    "min_current_thickness = 5.0    # threshold to trigger deepening\n",
    "target_thickness = 7.0        # enforce this thickness when deepening\n",
    "start_head_clearance = 1.0     # ensure starting head >= bottom + clearance\n",
    "layer = 0                      # target layer (assuming single-layer model)\n",
    "\n",
    "# --- Inputs / availability checks ---\n",
    "if 'mf' not in globals() or not hasattr(mf, 'dis'):\n",
    "    raise RuntimeError(\"Model or DIS package not found.\")\n",
    "if 'bas' not in globals():\n",
    "    raise RuntimeError(\"BAS package required.\")\n",
    "\n",
    "top_ref = mf.dis.top.array.copy()\n",
    "botm_all = mf.dis.botm.array.copy()  # (nlay, nrow, ncol)\n",
    "top_dis = mf.dis.top.array.copy()\n",
    "botm = botm_all[layer]\n",
    "\n",
    "if top_ref.shape != top_dis.shape:\n",
    "    raise ValueError(\"model_top_hres (or chosen top_ref) shape mismatch with model top.\")\n",
    "\n",
    "thickness = top_dis - botm\n",
    "shallow_mask = thickness < min_current_thickness\n",
    "\n",
    "# Compute desired new bottom for shallow cells\n",
    "desired_bottom = top_ref - target_thickness\n",
    "\n",
    "# New bottom rule: only deepen (i.e. lower) shallow cells\n",
    "new_botm = botm.copy()\n",
    "# For cells flagged as shallow: new bottom = min(current bottom, desired_bottom)\n",
    "to_change = shallow_mask & (desired_bottom < botm)\n",
    "new_botm[to_change] = desired_bottom[to_change]\n",
    "\n",
    "num_changed = int(np.count_nonzero(botm != new_botm))\n",
    "\n",
    "print(f\"Cells initially shallower than {min_current_thickness} m: {int(np.count_nonzero(shallow_mask))}\")\n",
    "print(f\"Cells actually deepened to reach ≥ {target_thickness} m thickness: {num_changed}\")\n",
    "\n",
    "# Store changes for reporting\n",
    "changed_idx = np.argwhere(botm != new_botm)\n",
    "if changed_idx.size:\n",
    "    change_records = []\n",
    "    for (i, j) in changed_idx[:500]:  # cap preview\n",
    "        change_records.append({\n",
    "            \"row\": i+1,\n",
    "            \"col\": j+1,\n",
    "            \"old_bot\": botm[i, j],\n",
    "            \"new_bot\": new_botm[i, j],\n",
    "            \"old_thk\": thickness[i, j],\n",
    "            \"new_thk\": top_dis[i, j] - new_botm[i, j]\n",
    "        })\n",
    "    df_changes = pd.DataFrame(change_records)\n",
    "    #display(df_changes.head(15))\n",
    "    if len(change_records) > 500:\n",
    "        print(\"... (truncated list)\")\n",
    "\n",
    "# Update botm array\n",
    "botm_all[layer] = new_botm\n",
    "\n",
    "# Rebuild DIS (preserve temporal settings and any rotation/xul if present)\n",
    "old_dis = mf.dis\n",
    "dis_kwargs = dict(\n",
    "    nlay=old_dis.nlay,\n",
    "    nrow=old_dis.nrow,\n",
    "    ncol=old_dis.ncol,\n",
    "    delr=old_dis.delr.array,\n",
    "    delc=old_dis.delc.array,\n",
    "    top=top_dis,\n",
    "    botm=botm_all,\n",
    "    nper=old_dis.nper,\n",
    "    perlen=old_dis.perlen.array,\n",
    "    nstp=old_dis.nstp.array,\n",
    "    tsmult=old_dis.tsmult.array,\n",
    "    steady=old_dis.steady.array\n",
    ")\n",
    "# include optional spatial metadata if present\n",
    "for attr in (\"xul\", \"yul\", \"rotation\", \"lenuni\"):\n",
    "    if hasattr(old_dis, attr):\n",
    "        dis_kwargs[attr] = getattr(old_dis, attr)\n",
    "\n",
    "mf.remove_package('DIS')\n",
    "dis = flopy.modflow.ModflowDis(mf, **dis_kwargs)\n",
    "print(\"DIS rebuilt with updated bottom elevations.\")\n",
    "\n",
    "# Adjust starting heads if below (new bottom + clearance)\n",
    "strt = bas.strt.array\n",
    "if strt.ndim == 2:\n",
    "    strt = strt[np.newaxis, ...]\n",
    "bottom_layer = botm_all[layer]\n",
    "adj_mask = strt[layer] < (bottom_layer + start_head_clearance)\n",
    "n_adj = int(np.count_nonzero(adj_mask))\n",
    "if n_adj:\n",
    "    strt[layer][adj_mask] = bottom_layer[adj_mask] + start_head_clearance\n",
    "    print(f\"Raised {n_adj} starting head cell(s) to maintain clearance above deepened bottom.\")\n",
    "\n",
    "# Rebuild BAS with updated start heads\n",
    "ibound = bas.ibound.array\n",
    "mf.remove_package('BAS6')\n",
    "bas = flopy.modflow.ModflowBas(mf, ibound=ibound, strt=strt, hnoflo=-999.99)\n",
    "print(\"BAS updated.\")\n",
    "\n",
    "# Write inputs\n",
    "mf.write_input()\n",
    "print(\"Model inputs written. You can now re-run the simulation.\")\n",
    "\n",
    "# Quick summary statistics\n",
    "final_thickness = top_dis - new_botm\n",
    "print(f\"New min thickness: {np.nanmin(final_thickness):.2f} m | \"\n",
    "      f\"Mean thickness: {np.nanmean(final_thickness):.2f} m | \"\n",
    "      f\"Max thickness: {np.nanmax(final_thickness):.2f} m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d006b9",
   "metadata": {},
   "source": [
    "We check if the CHD boundary is now consistent with the new bottom layer elevations in Figure 16. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79997cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-D visualization of model top, bottom, and CHD boundary heads (active domain only)\n",
    "fig = plot_interactive_model_domain_3d(\n",
    "    mf, bas=bas, chd=chd, engine=\"plotly\", exaggeration=20.0, \n",
    "    custom_title=\"Figure 16: 3D Model Domain Visualization with Increased Model Depth.\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250fcb11",
   "metadata": {},
   "source": [
    "The model geometry is now consistent with the CHD boundary. We move on to the next boundary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d7865",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(4, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c27f72",
   "metadata": {},
   "source": [
    "### 4.3 Net Areal Recharge (RCH Package)\n",
    "\n",
    "Next, we tackle the **recharge from the top**: In the perceptual model chapter, we found that about 110 mm/year of net recharge is expected in the Limmat Valley. We will implement this as a uniform recharge across the model area. We defined the stress period length as 1 day, so we need to convert the annual recharge rate to a daily recharge rate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16094b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average net recharge value for the Limmat valley: 110 mm/year\n",
    "rech_value = 0.110 / 365.25  # m/day\n",
    "rech_array = np.full((nrow_rotated, ncol_rotated), rech_value, dtype=float)\n",
    "\n",
    "rch = flopy.modflow.ModflowRch(\n",
    "    mf, \n",
    "    rech=rech_array, \n",
    "    nrchop=3  # apply recharge to highest active cell in column\n",
    ")\n",
    "\n",
    "print(\"\\nAreal recharge package created with constant rate:\")\n",
    "print(f\"Recharge value: {rech_value:.6f} m/day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c6ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49da04a9",
   "metadata": {},
   "source": [
    "### 4.4 River Interaction (RIV Package)\n",
    "\n",
    "Now we implement the river. We go for the RIV Package which is used to represent several conditions of loosing and gaining, connected and disconnected streams that are often present in shallow river-valley aquifers.\n",
    "\n",
    "First, we get the river layer by the Canton of Zurich. we only keep the river layers in the model domain. We further discard the smaller rivers because we do not have any information about them and we assume that they are not contributing significantly to the groundwater flow in the Limmat Valley (see Figure 17). \n",
    "\n",
    "We'll further have to estimate a bottom elevation of the river as river profiles are not publicly available. We will linearly interpolate the river bottom elevation based an assumed average river depth for each river. \n",
    "\n",
    "Please note that in a paid project, you would optimally get access to more detailed river profile data. River profile data is available for the river stretches which are relevant for flood management. As a modeler, you will have to remember to ask your client for this data. However, in many parts of the world, river profile data is not available and you will have to make many assumptions about the river-aquifer interaction.   \n",
    "\n",
    "> **Implementing Surface-Water–Groundwater Interaction in MODFLOW**\n",
    "> \n",
    "> MODFLOW offers several ways to represent exchanges between rivers and aquifers. The choice depends on model goals, data availability, and desired level of detail:\n",
    ">\n",
    "> **Coarse**:  \n",
    "> - *Constant Head (CHD)*: fixes head along a river reach → simple representation of boundary influence, but no feedback with aquifer conditions.\n",
    ">\n",
    "> **Intermediate**:\n",
    ">\n",
    "> - *Drain (DRN)*: removes water when groundwater is above river stage → simulates discharge but not recharge.\n",
    ">\n",
    "> - *River (RIV)*: allows two-way exchange based on stage, aquifer head, and riverbed conductance → widely used for river–aquifer interaction.\n",
    ">\n",
    "> **Detailed**:\n",
    ">\n",
    "> - *Streamflow Routing (SFR/SFR2)*: represents channel network, flow routing, stream gains/losses, and interactions with aquifer.\n",
    ">\n",
    "> - *Lake (LAK)*: simulates dynamic lake–aquifer exchange with surface water balance.\n",
    ">\n",
    "> Unsaturated Zone Flow (UZF): can simulate seepage from rivers or canals through the vadose zone to groundwater.\n",
    ">\n",
    "> 👉 In practice, many studies start with the RIV package and move toward SFR or LAK if surface water dynamics are important.\n",
    "\n",
    "The following steps guide you through the rather complex process of implementing the RIV package in your MODFLOW model. But don't worry, we will break it down into manageable tasks.\n",
    "\n",
    "1. Define the river geometry: This includes the river centerline, width, and depth. You can use GIS data to extract this information or make reasonable assumptions based on similar rivers in the region.\n",
    "\n",
    "2. Assign riverbed elevations: Since we don't have detailed river profile data, we will need to make assumptions about the riverbed elevations. One approach is to use a digital elevation model (DEM) to estimate the riverbed elevation at each river cross-section.\n",
    "\n",
    "3. Specify river hydraulic properties: This includes the riverbed hydraulic conductivity and the river stage. The hydraulic conductivity can be estimated based on soil and sediment characteristics, while the river stage can be derived from observed water levels or assumed based on regional data.\n",
    "\n",
    "4. Implement the RIV package in MODFLOW: This involves defining the river cells in the model grid, specifying the river geometry and hydraulic properties, and setting up the necessary input files for MODFLOW.\n",
    "\n",
    "5. Calibrate the model: Once the RIV package is implemented, you will need to calibrate the model to ensure that it accurately represents the river-aquifer interaction. This may involve adjusting the river hydraulic properties, refining the river geometry, or incorporating additional data.\n",
    "\n",
    "6. Validate the model: Finally, you should validate the model by comparing the simulated river stages and flows with observed data. This will help ensure that the model is reliable and can be used for decision-making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b2629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to the river shapes and to the boundary outline\n",
    "river_data_path = download_named_file(name='rivers', data_type='gis')\n",
    "boundary_path = download_named_file(name='model_boundary', data_type='gis')\n",
    "\n",
    "# Intersect the river data with the model grid and only keep the parts that are \n",
    "# inside the model boundary. \n",
    "river_gdf = gpd.read_file(river_data_path)\n",
    "boundary_gdf = gpd.read_file(boundary_path)\n",
    "# Ensure both GeoDataFrames are in the same CRS\n",
    "river_gdf = river_gdf.to_crs(modelgrid.crs)\n",
    "boundary_gdf = boundary_gdf.to_crs(modelgrid.crs)\n",
    "# Clip the river data to the model boundary\n",
    "river_clipped = gpd.clip(river_gdf, boundary_gdf)\n",
    "\n",
    "# Print the column names of the clipped river data to understand its structure\n",
    "print(\"Clipped river data columns:\")\n",
    "print(river_clipped.columns)\n",
    "# Print the unique values in the 'GEWAESSERNAME' column to understand the river names\n",
    "print(\"\\nUnique river names in the clipped data:\")\n",
    "print(river_clipped['GEWAESSERNAME'].unique())\n",
    "\n",
    "# We are interested in the river sections belonging to the rivers Sihl and Limmat. \n",
    "river_clipped = river_clipped[\n",
    "    (river_clipped['GEWAESSERNAME'].isin(['Sihl', 'Limmat'])) \n",
    "].copy()\n",
    "\n",
    "# Plot the clipped river data to verify\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "river_clipped.plot(ax=ax, color='blue', linewidth=2, label='Clipped River Data')\n",
    "blue_polygon = mpatches.Patch(facecolor='blue', linewidth=2, label='Clipped River Data')\n",
    "boundary_gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Model Boundary')\n",
    "ax.set_title(\"Figure 17: Clipped river data within the model boundary. \")\n",
    "ax.set_xlabel(\"X-coordinate\")\n",
    "ax.set_ylabel(\"Y-coordinate\")\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.legend(handles=[blue_polygon, red_line])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33d5ded",
   "metadata": {},
   "source": [
    "Now let's check if the elevation of the gauges on the river are consistent with the DEM. If the DEM is coarse and the river is narrow, the DEM might not capture the river elevation correctly. In this case, we might have to revert to a higher-resolution DEM that captures the river elevation better. If a higher-resolution DEM is not available, we can will have to carefully review the river elevation and adjust it manually if necessary. This will, in turn, make a bias correction of the river stage measurements necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e162d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summarizing river data ...\")\n",
    "\n",
    "# Load gauge locations\n",
    "gauges_path = download_named_file(name='gauges', data_type='gis')\n",
    "gauges_gdf = gpd.read_file(gauges_path, layer=\"GS_LIMNIGRAPHENSTATIONEN_P\")\n",
    "gauges_gdf = gauges_gdf.to_crs(modelgrid.crs)\n",
    "\n",
    "# Keep only the gauges in the model area\n",
    "gauges_gdf = gauges_gdf[gauges_gdf.geometry.within(gdf.union_all())]\n",
    "\n",
    "# print(\"\\nGauge information:\")\n",
    "# print(gauges_gdf[['LABEL', 'NAME']].head())\n",
    "\n",
    "# We extracted the average river stage values from the gauges in \n",
    "# `2_perceptual_model.ipynb`. Let's use these values to check if the river stage\n",
    "# is reasonable. The average river stage values are: \n",
    "river_data_path = os.path.join('case_study_zurich', 'data', 'rivers', 'river_data_summary.npy')\n",
    "river_stage_summary = np.load(river_data_path, allow_pickle=True).item()\n",
    "# Print the river stage summary to understand the values\n",
    "# print(\"\\nRiver stage summary:\")\n",
    "# print(river_stage_summary)\n",
    "# The river stage summary is a nested dictionary with river names as keys and \n",
    "# with names of statistics as secondary key. We replace the river names with the \n",
    "# gauge labels to make it easier to match with the gauges.\n",
    "# Create a mapping from river labels to river names in the river stage summary\n",
    "label_to_river = {\n",
    "    'LH  2099': 'limmat', \n",
    "    'LH  2176': 'sihl',\n",
    "}\n",
    "# Add 'mean' for each gauge to the gauges_gdf using the correct mapping\n",
    "gauges_gdf['mean_stage_masl'] = gauges_gdf['LABEL'].map(\n",
    "    lambda x: river_stage_summary.get(label_to_river.get(x, ''), {}).get('mean', np.nan)\n",
    ")\n",
    "# Round mean river stage values to 2 decimal places\n",
    "gauges_gdf['mean_stage_masl'] = gauges_gdf['mean_stage_masl'].round(2)\n",
    "\n",
    "# Print the updated gauges_gdf to verify\n",
    "# print(\"\\nUpdated gauges_gdf with mean river stage:\")\n",
    "# print(gauges_gdf[['LABEL', 'NAME', 'mean_stage_masl']])\n",
    "\n",
    "# print(\"\\nExtracting model_top values at gauge locations...\")\n",
    "# Check if gauges_gdf and mf.modelgrid have the same CRS\n",
    "if gauges_gdf.crs != modelgrid.crs:\n",
    "    print(\"Warning: CRS mismatch between gauges_gdf and modelgrid. Reprojecting...\")\n",
    "    gauges_gdf = gauges_gdf.to_crs(modelgrid.crs)\n",
    "# Print coordinates of gauges and model grid extent for debugging\n",
    "# print(\"\\nGauge coordinates:\")\n",
    "# for idx, gauge in gauges_gdf.iterrows():\n",
    "#     print(f\"Gauge {gauge['LABEL']} at ({gauge.geometry.centroid.x:.2f}, {gauge.geometry.centroid.y:.2f})\")\n",
    "# print(\"\\nModel grid extent:\")\n",
    "# print(f\"X range: {modelgrid.xcellcenters.min():.2f} to {modelgrid.xcellcenters.max():.2f}\")\n",
    "# print(f\"Y range: {modelgrid.ycellcenters.min():.2f} to {modelgrid.ycellcenters.max():.2f}\")\n",
    "\n",
    "# Check if each gauge is within the model grid extent\n",
    "# print(\"\\nChecking if each gauge is within model grid extent:\")\n",
    "for idx, gauge in gauges_gdf.iterrows():\n",
    "    gauge_x = gauge.geometry.x\n",
    "    gauge_y = gauge.geometry.y\n",
    "    \n",
    "    xlim = (gauge_x > modelgrid.xcellcenters.min()) & (gauge_x < modelgrid.xcellcenters.max())\n",
    "    ylim = (gauge_y > modelgrid.ycellcenters.min()) & (gauge_y < modelgrid.ycellcenters.max())\n",
    "    \n",
    "    within_bounds = xlim and ylim\n",
    "    if not within_bounds:\n",
    "        print(f\"  WARNING: Gauge {gauge['LABEL']} is outside the model grid extent!\")\n",
    "\n",
    "# Create a GridIntersect object\n",
    "ix = GridIntersect(modelgrid, method='vertex')\n",
    "\n",
    "# Get model top values at gauge locations\n",
    "model_top_at_gauges = []\n",
    "gauge_cell_info = []\n",
    "\n",
    "(\"\\nUsing nearest neighbor approach for all gauges:\")\n",
    "for idx, gauge in gauges_gdf.iterrows():\n",
    "    gauge_x, gauge_y = gauge.geometry.x, gauge.geometry.y\n",
    "    \n",
    "    # Calculate distances to all cell centers\n",
    "    x_centers = modelgrid.xcellcenters\n",
    "    y_centers = modelgrid.ycellcenters\n",
    "    \n",
    "    distances = np.sqrt((x_centers - gauge_x)**2 + (y_centers - gauge_y)**2)\n",
    "    \n",
    "    # Find the cell with minimum distance\n",
    "    min_row, min_col = np.unravel_index(distances.argmin(), distances.shape)\n",
    "    min_distance = distances[min_row, min_col]\n",
    "    \n",
    "    # Check if this cell is active\n",
    "    is_active = ibound[0, min_row, min_col] == 1\n",
    "    \n",
    "    # Get the model top value at this cell\n",
    "    top_value = modelgrid.top[min_row, min_col]\n",
    "    \n",
    "    # Add this to the dataframe\n",
    "    gauges_gdf.loc[idx, 'model_top_masl'] = top_value\n",
    "\n",
    "print(\"\\nUpdated gauges_gdf with model top:\")\n",
    "print(gauges_gdf[['LABEL', 'NAME', 'mean_stage_masl', 'model_top_masl']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e546c0",
   "metadata": {},
   "source": [
    "We see that the gauge level of the river Sihl is above the model top. The average elevation of the water level in the river is 412.35 m a.s.l. whereas the elevation of the grid cell is at 410 m a.s.l. For the river Limmat, we're ok. \n",
    "\n",
    "When you look for data to implement a numerical model, you will often encounter inconsistent data. This is a common issue in hydrological modeling, where different data sources may provide conflicting information about river stages, groundwater levels, and topography. You will have to factor in extra time to reconcile these discrepancies and ensure that your model is based on the best available data. Try to consult several independent data sources whenever possible.  \n",
    "\n",
    "In the present case, we have several options:   \n",
    "- Resample the model top from a higher-resolution DEM (way to go if a higher-resolution DEM is availble)\n",
    "- Manually bias-correct the time series of the river water level in the river Sihl to be consistent with the model top (tedious but doable)\n",
    "- Manually increase the DEM in the south-east corner of the model (last resort)\n",
    "\n",
    "In the case of the Limmat valley aquifer, a higher resolution DEM is indeed available. The swissALTI3D model from the Swiss Federal Office of Topography (swisstopo), see Figure 18. If you are interested in how to download the DEM and to merge the tiles, please refer to the `processing_DEM.ipynb` in `SUPPPORT_REPO/src/scripts/scripts_limmat_data_preprocessing/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24afba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the high-resolution DEM data\n",
    "dem_path = download_named_file(\n",
    "    name='dem_hres',\n",
    "    data_type='gis'\n",
    ")\n",
    "\n",
    "# Check CRS compatibility first\n",
    "with rasterio.open(dem_path) as src:\n",
    "    dem_crs = src.crs\n",
    "    print(f\"DEM CRS: {dem_crs}\")\n",
    "    print(f\"Model grid CRS: {modelgrid.crs}\")\n",
    "    \n",
    "    if str(dem_crs) != str(modelgrid.crs):\n",
    "        print(\"CRS transformation needed\")\n",
    "        \n",
    "        # Get the bounds of the model grid in its CRS\n",
    "        grid_bounds = modelgrid.extent\n",
    "        \n",
    "        # Transform model grid bounds to DEM CRS for cropping\n",
    "        dem_bounds = transform_bounds(\n",
    "            modelgrid.crs, dem_crs, \n",
    "            grid_bounds[0], grid_bounds[2], \n",
    "            grid_bounds[1], grid_bounds[3]\n",
    "        )\n",
    "        \n",
    "        # Read and crop the DEM data\n",
    "        window = src.window(*dem_bounds)\n",
    "        dem_data = src.read(1, window=window)\n",
    "        dem_transform = src.window_transform(window)\n",
    "        \n",
    "        # Now reproject the cropped DEM to match the model grid CRS\n",
    "        dst_crs = modelgrid.crs\n",
    "        dst_transform, dst_width, dst_height = rasterio.warp.calculate_default_transform(\n",
    "            dem_crs, dst_crs, dem_data.shape[1], dem_data.shape[0], *dem_bounds\n",
    "        )\n",
    "        \n",
    "        # Create output array\n",
    "        reprojected_dem = np.empty((dst_height, dst_width), dtype=dem_data.dtype)\n",
    "        \n",
    "        # Perform the reprojection\n",
    "        reproject(\n",
    "            dem_data,\n",
    "            reprojected_dem,\n",
    "            src_transform=dem_transform,\n",
    "            src_crs=dem_crs,\n",
    "            dst_transform=dst_transform,\n",
    "            dst_crs=dst_crs,\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "        \n",
    "        # Create a temporary raster file with the reprojected data\n",
    "        import tempfile\n",
    "        with tempfile.NamedTemporaryFile(suffix='.tif', delete=False) as tmp:\n",
    "            tmp_path = tmp.name\n",
    "            \n",
    "        with rasterio.open(\n",
    "            tmp_path, 'w',\n",
    "            driver='GTiff',\n",
    "            height=dst_height,\n",
    "            width=dst_width,\n",
    "            count=1,\n",
    "            dtype=reprojected_dem.dtype,\n",
    "            crs=dst_crs,\n",
    "            transform=dst_transform,\n",
    "        ) as dst:\n",
    "            dst.write(reprojected_dem, 1)\n",
    "        \n",
    "        # Now load with FloPy Raster\n",
    "        rio = Raster.load(tmp_path)\n",
    "        \n",
    "        # Clean up temporary file\n",
    "        import os\n",
    "        os.unlink(tmp_path)\n",
    "        \n",
    "    else:\n",
    "        print(\"CRS are compatible, no transformation needed\")\n",
    "        rio = Raster.load(dem_path)\n",
    "\n",
    "arr = rio.get_array(1)\n",
    "# Mask values below 0 and set them to NaN\n",
    "arr = np.where(arr <= 0, np.nan, arr)\n",
    "\n",
    "idx = np.isfinite(arr)\n",
    "\n",
    "vmin, vmax = arr[idx].min(), arr[idx].max()\n",
    "print(f\"DEM elevation range: {vmin:.1f} to {vmax:.1f} meters\")\n",
    "\n",
    "# Get the minimum and maximum coordinates of the DEM file\n",
    "dem_bounds = rio.bounds\n",
    "print(f\"DEM bounds: {dem_bounds}\")\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "\n",
    "# Create a masked array for plotting to handle NaN values properly\n",
    "masked_arr = np.ma.masked_invalid(arr)\n",
    "\n",
    "# Plot the raster with proper extent\n",
    "im = ax.imshow(masked_arr, extent=rio.bounds, vmin=vmin, vmax=vmax, cmap='terrain')\n",
    "plt.colorbar(im, shrink=0.7, label=\"Elevation (m)\")\n",
    "\n",
    "# Plot the model grid on top\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "pmv.plot_grid(lw=0.5, color=\"white\", alpha=0.7)\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "ax.set_title(\"Figure 18: High-resolution DEM with model grid overlay in grey and model boundary in red.\")\n",
    "ax.set_xlabel(\"X-coordinate (m)\")\n",
    "ax.set_ylabel(\"Y-coordinate (m)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e00ff",
   "metadata": {},
   "source": [
    "We resample the high-resolution DEM to our 50 m x 50 m grid (Figure 19).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8256398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Resample the high-resolution DEM ---\n",
    "# Verify CRS alignment\n",
    "print(\"Raster CRS:\", rio.crs)\n",
    "print(\"Grid CRS:  \", modelgrid.crs)\n",
    "\n",
    "# Depending on the resolution of the DEM, resampling can be computationally \n",
    "# intensive.\n",
    "t0 = time.time() # To log the time it takes to resample the DEM\n",
    "model_top_hres = rio.resample_to_grid(modelgrid, band=rio.bands[0], method=\"nearest\")\n",
    "resample_time = time.time() - t0\n",
    "\n",
    "# Build a valid-data mask (exclude nodata and non-finite)\n",
    "valid = np.isfinite(model_top_hres)\n",
    "for nod in (rio.nodatavals or []):\n",
    "    if nod is not None:\n",
    "        valid &= model_top_hres != nod\n",
    "\n",
    "# Also drop absurd magnitudes (typical float32 nodata)\n",
    "valid &= np.abs(model_top_hres) < 1e6\n",
    "\n",
    "# Drop values below 0\n",
    "valid &= model_top_hres > 0\n",
    "\n",
    "# We round to 10 centimeters to avoid having to store too many digits\n",
    "model_top_hres = np.round(model_top_hres, 1)\n",
    "\n",
    "# Compute robust vmin/vmax\n",
    "if np.any(valid):\n",
    "    vmin, vmax = np.nanmin(model_top_hres[valid]), np.nanmax(model_top_hres[valid])\n",
    "else:\n",
    "    raise RuntimeError(\"No valid DEM samples on the grid. Check CRS/projection.\")\n",
    "\n",
    "\n",
    "# Now to visualize using flopy and matplotlib\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "im = pmv.plot_array(model_top_hres, masked_values=rio.nodatavals, vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Overlay the buffered model boundary with proper legend handling\n",
    "boundary_patch = gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "\n",
    "plt.title(f\"Resample time, nearest neighbor: {resample_time:.3f} sec\")\n",
    "plt.colorbar(im, shrink=0.7, label=\"Elevation (m a.s.l.)\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "\n",
    "# Create custom legend handle to avoid warnings\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Buffered Model Boundary')\n",
    "ax.legend(handles=[red_line])\n",
    "ax.set_title(\"Figure 19: Resampled DEM on Model Grid with Buffered Model Boundary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6989b304",
   "metadata": {},
   "source": [
    "This is our new model top. We now get the elevation of the river bottom and make sure all our layers are consistent with the new top elevation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9afad97",
   "metadata": {},
   "source": [
    "#### 4.4.1 Delineating River Cells and Assigning Elevations\n",
    "With our model grid established, we now need to tell the model exactly where the rivers are located and define their physical properties. We'll use our model grid layer (IBOUND) and a Digital Elevation Model (DEM) to accomplish this. The goal is to create the key input for the River (RIV) Package: a list of active river cells and their corresponding bottom elevations (rbot).\n",
    "\n",
    "**1. Selecting River Cells from the Grid**\n",
    "The first step is to identify which specific grid cells represent the Sihl and Limmat rivers. We can overlay our river shapes with the model grid and select the intersecting cells.\n",
    "\n",
    "Action: We loaded the IBOUND grid layer into QGIS. Using the \"Select Features\" tool, we manually selected each cell that the Sihl and Limmat rivers flow through.\n",
    "\n",
    "Important Consideration: During selection, we ensured that the path of river cells was continuous. Each cell in the river is connected to the next one by sharing a cell face, not just a corner. This is best practice for the River (RIV) Package ensuring conceptual integrity and an absolute requirement for advanced packages like the Streamflow Routing (SFR) Package.\n",
    "\n",
    "Output: The selected cells were then saved as a new GeoPackage layer named river_cells.gpkg. This gives us a clean, isolated layer containing only the cells that will make up our rivers.\n",
    "\n",
    "**2. Extracting Riverbed Elevation (rbot)**\n",
    "Each river cell in the model needs a riverbed elevation (rbot). This value represents the bottom of the river channel and is used to determine whether the river is losing water to the aquifer or gaining water from it.\n",
    "\n",
    "Action: We used the Zonal Statistics tool in QGIS.\n",
    "\n",
    "Zones Layer: river_cells.gpkg\n",
    "\n",
    "Raster Layer: The project's high-resolution DEM.\n",
    "\n",
    "Statistic to calculate: Minimum\n",
    "\n",
    "Why the 'Minimum' Value? A single model cell (e.g., 50x50 meters) covers a significant area. The river channel within that cell will naturally occupy the lowest point. By extracting the minimum elevation from the DEM within each cell's boundary, we get a very good approximation of the true riverbed elevation.\n",
    "\n",
    "Figure 20 shows the output of the Zonal Statistics tool, with the extracted minimum elevations for each river cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c92c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(\n",
    "    image_filename='river_cells_qgis.png', \n",
    "    image_folder='4_model_implementation',\n",
    "    caption='Figure 20: Cells selected to represent the rivers. The active model cells are represented in grey. The background map is OpenStreetMap.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dceae28",
   "metadata": {},
   "source": [
    "**3. Quality Control and Manual Correction**\n",
    "Automated processes are powerful, but they aren't perfect and require a \"reality check.\" A river's elevation profile should consistently and smoothly decrease as it flows downstream—water doesn't flow uphill!\n",
    "\n",
    "Action: We inspected the minimum elevation values generated by Zonal Statistics. We discovered an issue near the Zürich Hauptbahnhof (main station). Here, the Sihl river flows through a tunnel beneath the railway tracks.\n",
    "\n",
    "The Problem: The DEM represents the surface elevation, which in this case is the top of the train station and tracks, not the hidden riverbed below. This resulted in artificially high rbot values.\n",
    "\n",
    "The Solution: We manually edited the attribute table for the river_cells layer, correcting these values based on known engineering plans or logical interpolation. This ensured we have a monotonically decreasing riverbed profile, which is physically realistic.\n",
    "\n",
    "With these steps complete, we now have a river_cells.gpkg file where each polygon represents a specific model cell and has a corrected attribute for its riverbed elevation. This is the perfect input for building our FloPy river package.\n",
    "\n",
    "Let's have a look at the river bottoms (rbot) we've extracted (Figure 21)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b20e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the riverbed elevations (rbot) from the river_cells layer\n",
    "river_cells_path = download_named_file(\n",
    "    name=\"river_cells\", \n",
    "    data_type=\"limmat_valley_model\"\n",
    "    )\n",
    "# Plot river cells over DEM with the same color scale\n",
    "# Load river cells and align CRS\n",
    "river_cells_gdf = gpd.read_file(river_cells_path)\n",
    "river_cells_gdf = river_cells_gdf.to_crs(modelgrid.crs)\n",
    "# Print the features of river_cells_gdf\n",
    "# print(river_cells_gdf)\n",
    "\n",
    "# Pick the riverbed elevation column (try common names)\n",
    "rbot_candidates = ['rbot', 'r_bottom', 'rbed', 'rbed_elev', 'rbot_m',\n",
    "                   'min', '_min', 'MIN', 'min_elev', 'z_min', 'Z_MIN']\n",
    "rbot_col = next((c for c in rbot_candidates if c in river_cells_gdf.columns), None)\n",
    "if rbot_col is None:\n",
    "    raise ValueError(f\"No riverbed elevation column found. Available columns: {list(river_cells_gdf.columns)}\")\n",
    "\n",
    "# Ensure row/col indices for placing values on the grid\n",
    "def _find_index_col(gdf, name_opts):\n",
    "    for n in name_opts:\n",
    "        if n in gdf.columns:\n",
    "            return n\n",
    "    return None\n",
    "\n",
    "row_col_name = _find_index_col(river_cells_gdf, ['row', 'ROW', 'i'])\n",
    "col_col_name = _find_index_col(river_cells_gdf, ['col', 'COL', 'j'])\n",
    "\n",
    "if row_col_name is None or col_col_name is None:\n",
    "    # Fallback: spatial join with ibound_gdf if available\n",
    "    if 'ibound_gdf' in globals():\n",
    "        joined = gpd.sjoin(river_cells_gdf, ibound_gdf[['cell_id','row','col','geometry']], how='left', predicate='intersects')\n",
    "        if joined[['row','col']].isna().any().any():\n",
    "            raise ValueError(\"Could not map all river cells to grid indices via ibound_gdf.\")\n",
    "        river_cells_gdf['row'] = joined['row'].astype(int)\n",
    "        river_cells_gdf['col'] = joined['col'].astype(int)\n",
    "        row_col_name, col_col_name = 'row', 'col'\n",
    "    else:\n",
    "        # Last resort: use GridIntersect\n",
    "        ix = GridIntersect(modelgrid, method='vertex', rtree=True)\n",
    "        rows_list, cols_list = [], []\n",
    "        for _, feat in river_cells_gdf.iterrows():\n",
    "            res = ix.intersect(feat.geometry)\n",
    "            if len(res) == 0:\n",
    "                rows_list.append(np.nan); cols_list.append(np.nan)\n",
    "            else:\n",
    "                # take the first intersecting cell (cells should be unique per feature)\n",
    "                rr = int(res.iloc[0]['row']); cc = int(res.iloc[0]['col'])\n",
    "                rows_list.append(rr); cols_list.append(cc)\n",
    "        river_cells_gdf['row'] = rows_list\n",
    "        river_cells_gdf['col'] = cols_list\n",
    "        if river_cells_gdf[['row','col']].isna().any().any():\n",
    "            raise ValueError(\"Could not map some river cells to grid indices (GridIntersect).\")\n",
    "        row_col_name, col_col_name = 'row', 'col'\n",
    "\n",
    "# Build an array of riverbed elevations on the model grid\n",
    "river_rbot_array = np.full((nrow_rotated, ncol_rotated), np.nan, dtype=float)\n",
    "for _, r in river_cells_gdf.iterrows():\n",
    "    i = int(r[row_col_name]); j = int(r[col_col_name])\n",
    "    if 0 <= i < nrow_rotated and 0 <= j < ncol_rotated:\n",
    "        river_rbot_array[i, j] = float(r[rbot_col])\n",
    "\n",
    "# Use the same color scale as model_top_hres\n",
    "valid_top = np.isfinite(model_top_hres) & (np.abs(model_top_hres) < 1e6)\n",
    "if not np.any(valid_top):\n",
    "    raise RuntimeError(\"model_top_hres has no valid values to define color scale.\")\n",
    "cmap = 'terrain'\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "\n",
    "# Base DEM (high‑res resampled)\n",
    "im = pmv.plot_array(model_top_hres, vmin=vmin, vmax=vmax, cmap=cmap, alpha=0.9)\n",
    "\n",
    "# Overlay river cells, colored by rbot, using the same vmin/vmax/cmap\n",
    "#pmv.plot_array(np.ma.masked_invalid(river_rbot_array), vmin=vmin, vmax=vmax, cmap=cmap, alpha=1.0)\n",
    "\n",
    "# Boundary outline\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2, label='Model boundary')\n",
    "\n",
    "# Colorbar reflects the shared scale\n",
    "cb = plt.colorbar(im, ax=ax, shrink=0.75, label=\"Elevation (m a.s.l.)\")\n",
    "\n",
    "ax.set_title(\"Figure 21: River cells (rbot) over model_top_hres (shared color scale)\")\n",
    "ax.set_xlabel(\"X-coordinate (m)\")\n",
    "ax.set_ylabel(\"Y-coordinate (m)\")\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de7ec6f",
   "metadata": {},
   "source": [
    "We see by the darker blue of the river in the downstream part that the river bottom elevation is below the surrounding DEM, as we expect. Let's see if in the river bottom is below the DEM of the river cells everywhere. We take the difference between the two (Figure 22)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdff871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth-to-riverbed on river cells: positive if riverbed is below ground, negative if inconsistent\n",
    "river_mask = np.isfinite(river_rbot_array) & np.isfinite(model_top_hres)\n",
    "if not np.any(river_mask):\n",
    "    raise RuntimeError(\"No valid river rbot values found to compute differences.\")\n",
    "\n",
    "depth_to_riverbed = model_top_hres - river_rbot_array\n",
    "depth_to_riverbed_masked = np.ma.masked_where(~river_mask, depth_to_riverbed)\n",
    "\n",
    "# Symmetric color scale around 0 to make inconsistencies visible\n",
    "absmax = np.nanmax(np.abs(depth_to_riverbed[river_mask]))\n",
    "vmin_diff, vmax_diff = -absmax, absmax if np.isfinite(absmax) and absmax > 0 else (-1, 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "# Show the model grid\n",
    "pmv.plot_grid(color=\"grey\", linewidth=0.3, alpha=0.25, zorder=0)\n",
    "\n",
    "# Plot only river cells with a diverging cmap centered at 0\n",
    "im = pmv.plot_array(\n",
    "    depth_to_riverbed_masked,\n",
    "    cmap=\"RdBu_r\",\n",
    "    vmin=vmin_diff,\n",
    "    vmax=vmax_diff,\n",
    "    alpha=0.95\n",
    ")\n",
    "\n",
    "# Boundary\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=1.5, label='Model boundary')\n",
    "\n",
    "cb = plt.colorbar(im, ax=ax, shrink=0.75, label=\"model_top_hres − rbot (m)\")\n",
    "ax.set_title(\"Figure 22: Depth to riverbed on river cells (positive = river below ground)\")\n",
    "ax.set_xlabel(\"X-coordinate (m)\")\n",
    "ax.set_ylabel(\"Y-coordinate (m)\")\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# Quick summary in console\n",
    "neg_cnt = np.sum(depth_to_riverbed[river_mask] < 0)\n",
    "print(f\"River cells: {river_mask.sum()} | negatives (rbot above ground): {neg_cnt}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acf43e1",
   "metadata": {},
   "source": [
    "We have consistently lower river bottom than model top. Now we define other parameters of the River (RIV) package.\n",
    "\n",
    "#### 4.4.2 Write RIV package \n",
    "The River (RIV) package represents rivers that can either gain water from or lose water to the aquifer, depending on the hydraulic gradient. Unlike the CHD package, which fixes heads, the RIV package simulates a dynamic head-dependent flux boundary.\n",
    "\n",
    "In Flopy, each active river cell requires three main parameters:\n",
    "\n",
    "1. **Stage** – the river water level (m).\n",
    "\n",
    "2. **Conductance** – the hydraulic connection between the river and the aquifer. It is usually computed as:\n",
    "\n",
    "$$𝐶=𝐾_{riverbed}⋅\\frac{𝑊⋅𝐿}{𝑀}$$\n",
    "\n",
    "where \n",
    "$K_{riverbed}$ = riverbed hydraulic conductivity,  \n",
    "$W$ = river width,  \n",
    "$L$ = river reach length,  \n",
    "$M$ = riverbed thickness.  \n",
    "\n",
    "3. **Riverbed Bottom Elevation** – the elevation of the base of the riverbed (m). This ensures that if the aquifer head drops below this level, no more seepage to the river occurs.\n",
    "\n",
    "Please have a look at the Section on the River-Aquifer Interaction in the second notebook on the Perceptual model to be reminded of how the flux is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dca51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RIV package\n",
    "# Parameters\n",
    "# Leakage coefficient as estimated in perceptual model chapter:\n",
    "q_riv_sihl = 1.3e-6 * 86400  # 1/day\n",
    "q_riv_limmat = 3.5e-6 * 86400  # 1/day\n",
    "\n",
    "riverbed_thickness = 0.5    # m, typical assumption\n",
    "riverbed_k_sihl = q_riv_sihl * riverbed_thickness  # m/d (hydraulic conductivity of riverbed)\n",
    "riverbed_k_limmat = q_riv_limmat * riverbed_thickness  # m/d (hydraulic conductivity of riverbed)\n",
    "\n",
    "# Average river depth estimated in perceptual model chapter:\n",
    "sihl_depth_mean = 0.3\n",
    "limmat_depth_mean = 0.7\n",
    "min_stage_clearance = 0.05  # m above rbot to avoid stage==rbot\n",
    "# Optional width by river name (if attribute present on river_cells_gdf)\n",
    "width_by_name = {\n",
    "    'Limmat': 30.0,  # m\n",
    "    'Sihl':   15.0,  # m\n",
    "}\n",
    "default_width = 15.0  # m (used if river name is not available)\n",
    "\n",
    "# Find a river name column, if any\n",
    "river_name_col = None\n",
    "for cand in ['GEWAESSERNAME', 'name', 'river', 'river_name', 'Name', 'gew_name']:\n",
    "    if cand in river_cells_gdf.columns:\n",
    "        river_name_col = cand\n",
    "        break\n",
    "\n",
    "# Build RIV stress period data\n",
    "riv_spd = []  # Initialize river stress period data\n",
    "n_skipped = 0  \n",
    "\n",
    "# Exclude CHD cells from RIV\n",
    "chd_cells_set = set()\n",
    "if 'chd' in globals():\n",
    "    try:\n",
    "        chd_cells_set = {(int(c[1]), int(c[2])) for c in chd.stress_period_data[0]}\n",
    "    except Exception:\n",
    "        chd_cells_set = set()\n",
    "\n",
    "for _, rec in river_cells_gdf.iterrows():\n",
    "    i = int(rec['row'])\n",
    "    j = int(rec['col'])\n",
    "\n",
    "    # Skip if out of grid or not active\n",
    "    if not (0 <= i < nrow_rotated and 0 <= j < ncol_rotated):\n",
    "        n_skipped += 1\n",
    "        continue\n",
    "    if ibound[0, i, j] != 1:\n",
    "        # Exclude inactive (0) and CHD (-1) cells\n",
    "        n_skipped += 1\n",
    "        continue\n",
    "    if (i, j) in chd_cells_set:\n",
    "        n_skipped += 1\n",
    "        continue\n",
    "\n",
    "    # Assign river bottom elevation (rbot)\n",
    "    rbot = float(rec[rbot_col])\n",
    "    if not np.isfinite(rbot):\n",
    "        n_skipped += 1\n",
    "        continue\n",
    "\n",
    "    # Choose width (W)\n",
    "    if river_name_col is not None and isinstance(rec[river_name_col], str):\n",
    "        W = width_by_name.get(rec[river_name_col], default_width)\n",
    "    else:\n",
    "        W = default_width\n",
    "\n",
    "    # Approximate reach length (L) for a cell\n",
    "    # Using min of delr/delc at this location (uniform here, ~cell_size)\n",
    "    L = float(min(delr_rotated[j], delc_rotated[i]))\n",
    "\n",
    "    # Conductance: C = K_riverbed * (W * L) / M  [units: m^2/day]\n",
    "    if river_name_col is not None and isinstance(rec[river_name_col], str):\n",
    "        cond = (riverbed_k_limmat if rec[river_name_col] == 'Limmat' else riverbed_k_sihl) * (W * L) / riverbed_thickness\n",
    "    else:\n",
    "        cond = riverbed_k_sihl * (W * L) / riverbed_thickness\n",
    "\n",
    "    # Stage: put the water surface slightly above rbot\n",
    "    if river_name_col is not None and isinstance(rec[river_name_col], str):\n",
    "        stage = rbot + (sihl_depth_mean if rec[river_name_col] == 'Sihl' else limmat_depth_mean)\n",
    "    else:\n",
    "        stage = rbot + sihl_depth_mean\n",
    "\n",
    "    # Optional cap to remain below ground (if DEM available at cell)\n",
    "    if 'model_top_hres' in globals() and np.isfinite(model_top_hres[i, j]):\n",
    "        stage = min(stage, model_top_hres[i, j] - min_stage_clearance)\n",
    "\n",
    "    # Ensure stage is above rbot\n",
    "    if stage <= rbot:\n",
    "        stage = rbot + min_stage_clearance\n",
    "\n",
    "    riv_spd.append([0, i, j, float(stage), float(cond), float(rbot)])\n",
    "\n",
    "print(f\"RIV cells prepared: {len(riv_spd)} (skipped: {n_skipped})\")\n",
    "\n",
    "# 3) Create/replace the RIV package\n",
    "riv = flopy.modflow.ModflowRiv(\n",
    "    mf,\n",
    "    stress_period_data={0: riv_spd},\n",
    "    ipakcb=53  # enable cbc output for river package\n",
    ")\n",
    "\n",
    "print(\"RIV package created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d713ff",
   "metadata": {},
   "source": [
    "#### 4.4.3 Update the DIS package\n",
    "We also have to update the model bottom and make sure the river bottom is consistently above the aquifer bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a862ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-calculate model bottom, enforce a minimum aquifer thickness of at least 5 m\n",
    "model_bottom_hres = model_top_hres - np.maximum(aquifer_thickness_resampled, 5)\n",
    "\n",
    "# Let's check if the model bottom is below the river bottom\n",
    "# Masks\n",
    "river_mask = np.isfinite(river_rbot_array)           # only river cells\n",
    "active_mask = ibound[0] != 0                         # exclude fully inactive cells\n",
    "check_mask = river_mask & active_mask\n",
    "\n",
    "# Difference: botm - rbot\n",
    "diff = model_bottom_hres - river_rbot_array\n",
    "problem_mask = check_mask & (diff > 0)\n",
    "\n",
    "n_checked = int(np.nansum(check_mask))\n",
    "n_problem = int(np.nansum(problem_mask))\n",
    "print(f\"River cells checked: {n_checked}\")\n",
    "print(f\"Problem cells (botm > rbot): {n_problem}\")\n",
    "\n",
    "# Show top 10 violations\n",
    "if n_problem:\n",
    "    ii, jj = np.where(problem_mask)\n",
    "    violations = pd.DataFrame({\n",
    "        'row': ii,\n",
    "        'col': jj,\n",
    "        'botm': model_bottom_hres[ii, jj],\n",
    "        'rbot': river_rbot_array[ii, jj],\n",
    "        'botm_minus_rbot': diff[ii, jj],\n",
    "    }).sort_values('botm_minus_rbot', ascending=False)\n",
    "    display(violations.head(10))\n",
    "\n",
    "# Plot map of problem cells (colored by botm - rbot)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "plot_arr = np.where(problem_mask, diff, np.nan)\n",
    "im = pmv.plot_array(plot_arr, cmap='Reds')\n",
    "pmv.plot_grid(alpha=0.2, linewidth=0.4)\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=1)\n",
    "ax.set_title(\"Figure 23: Cells where model bottom > riverbed (color = botm − rbot, m)\")\n",
    "ax.set_aspect('equal')\n",
    "plt.colorbar(im, ax=ax, shrink=0.7, label='botm − rbot (m)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd8d40d",
   "metadata": {},
   "source": [
    "Figure 23 shows that, at a few locations at the model boundary, the river bottom is below the model bottom. We will lower the model bottom to 2 m below the river bottom at these locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0dabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the model bottom where it is below the river bottom\n",
    "model_bottom_hres[problem_mask] = river_rbot_array[problem_mask] - 2\n",
    "\n",
    "# Visual check\n",
    "# Difference: botm - rbot\n",
    "diff = model_bottom_hres - river_rbot_array\n",
    "problem_mask = check_mask & (diff > 0)\n",
    "\n",
    "n_checked = int(np.nansum(check_mask))\n",
    "n_problem = int(np.nansum(problem_mask))\n",
    "print(f\"River cells checked: {n_checked}\")\n",
    "print(f\"Problem cells (botm > rbot): {n_problem}\")\n",
    "\n",
    "# Show top 10 violations\n",
    "if n_problem:\n",
    "    ii, jj = np.where(problem_mask)\n",
    "    violations = pd.DataFrame({\n",
    "        'row': ii,\n",
    "        'col': jj,\n",
    "        'botm': model_bottom_hres[ii, jj],\n",
    "        'rbot': river_rbot_array[ii, jj],\n",
    "        'botm_minus_rbot': diff[ii, jj],\n",
    "    }).sort_values('botm_minus_rbot', ascending=False)\n",
    "    display(violations.head(10))\n",
    "\n",
    "# Plot map of problem cells (colored by botm - rbot)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "plot_arr = np.where(problem_mask, diff, np.nan)\n",
    "im = pmv.plot_array(plot_arr, cmap='Reds')\n",
    "pmv.plot_grid(alpha=0.2, linewidth=0.4)\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=1)\n",
    "ax.set_title(\"Figure 24: Cells where model bottom > riverbed (color = botm − rbot, m)\")\n",
    "ax.set_aspect('equal')\n",
    "plt.colorbar(im, ax=ax, shrink=0.7, label='botm − rbot (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c73516e",
   "metadata": {},
   "source": [
    "The river bed elevation is now consistent with the model bottom (Figure 24). Now we can update the DIS package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the DIS package\n",
    "dis = flopy.modflow.ModflowDis(\n",
    "    mf,\n",
    "    nlay=nlay,\n",
    "    nrow=nrow_rotated,\n",
    "    ncol=ncol_rotated,\n",
    "    delr=delr_rotated,\n",
    "    delc=delc_rotated,\n",
    "    top=model_top_hres,\n",
    "    botm=model_bottom_hres,\n",
    "    xoff=xmin_original,\n",
    "    yoff=ymin_original,\n",
    "    angrot=-grid_rotation_angle,\n",
    "    lenuni=2,\n",
    "    nper=nper,\n",
    "    perlen=perlen,\n",
    "    nstp=nstp,\n",
    "    tsmult=tsmult,\n",
    "    steady=steady\n",
    ")\n",
    "\n",
    "# Check if model top and model bottom are less than 2 meters apart.\n",
    "if np.any(dis.top - dis.botm[0] < 2):\n",
    "    raise ValueError(\"Model top and bottom must be at least 2 meters apart.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe242a6e",
   "metadata": {},
   "source": [
    "#### 4.4.4 Update the initial heads in the BAS package\n",
    "Since we changed top and bottom of aquifer, we should also update the initial groundwater tables in the BAS package to make sure we have starting heads that are consistent with the new model geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372a0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update starting heads  in bas package\n",
    "if 'model_top_hres' in globals():\n",
    "    strt = np.minimum(model_top_hres - 0.5, model_top_hres)  # 0.5 m below surface\n",
    "    bas = flopy.modflow.ModflowBas(mf, ibound=ibound, strt=strt, hnoflo=-999.99)\n",
    "    print(\"Rebuilt BAS with starting heads = top - 0.5 m (clipped).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91658f9",
   "metadata": {},
   "source": [
    "#### 4.4.5 Check if the CHD boundary is consistent with new model geometry\n",
    "We should now check if the CHD boundary conditions are consistent with the new model geometry. This includes verifying that the elevations of the CHD boundaries are within the updated model layer elevations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71440bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compare CHD shead values to model top & bottom at ibound == -1 cells ---\n",
    "# Safety checks\n",
    "if 'chd' not in globals():\n",
    "    raise RuntimeError(\"CHD package (chd) not found.\")\n",
    "if 'bas' not in globals():\n",
    "    raise RuntimeError(\"BAS package (bas) not found.\")\n",
    "if not hasattr(mf, 'dis'):\n",
    "    raise RuntimeError(\"DIS package not found on model (mf).\")\n",
    "\n",
    "# Get CHD stress period 0 data (recarray with fields k, i, j, shead, ehead)\n",
    "spd0 = chd.stress_period_data[0]\n",
    "k = spd0['k']\n",
    "i = spd0['i']\n",
    "j = spd0['j']\n",
    "shead = spd0['shead']  # initial (start) heads\n",
    "\n",
    "# Model top (2D) and bottom (first/only layer)\n",
    "top_2d = mf.dis.top.array\n",
    "botm_3d = mf.dis.botm.array\n",
    "botm_2d = botm_3d[0]  # single-layer model\n",
    "\n",
    "# IBOUND array\n",
    "ibound_arr = bas.ibound.array  # shape (nlay, nrow, ncol)\n",
    "\n",
    "# Ensure all listed CHD cells are actually flagged ibound == -1\n",
    "ibound_flags = ibound_arr[k, i, j]\n",
    "if not np.all(ibound_flags == -1):\n",
    "    mismatch_idx = np.where(ibound_flags != -1)[0]\n",
    "    print(f\"Warning: {len(mismatch_idx)} CHD cells are not ibound == -1. Showing first few:\")\n",
    "    print(pd.DataFrame({\n",
    "        'k': k[mismatch_idx],\n",
    "        'i': i[mismatch_idx],\n",
    "        'j': j[mismatch_idx],\n",
    "        'ibound': ibound_flags[mismatch_idx],\n",
    "        'shead': shead[mismatch_idx]\n",
    "    }).head())\n",
    "\n",
    "# Extract top & bottom at CHD cells\n",
    "top_at = top_2d[i, j]\n",
    "botm_at = botm_2d[i, j]\n",
    "\n",
    "# Tolerance for comparisons\n",
    "tol = 1e-6\n",
    "\n",
    "within_top = shead <= (top_at + tol)\n",
    "above_botm = shead >= (botm_at - tol)\n",
    "within_bounds = within_top & above_botm\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'k': k,\n",
    "    'i': i,\n",
    "    'j': j,\n",
    "    'shead': shead,\n",
    "    'top': top_at,\n",
    "    'botm': botm_at,\n",
    "    'above_botm': above_botm,\n",
    "    'below_top': within_top,\n",
    "    'within_bounds': within_bounds,\n",
    "})\n",
    "\n",
    "print(f\"Total CHD cells: {len(summary_df)}\")\n",
    "print(f\"Within (botm <= shead <= top): {within_bounds.sum()}\")\n",
    "print(f\"Above top: {(~within_top).sum()}\")\n",
    "print(f\"Below bottom: {(~above_botm).sum()}\")\n",
    "\n",
    "# Show any problem rows\n",
    "problem_rows = summary_df[~within_bounds]\n",
    "if not problem_rows.empty:\n",
    "    print(\"\\nCHD cells with inconsistent heads (showing all):\")\n",
    "    display(problem_rows)\n",
    "else:\n",
    "    print(\"All CHD heads lie between model bottom and top (within tolerance).\")\n",
    "\n",
    "# Optional: quick numeric ranges\n",
    "if len(summary_df):\n",
    "    print(f\"\\nRange shead: {shead.min():.3f} – {shead.max():.3f} m\")\n",
    "    print(f\"Range top  : {top_at.min():.3f} – {top_at.max():.3f} m\")\n",
    "    print(f\"Range botm : {botm_at.min():.3f} – {botm_at.max():.3f} m\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d656747d",
   "metadata": {},
   "source": [
    "We have 1 cell where the starting head is below the model bottom elevation. Let's see where it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac56840",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'chd' not in globals():\n",
    "    raise RuntimeError(\"CHD package (chd) not found.\")\n",
    "if not hasattr(mf, 'dis'):\n",
    "    raise RuntimeError(\"DIS package not found on model.\")\n",
    "if 'bas' not in globals():\n",
    "    raise RuntimeError(\"BAS package (bas) required for ibound context (only to mask CHD cells).\")\n",
    "\n",
    "# Model geometry\n",
    "top_arr  = mf.dis.top.array              # (nrow, ncol)\n",
    "botm_arr = mf.dis.botm.array             # (nlay, nrow, ncol)\n",
    "nlay, nrow, ncol = botm_arr.shape\n",
    "\n",
    "# IBOUND array (CHD cells have ibound == -1)\n",
    "ibound_arr = bas.ibound.array\n",
    "\n",
    "# Build an array of CHD shead values (NaN elsewhere)\n",
    "chd_shead = np.full((nlay, nrow, ncol), np.nan, dtype=float)\n",
    "\n",
    "# Extract stress period 0 CHD data (k,i,j,shead,ehead)\n",
    "spd0 = chd.stress_period_data[0]\n",
    "for rec in spd0:\n",
    "    k, i, j, shead = rec['k'], rec['i'], rec['j'], rec['shead']\n",
    "    chd_shead[k, i, j] = shead\n",
    "\n",
    "tol = 1e-6\n",
    "\n",
    "records = []\n",
    "for k in range(nlay):\n",
    "    # CHD cells this layer\n",
    "    chd_mask = (ibound_arr[k] == -1) & np.isfinite(chd_shead[k])\n",
    "    if not np.any(chd_mask):\n",
    "        continue\n",
    "\n",
    "    shead_layer = chd_shead[k][chd_mask]\n",
    "    botm_layer  = botm_arr[k][chd_mask]\n",
    "    top_layer   = top_arr[chd_mask]\n",
    "\n",
    "    below_botm_mask = shead_layer < (botm_layer - tol)\n",
    "    above_top_mask  = shead_layer > (top_layer + tol)\n",
    "\n",
    "    # Indices (row,col) for all CHD cells\n",
    "    rows, cols = np.where(chd_mask)\n",
    "\n",
    "    for idx, (r, c) in enumerate(zip(rows, cols)):\n",
    "        shead_v = chd_shead[k, r, c]\n",
    "        botm_v  = botm_arr[k, r, c]\n",
    "        top_v   = top_arr[r, c]\n",
    "        records.append({\n",
    "            'lay': k,\n",
    "            'row': r,\n",
    "            'col': c,\n",
    "            'shead': shead_v,\n",
    "            'botm': botm_v,\n",
    "            'top': top_v,\n",
    "            'thickness': top_v - botm_v,\n",
    "            'below_botm': shead_v < (botm_v - tol),\n",
    "            'above_top': shead_v > (top_v + tol),\n",
    "            'deficit_botm': (botm_v - shead_v) if shead_v < (botm_v - tol) else 0.0,\n",
    "            'excess_top': (shead_v - top_v) if shead_v > (top_v + tol) else 0.0\n",
    "        })\n",
    "\n",
    "problem_df = pd.DataFrame(records)\n",
    "\n",
    "print(\"CHD shead consistency summary:\")\n",
    "if problem_df.empty:\n",
    "    print(\"No CHD cells found.\")\n",
    "else:\n",
    "    total_chd = len(problem_df)\n",
    "    below_cnt = int(problem_df['below_botm'].sum())\n",
    "    above_cnt = int(problem_df['above_top'].sum())\n",
    "    print(f\"Total CHD cells: {total_chd}\")\n",
    "    print(f\"Below bottom: {below_cnt}\")\n",
    "    print(f\"Above top: {above_cnt}\")\n",
    "    print(f\"Within (botm <= shead <= top): {total_chd - below_cnt - above_cnt}\")\n",
    "\n",
    "    # Display problem rows\n",
    "    problems = problem_df[(problem_df['below_botm']) | (problem_df['above_top'])]\n",
    "    if not problems.empty:\n",
    "        display(problems.sort_values(['below_botm','deficit_botm','excess_top'], ascending=[False, False, False]).head(30))\n",
    "    else:\n",
    "        print(\"All CHD heads lie between bottom and top (within tolerance).\")\n",
    "\n",
    "    # Map: deficits (botm - shead > 0)\n",
    "    for k in sorted(problem_df['lay'].unique()):\n",
    "        layer_df = problem_df[problem_df.lay == k]\n",
    "        deficit_map = np.full((nrow, ncol), np.nan, dtype=float)\n",
    "        excess_map  = np.full((nrow, ncol), np.nan, dtype=float)\n",
    "\n",
    "        bd = layer_df[layer_df.below_botm]\n",
    "        if not bd.empty:\n",
    "            deficit_map[bd.row, bd.col] = bd.deficit_botm\n",
    "\n",
    "        at = layer_df[layer_df.above_top]\n",
    "        if not at.empty:\n",
    "            excess_map[at.row, at.col] = at.excess_top\n",
    "\n",
    "        if np.isfinite(deficit_map).any():\n",
    "            fig, ax = plt.subplots(figsize=(6.5,6.5))\n",
    "            pmv = flopy.plot.PlotMapView(modelgrid=mf.modelgrid, ax=ax)\n",
    "            im = pmv.plot_array(deficit_map, cmap='Reds')\n",
    "            pmv.plot_ibound(alpha=0.25)\n",
    "            #pmv.plot_bc(package=chd, color='navy')\n",
    "            plt.colorbar(im, ax=ax, shrink=0.25, label='botm - shead (m)')\n",
    "            ax.set_title(f\"Figure 25: CHD shead below bottom in red. IBOUND (black: inactive, blue: CHD, white: active)\")\n",
    "            ax.set_aspect('equal')\n",
    "            plt.show()\n",
    "\n",
    "        if np.isfinite(excess_map).any():\n",
    "            fig, ax = plt.subplots(figsize=(6.5,6.5))\n",
    "            pmv = flopy.plot.PlotMapView(modelgrid=mf.modelgrid, ax=ax)\n",
    "            im = pmv.plot_array(excess_map, cmap='PuBu')\n",
    "            pmv.plot_ibound(alpha=0.25)\n",
    "            #pmv.plot_bc(package=chd, color='navy')\n",
    "            plt.colorbar(im, ax=ax, shrink=0.25, label='shead - top (m)')\n",
    "            ax.set_title(f\"Figure 25b: CHD shead above top in red and IBOUND (black: inactive, blue: CHD, white: active)\")\n",
    "            ax.set_aspect('equal')\n",
    "            plt.show()# Map (per layer) of deficit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f7c0f",
   "metadata": {},
   "source": [
    "We have one cell at the outflow boundary (Figure 25) where we have a significant deficit, indicating that the fixed head is below the bottom of the cell. This cell will always be dry. This issue likely originates in the model top layer which might be too high in this location (highway, bridge) and the fact that the bottom of the aquifer is very shallow in this area. It is a cell right next to the river in the north of the river (far downstream of our area of interest). We will lower the aquifer bottom in this cell by 2 meters to satisfy the boundary condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daeaeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "lower_amount     = 2.0   # meters to lower\n",
    "min_thickness    = 2.0   # enforce at least this thickness (safety)\n",
    "head_clearance   = 1.0   # ensure starting head >= bottom + clearance\n",
    "layer            = 0     # single-layer model index\n",
    "\n",
    "# Safety checks\n",
    "if 'deficit_map' not in globals():\n",
    "    raise RuntimeError(\"deficit_map not found. Run the CHD consistency cell first.\")\n",
    "if not hasattr(mf, 'dis'):\n",
    "    raise RuntimeError(\"mf.dis (DIS package) not found.\")\n",
    "if 'bas' not in globals():\n",
    "    raise RuntimeError(\"BAS package (bas) not found.\")\n",
    "\n",
    "# Current geometry\n",
    "top_arr  = mf.dis.top.array            # (nrow, ncol)\n",
    "botm_arr = mf.dis.botm.array.copy()    # (nlay, nrow, ncol)\n",
    "nlay, nrow, ncol = botm_arr.shape\n",
    "\n",
    "if layer >= nlay:\n",
    "    raise ValueError(\"Requested layer index out of range.\")\n",
    "\n",
    "# Build mask: positive deficits\n",
    "mask = np.isfinite(deficit_map) & (deficit_map > 0)\n",
    "n_cells_to_lower = int(mask.sum())\n",
    "\n",
    "if n_cells_to_lower == 0:\n",
    "    print(\"No positive deficits found; nothing to adjust.\")\n",
    "else:\n",
    "    print(f\"Cells with positive deficit: {n_cells_to_lower}\")\n",
    "\n",
    "    # Lower bottom\n",
    "    before = botm_arr[layer, mask].copy()\n",
    "    botm_arr[layer, mask] -= lower_amount\n",
    "\n",
    "    # Enforce minimum thickness everywhere (after lowering)\n",
    "    thickness = top_arr - botm_arr[layer]\n",
    "    too_thin = thickness < min_thickness\n",
    "    if np.any(too_thin):\n",
    "        botm_arr[layer, too_thin] = top_arr[too_thin] - min_thickness\n",
    "\n",
    "    # Rebuild DIS with updated bottom\n",
    "    old_dis = mf.dis\n",
    "    dis_kwargs = dict(\n",
    "        nlay=old_dis.nlay,\n",
    "        nrow=old_dis.nrow,\n",
    "        ncol=old_dis.ncol,\n",
    "        delr=old_dis.delr.array,\n",
    "        delc=old_dis.delc.array,\n",
    "        top=top_arr,\n",
    "        botm=botm_arr,\n",
    "        nper=old_dis.nper,\n",
    "        perlen=old_dis.perlen.array,\n",
    "        nstp=old_dis.nstp.array,\n",
    "        tsmult=old_dis.tsmult.array,\n",
    "        steady=old_dis.steady.array\n",
    "    )\n",
    "    # Preserve optional spatial metadata if present\n",
    "    for attr in (\"xul\", \"yul\", \"rotation\", \"lenuni\"):\n",
    "        if hasattr(old_dis, attr):\n",
    "            dis_kwargs[attr] = getattr(old_dis, attr)\n",
    "\n",
    "    mf.remove_package('DIS')\n",
    "    flopy.modflow.ModflowDis(mf, **dis_kwargs)\n",
    "\n",
    "    # Adjust starting heads (raise only if below new bottom + clearance)\n",
    "    strt = bas.strt.array\n",
    "    if strt.ndim == 2:\n",
    "        strt = strt[np.newaxis, ...]\n",
    "    new_bot_layer = botm_arr[layer]\n",
    "    need_raise = strt[layer] < (new_bot_layer + head_clearance)\n",
    "    n_raise = int(need_raise.sum())\n",
    "    if n_raise:\n",
    "        strt[layer][need_raise] = new_bot_layer[need_raise] + head_clearance\n",
    "\n",
    "    # Rebuild BAS\n",
    "    ibound_arr = bas.ibound.array\n",
    "    mf.remove_package('BAS6')\n",
    "    flopy.modflow.ModflowBas(mf, ibound=ibound_arr, strt=strt, hnoflo=-999.99)\n",
    "\n",
    "    # Report\n",
    "    new_thickness = top_arr - botm_arr[layer]\n",
    "    print(f\"Lowered {n_cells_to_lower} cell bottoms by {lower_amount} m.\")\n",
    "    print(f\"Raised {n_raise} starting-head cells to maintain clearance.\")\n",
    "    print(f\"Thickness stats (m): min {new_thickness.min():.2f} | mean {new_thickness.mean():.2f} | max {new_thickness.max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d33de",
   "metadata": {},
   "source": [
    "#### 4.4.6 Update LFP package\n",
    "To make sure we don't have any old information in the LPF package, we can use the `rebuild_lpf_preserve_transmissivity` function defined below. This function will update the LPF package with the new hydraulic conductivity values while preserving transmissivity if the old thickness is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8154ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_lpf_preserve_transmissivity(\n",
    "    mf,\n",
    "    min_thickness=0.5,\n",
    "    hk_min=1e-4,\n",
    "    hk_max=1e4,\n",
    "    preserve_T=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Rebuild LPF so hydraulic conductivity fields stay consistent after geometry (DIS) changes.\n",
    "    If preserve_T and old_thickness is available (same shape), transmissivity is preserved:\n",
    "        T_old = hk_old * old_thickness  -> hk_new = T_old / new_thickness\n",
    "    Otherwise hk_old is kept.\n",
    "    Vertical K is rebuilt from preserved anisotropy ratio (kv/kh) where possible.\n",
    "    Requirements:\n",
    "        - Existing LPF package already attached to model (to read prior hk/vka).\n",
    "        - Updated DIS already present (new top/botm).\n",
    "        - (Optional) old_thickness in globals with shape (nrow, ncol).\n",
    "    \"\"\"\n",
    "    lpf_old = mf.get_package(\"LPF\")\n",
    "    if lpf_old is None:\n",
    "        raise RuntimeError(\"No existing LPF package found.\")\n",
    "\n",
    "    # Current geometry\n",
    "    top = mf.dis.top.array\n",
    "    botm0 = mf.dis.botm.array[0]\n",
    "    new_thk = top - botm0\n",
    "    if (new_thk <= 0).any():\n",
    "        raise ValueError(\"Found non-positive thickness cells after DIS update.\")\n",
    "\n",
    "    # Old property arrays\n",
    "    hk_old = np.array(lpf_old.hk.array[0], dtype=float)  # (nrow, ncol)\n",
    "    vka_old = np.array(lpf_old.vka.array[0], dtype=float)\n",
    "\n",
    "    # Try to preserve transmissivity if old_thickness provided\n",
    "    use_T = False\n",
    "    if preserve_T and 'old_thickness' in globals():\n",
    "        if isinstance(old_thickness, np.ndarray) and old_thickness.shape == hk_old.shape:\n",
    "            old_T = hk_old * np.maximum(old_thickness, min_thickness)\n",
    "            hk_new = old_T / np.maximum(new_thk, min_thickness)\n",
    "            use_T = True\n",
    "        else:\n",
    "            hk_new = hk_old.copy()\n",
    "    else:\n",
    "        hk_new = hk_old.copy()\n",
    "\n",
    "    # Bound hk\n",
    "    hk_new = np.clip(hk_new, hk_min, hk_max)\n",
    "\n",
    "    # Preserve anisotropy ratio (kv/kh) safely\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ratio = np.where(hk_old > 0, vka_old / hk_old, np.nan)\n",
    "    # Fallback ratio where invalid\n",
    "    default_ratio = np.nanmedian(ratio[np.isfinite(ratio)]) if np.isfinite(ratio).any() else 0.1\n",
    "    ratio[~np.isfinite(ratio)] = default_ratio\n",
    "    vka_new = hk_new * ratio\n",
    "    vka_new = np.clip(vka_new, hk_min, hk_max)\n",
    "\n",
    "    # Rebuild LPF (remove old first for cleanliness)\n",
    "    mf.remove_package('LPF')\n",
    "    new_lpf = flopy.modflow.ModflowLpf(\n",
    "        mf,\n",
    "        hk=hk_new[np.newaxis, ...],\n",
    "        vka=vka_new[np.newaxis, ...],\n",
    "        sy=lpf_old.sy.array if lpf_old.sy is not None else 0.15,\n",
    "        ss=lpf_old.ss.array if lpf_old.ss is not None else 1e-4,\n",
    "        laytyp=lpf_old.laytyp.array if lpf_old.laytyp is not None else 1,\n",
    "        ipakcb=lpf_old.ipakcb,\n",
    "        hdry=lpf_old.hdry,\n",
    "        wetfct=lpf_old.wetfct,\n",
    "        iwetit=lpf_old.iwetit,\n",
    "        laywet=lpf_old.laywet.array if lpf_old.laywet is not None else 1,\n",
    "        wetdry=getattr(lpf_old, 'wetdry', 0.01)\n",
    "    )\n",
    "\n",
    "    print(\"LPF rebuilt.\")\n",
    "    print(f\"  Preserved transmissivity: {use_T}\")\n",
    "    print(f\"  Thickness (m): min {new_thk.min():.2f} | mean {new_thk.mean():.2f} | max {new_thk.max():.2f}\")\n",
    "    print(f\"  hk_new (m/d):  min {hk_new.min():.3g} | mean {hk_new.mean():.3g} | max {hk_new.max():.3g}\")\n",
    "    print(f\"  vka_new (m/d): min {vka_new.min():.3g} | mean {vka_new.mean():.3g} | max {vka_new.max():.3g}\")\n",
    "    return new_lpf\n",
    "\n",
    "\n",
    "# Run rebuild\n",
    "lpf = rebuild_lpf_preserve_transmissivity(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d9aa66",
   "metadata": {},
   "source": [
    "### 4.5 Groundwater Pumping & Lateral Inflow - Well (WEL) Package\n",
    "\n",
    "Next we tackle the **lateral inflows from the north and the south** of the model. We will implement these as recharge wells with specified rates. In Chapter 2 - Perceptual Model, we estimate the lateral inflows to be about 20% of the annual precipiation of 1100 mm/year on an area of 11 km2 in the north and 15 km2 in the south. These amounts have to be distributed along the northern and southern boundaries of the model. We will do the same trick with the selection of cells for in QGIS as for the constant head boundary condition. The code below shows how to create the lateral inflow boundary condition based on the selected cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa10e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each selected boundary cell receives an equal share of the total inflow\n",
    "# Positive WEL rates inject water (MODFLOW convention)\n",
    "inflow_north = 0.2 * 1.100 * 11000000 / 365.25  # m3/day\n",
    "inflow_south = 0.2 * 1.100 * 15000000 / 365.25  # m3/day\n",
    "\n",
    "wells_north_path = download_named_file(\n",
    "    name='wells_north', \n",
    "    data_type='limmat_valley_model'\n",
    ")\n",
    "wells_south_path = download_named_file(\n",
    "    name='wells_south', \n",
    "    data_type='limmat_valley_model'\n",
    ")\n",
    "\n",
    "# Load selections\n",
    "wells_north_gdf = gpd.read_file(wells_north_path).to_crs(modelgrid.crs)\n",
    "wells_south_gdf = gpd.read_file(wells_south_path).to_crs(modelgrid.crs)\n",
    "\n",
    "if 'ibound_gdf' not in globals():\n",
    "    raise RuntimeError(\"ibound_gdf not in scope. Run IBOUND section first.\")\n",
    "\n",
    "for need in ['cell_id', 'row', 'col', 'ibound']:\n",
    "    if need not in ibound_gdf.columns:\n",
    "        raise ValueError(f\"ibound_gdf missing column: {need}\")\n",
    "\n",
    "for g in (wells_north_gdf, wells_south_gdf):\n",
    "    if 'cell_id' not in g.columns:\n",
    "        raise ValueError(\"Boundary well selection layers must contain 'cell_id' (export from ibound layer).\")\n",
    "\n",
    "# Normalize identifiers\n",
    "ibound_gdf['cell_id'] = ibound_gdf['cell_id'].astype(str).str.strip()\n",
    "wells_north_gdf['cell_id'] = wells_north_gdf['cell_id'].astype(str).str.strip()\n",
    "wells_south_gdf['cell_id'] = wells_south_gdf['cell_id'].astype(str).str.strip()\n",
    "\n",
    "def prepare_boundary(df_sel, label):\n",
    "    joined = df_sel.merge(\n",
    "        ibound_gdf[['cell_id']],\n",
    "        on='cell_id',\n",
    "        how='inner',\n",
    "        validate='1:1'\n",
    "    )\n",
    "    if joined.empty:\n",
    "        raise ValueError(f\"No matching cell_id for {label} boundary selection.\")\n",
    "    # Keep active (ibound==1) only (exclude inactive and CHD cells)\n",
    "    joined = joined.loc[joined['ibound'] == 1].drop_duplicates(subset=['row','col'])\n",
    "    joined['row'] = joined['row'].astype(int)\n",
    "    joined['col'] = joined['col'].astype(int)\n",
    "    return joined\n",
    "\n",
    "north_cells = prepare_boundary(wells_north_gdf, \"north\")\n",
    "south_cells = prepare_boundary(wells_south_gdf, \"south\")\n",
    "\n",
    "n_north = len(north_cells)\n",
    "n_south = len(south_cells)\n",
    "\n",
    "if n_north == 0:\n",
    "    raise ValueError(\"North boundary selection has no active non-CHD cells.\")\n",
    "if n_south == 0:\n",
    "    raise ValueError(\"South boundary selection has no active non-CHD cells.\")\n",
    "\n",
    "# Distribute uniformly\n",
    "q_north_each = inflow_north / n_north\n",
    "q_south_each = inflow_south / n_south\n",
    "\n",
    "# Build stress period data list: [lay, row, col, flux]\n",
    "wel_spd = []\n",
    "for _, r in north_cells.iterrows():\n",
    "    wel_spd.append([0, r.row, r.col, q_north_each])\n",
    "for _, r in south_cells.iterrows():\n",
    "    wel_spd.append([0, r.row, r.col, q_south_each])\n",
    "\n",
    "total_assigned = sum(w[3] for w in wel_spd)\n",
    "print(f\"Lateral inflow north total: {inflow_north:.2f} m3/d over {n_north} cells \"\n",
    "      f\"(each {q_north_each:.3f} m3/d)\")\n",
    "print(f\"Lateral inflow south total: {inflow_south:.2f} m3/d over {n_south} cells \"\n",
    "      f\"(each {q_south_each:.3f} m3/d)\")\n",
    "print(f\"Combined injected via WEL: {total_assigned:.2f} m3/d\")\n",
    "\n",
    "# Create / replace WEL package\n",
    "wel = flopy.modflow.ModflowWel(\n",
    "    mf,\n",
    "    stress_period_data={0: wel_spd},\n",
    "    ipakcb=53\n",
    ")\n",
    "\n",
    "print(\"WEL package created for lateral inflows.\")\n",
    "\n",
    "# Plot wells\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=modelgrid, ax=ax)\n",
    "pmv.plot_grid(alpha=0.2, linewidth=0.4)\n",
    "# Symbol size scaled (simple)\n",
    "for qlist, color, label in [(north_cells, 'cyan', 'North inflow cell'),\n",
    "                            (south_cells, 'magenta', 'South inflow cell')]:\n",
    "    ax.scatter(\n",
    "        modelgrid.xcellcenters[qlist['row'], qlist['col']],\n",
    "        modelgrid.ycellcenters[qlist['row'], qlist['col']],\n",
    "        c=color, s=50, edgecolors='k', linewidths=0.4, label=label\n",
    "    )\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "ax.set_title(\"Figure 26: Lateral inflow cells (WEL) forming the northern and southern inflow boundaries. The model boundary is shown in red. The background is the model top elevation.\")\n",
    "ax.set_xlabel(\"X (m)\")\n",
    "ax.set_ylabel(\"Y (m)\")\n",
    "ax.set_aspect('equal')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# Quick check: ensure no CHD overlap\n",
    "overlap = []\n",
    "if 'chd' in globals():\n",
    "    chd_cells_set = {(c[1], c[2]) for c in chd.stress_period_data[0]}\n",
    "    for w in wel_spd:\n",
    "        if (w[1], w[2]) in chd_cells_set:\n",
    "            overlap.append((w[1], w[2]))\n",
    "if overlap:\n",
    "    print(f\"Warning: {len(overlap)} WEL cells overlap CHD cells (they will be ignored by MODFLOW).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ec076",
   "metadata": {},
   "source": [
    "In Figure 26, we see the locations of the wells representing the lateral inflow from the hillsides. Now we add the groundwater abstractions in the Limmat valley. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the wells geopackage\n",
    "# Get the path to the well locations\n",
    "well_data_path = download_named_file(name='wells', data_type='gis')\n",
    "\n",
    "# Read the geopackage into a geopandas dataframe\n",
    "wells_gdf = gpd.read_file(well_data_path, layer='GS_GRUNDWASSERFASSUNGEN_OGD_P').to_crs(modelgrid.crs)\n",
    "\n",
    "# 1. Normalize / helper columns\n",
    "wells_gdf['GWR_PREFIX'] = (\n",
    "    wells_gdf['GWR_ID']\n",
    "    .astype(str)\n",
    "    .str.split('_', n=1).str[0]\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "wells_gdf['FASSBEZ_CLEAN'] = (\n",
    "    wells_gdf['FASSBEZ']\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# 2. Target ID prefixes (lowercase)\n",
    "target_ids = {'b010071', 'b010020', 'b010063'}\n",
    "mask_prefix = wells_gdf['GWR_PREFIX'].isin(target_ids)\n",
    "\n",
    "# 3. Location / construction type logic\n",
    "# Hardhof (substring match, case-insensitive) AND Horizontalbrunnen\n",
    "mask_hard = (\n",
    "    wells_gdf['FASSBEZ_CLEAN'].str.contains(r'hardhof brunnen', case=False, na=False)\n",
    "    & wells_gdf['FASSART'].str.contains('Horizontalbrunnen', case=False, na=False)\n",
    ")\n",
    "\n",
    "# Lochergut or Schlachthof (substring match) AND Vertikalbrunnen\n",
    "mask_loch_schl = (\n",
    "    wells_gdf['FASSBEZ_CLEAN'].str.contains('lochergut|schlachthof', case=False, na=False)\n",
    "    & wells_gdf['FASSART'].str.contains('Vertikalbrunnen', case=False, na=False)\n",
    ")\n",
    "\n",
    "# 4. Combine\n",
    "mask_final = mask_prefix & (mask_hard | mask_loch_schl)\n",
    "\n",
    "selected_wells = wells_gdf.loc[mask_final].copy()\n",
    "\n",
    "print(f\"Total wells: {len(wells_gdf)}\")\n",
    "print(f\"Matched target prefixes: {mask_prefix.sum()}\")\n",
    "print(f\"Hardhof horizontal matches: {mask_hard.sum()}\")\n",
    "print(f\"Lochergut/Schlachthof vertical matches: {mask_loch_schl.sum()}\")\n",
    "print(f\"Selected wells (final): {len(selected_wells)}\")\n",
    "\n",
    "display(\n",
    "    selected_wells[\n",
    "        ['GWR_ID','GWR_PREFIX','FASSBEZ','FASSART','FASSBEZ_CLEAN']\n",
    "    ].sort_values('GWR_ID')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e365de1",
   "metadata": {},
   "source": [
    "Now we assign the pumping rates to these selected wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a195c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define annual volumes (m3/year)\n",
    "hardhof_total_year = 7_000_000   # distributed over 4 Hardhof horizontal wells\n",
    "vertical_total_year = 600_000    # distributed over 2 vertical wells (Lochergut + Schlachthof)\n",
    "\n",
    "# Identify groups\n",
    "mask_hardhof = (\n",
    "    selected_wells['FASSBEZ_CLEAN'].str.contains('hardhof', case=False, na=False) &\n",
    "    selected_wells['FASSART'].str.contains('Horizontalbrunnen', case=False, na=False)\n",
    ")\n",
    "\n",
    "mask_vertical = (\n",
    "    selected_wells['FASSBEZ_CLEAN'].str.contains('lochergut|schlachthof', case=False, na=False) &\n",
    "    selected_wells['FASSART'].str.contains('Vertikalbrunnen', case=False, na=False)\n",
    ")\n",
    "\n",
    "n_hardhof = mask_hardhof.sum()\n",
    "n_vertical = mask_vertical.sum()\n",
    "\n",
    "# Expected counts (for even split)\n",
    "expected_hardhof = 4\n",
    "expected_vertical = 2\n",
    "\n",
    "if n_hardhof != expected_hardhof:\n",
    "    print(f\"Warning: Detected {n_hardhof} Hardhof horizontal wells (expected {expected_hardhof}). Rates still assigned evenly over detected count.\")\n",
    "\n",
    "if n_vertical != expected_vertical:\n",
    "    print(f\"Warning: Detected {n_vertical} vertical wells (expected {expected_vertical}). Rates still assigned evenly over detected count.\")\n",
    "\n",
    "# Per-well annual volumes (fallback to detected counts to avoid division by zero)\n",
    "hardhof_per_well_year = hardhof_total_year / (n_hardhof if n_hardhof else 1)\n",
    "vertical_per_well_year = vertical_total_year / (n_vertical if n_vertical else 1)\n",
    "\n",
    "# Convert to daily (365.25 days/year)\n",
    "hardhof_per_well_day = round(hardhof_per_well_year / 365.25)\n",
    "vertical_per_well_day = round(vertical_per_well_year / 365.25)\n",
    "\n",
    "# Initialize abstraction column (m3/day, negative = pumping)\n",
    "selected_wells['abstraction_m3_d'] = 0.0\n",
    "selected_wells.loc[mask_hardhof, 'abstraction_m3_d'] = -hardhof_per_well_day\n",
    "selected_wells.loc[mask_vertical, 'abstraction_m3_d'] = -vertical_per_well_day\n",
    "\n",
    "# Summary\n",
    "print(\"Assigned abstraction (m3/day per well):\")\n",
    "print(f\"  Hardhof horizontals: {hardhof_per_well_day:,.2f} (negative sign denotes pumping)\")\n",
    "print(f\"  Vertical (Lochergut/Schlachthof): {vertical_per_well_day:,.2f}\")\n",
    "\n",
    "display(\n",
    "    selected_wells[\n",
    "        ['GWR_ID','FASSBEZ','FASSART','abstraction_m3_d']\n",
    "    ].sort_values('GWR_ID')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f53527",
   "metadata": {},
   "source": [
    "Now we intersect the selected wells with the model grid to assign them to the appropriate grid cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38182213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: assign each well to (row,col) with robust handling of GridIntersect output\n",
    "ix = GridIntersect(modelgrid, method='vertex', rtree=True)\n",
    "\n",
    "# Pre-build KDTree for nearest-cell fallback (cell centers)\n",
    "xc = modelgrid.xcellcenters\n",
    "yc = modelgrid.ycellcenters\n",
    "centers_flat = np.column_stack([xc.ravel(), yc.ravel()])\n",
    "kdtree = cKDTree(centers_flat)\n",
    "\n",
    "def _extract_rc_from_intersect(res, ncol):\n",
    "    \"\"\"\n",
    "    Accepts possible return types from GridIntersect:\n",
    "      - numpy recarray with fields (row,col) or (cellids)\n",
    "      - pandas DataFrame with columns\n",
    "      - list/tuple of cellids\n",
    "    Returns (r, c) or raises ValueError.\n",
    "    \"\"\"\n",
    "    if res is None:\n",
    "        raise ValueError(\"Intersection result is None.\")\n",
    "    # Numpy structured / recarray\n",
    "    if isinstance(res, np.recarray):\n",
    "        names = res.dtype.names or ()\n",
    "        if len(res) == 0:\n",
    "            raise ValueError(\"Empty recarray.\")\n",
    "        if 'row' in names and 'col' in names:\n",
    "            return int(res['row'][0]), int(res['col'][0])\n",
    "        if 'cellids' in names:\n",
    "            cellid = int(res['cellids'][0])\n",
    "            r, c = divmod(cellid, ncol)\n",
    "            return r, c\n",
    "        # Fallback first numeric value\n",
    "        cellid = int(res[0])\n",
    "        r, c = divmod(cellid, ncol)\n",
    "        return r, c\n",
    "    # Pandas DataFrame\n",
    "    try:\n",
    "        import pandas as _pd\n",
    "        if isinstance(res, _pd.DataFrame):\n",
    "            if len(res) == 0:\n",
    "                raise ValueError(\"Empty DataFrame.\")\n",
    "            cols = res.columns\n",
    "            if 'row' in cols and 'col' in cols:\n",
    "                return int(res.iloc[0]['row']), int(res.iloc[0]['col'])\n",
    "            if 'cellids' in cols:\n",
    "                cellid = int(res.iloc[0]['cellids'])\n",
    "                r, c = divmod(cellid, ncol)\n",
    "                return r, c\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Iterable of cellids\n",
    "    if hasattr(res, '__iter__'):\n",
    "        seq = list(res)\n",
    "        if len(seq):\n",
    "            cellid = int(seq[0])\n",
    "            r, c = divmod(cellid, ncol)\n",
    "            return r, c\n",
    "    raise ValueError(\"Could not parse row/col from intersection result.\")\n",
    "\n",
    "well_cell_records = []\n",
    "skipped_inactive = 0\n",
    "skipped_chd = 0\n",
    "skipped_missing_rate = 0\n",
    "skipped_intersection = 0\n",
    "\n",
    "for _, w in selected_wells.iterrows():\n",
    "    geom = w.geometry\n",
    "    if geom is None or geom.is_empty:\n",
    "        continue\n",
    "\n",
    "    res = ix.intersect(geom)  # point intersection\n",
    "    try:\n",
    "        if res is None or len(res) == 0:\n",
    "            raise ValueError(\"Empty intersection\")\n",
    "        r, c = _extract_rc_from_intersect(res, modelgrid.ncol)\n",
    "    except Exception:\n",
    "        # Fallback: nearest cell center\n",
    "        dist, idx_flat = kdtree.query([geom.x, geom.y])\n",
    "        r, c = np.unravel_index(idx_flat, xc.shape)\n",
    "        skipped_intersection += 1\n",
    "\n",
    "    # Pumping rate\n",
    "    if 'abstraction_m3_d' not in w or pd.isna(w['abstraction_m3_d']):\n",
    "        skipped_missing_rate += 1\n",
    "        continue\n",
    "    flux = float(w['abstraction_m3_d'])\n",
    "\n",
    "    flag = ibound[0, r, c]\n",
    "    if flag == 0:\n",
    "        skipped_inactive += 1\n",
    "        continue\n",
    "    if flag == -1:\n",
    "        skipped_chd += 1\n",
    "        continue\n",
    "\n",
    "    well_cell_records.append((0, r, c, flux, w.get('GWR_ID', None)))\n",
    "\n",
    "print(f\"Wells mapped: {len(well_cell_records)}\")\n",
    "if skipped_intersection:  print(f\"  Used nearest-cell fallback: {skipped_intersection}\")\n",
    "if skipped_inactive:      print(f\"  Skipped inactive cells: {skipped_inactive}\")\n",
    "if skipped_chd:           print(f\"  Skipped CHD cells: {skipped_chd}\")\n",
    "if skipped_missing_rate:  print(f\"  Skipped missing rate: {skipped_missing_rate}\")\n",
    "\n",
    "# Merge with existing WEL (lateral inflows)\n",
    "existing_spd = wel.stress_period_data[0]\n",
    "combined = {}\n",
    "for rec in existing_spd:\n",
    "    key = (int(rec['k']), int(rec['i']), int(rec['j']))\n",
    "    combined[key] = combined.get(key, 0.0) + float(rec['flux'])\n",
    "\n",
    "for k, r, c, flux, wid in well_cell_records:\n",
    "    key = (k, r, c)\n",
    "    combined[key] = combined.get(key, 0.0) + flux\n",
    "\n",
    "new_wel_spd = [[k, r, c, f] for (k, r, c), f in combined.items()]\n",
    "\n",
    "mf.remove_package('WEL')\n",
    "wel = flopy.modflow.ModflowWel(\n",
    "    mf,\n",
    "    stress_period_data={0: new_wel_spd},\n",
    "    ipakcb=53\n",
    ")\n",
    "\n",
    "print(f\"Total WEL cells (inflow + pumping): {len(new_wel_spd)}\")\n",
    "total_injection = sum(f for _,_,_,f in new_wel_spd if f > 0)\n",
    "total_pumping  = sum(f for _,_,_,f in new_wel_spd if f < 0)\n",
    "print(f\"  Injection total (m3/d): {total_injection:,.2f}\")\n",
    "print(f\"  Pumping   total (m3/d): {total_pumping:,.2f}\")\n",
    "\n",
    "# Quick plot of pumping vs injection cells\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mf.modelgrid, ax=ax)\n",
    "pmv.plot_grid(alpha=0.15, linewidth=0.4)\n",
    "pmv.plot_ibound()\n",
    "pmv.plot_bc(package=wel)\n",
    "ax.set_title(\"Figure 27: WEL cells: Lateral inflow and pumping (red). IBOUND with inactive (black), active (white) and CHD (blue) boundaries.\")\n",
    "ax.set_xlabel(\"X (m)\")\n",
    "ax.set_ylabel(\"Y (m)\")\n",
    "ax.set_aspect('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301d6982",
   "metadata": {},
   "source": [
    "Figure 27 shows the finished plot of WEL cells, illustrating the spatial distribution of lateral inflow and pumping cells within the model domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b9e63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c4aa1d",
   "metadata": {},
   "source": [
    "## 5 Solver and Output Control (PCG & OC Packages)\n",
    "\n",
    "We need to tell MODFLOW how to solve the system of equations. The **Preconditioned Conjugate-Gradient (PCG)** package is a robust and commonly used solver. We also need to specify what results we want to save using the **Output Control (OC)** package. We are interested in saving the head and budget results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc696cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Solver and Output Control ---\n",
    "# Add the PCG solver\n",
    "pcg = flopy.modflow.ModflowPcg(\n",
    "    mf, \n",
    "    mxiter=200,  # Maximum number of iterations\n",
    "    iter1=100,  # Number of iterations for the first stage\n",
    "    hclose = 1e-3,  # Head change convergence criterion\n",
    "    rclose = 1e-1,  # Residual convergence criterion\n",
    "    damp=0.7  # Damping factor\n",
    ")\n",
    "\n",
    "# Specify output control\n",
    "oc = flopy.modflow.ModflowOc(\n",
    "    mf, \n",
    "    # Save head and budget at the end of each stress period\n",
    "    stress_period_data={(0, 0): ['save head', 'save budget']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d37f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_nested_step_completion_marker(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b024aaf9",
   "metadata": {},
   "source": [
    "## 6 Run the model\n",
    "Now that we have defined all the necessary packages, we can run the model. We will use the `write_input` method to write all the input files and then use the `run_model` method to execute the simulation.\n",
    "\n",
    "### 6.1 Write and inspect input files\n",
    "We start by writing the input files using the `write_input` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write input files\n",
    "mf.write_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aba007",
   "metadata": {},
   "source": [
    "Please find the newly created files in your working directory. You should see a list of files called limmat_valley_model with different file endings, reflecting the package structure of a MODFLOW model, for example: \n",
    "- .nam\n",
    "- .dis\n",
    "- .bas\n",
    "- .lpf\n",
    "- .pcg\n",
    "- .oc\n",
    "All of the above files can be opened in your default text editor. Since flopy conveniently handles reading and writing of these files for us, we will not go into detail about the contents of each package. We do, however, want to highlight the importance of the following file for debugging your model:\n",
    "\n",
    "#### .nam file\n",
    "The .nam file is the name file for the MODFLOW model. It contains the names of all the input files that MODFLOW will use during the simulation. This file is essential for running the model, as it tells MODFLOW where to find the necessary input data.  \n",
    "\n",
    "You can check if all the required input files are listed in the .nam file by opening it in a text editor and verifying the file names.\n",
    "\n",
    "### 6.2 Check if the modflow model setup is consistent\n",
    "Modflow has a model check utility that can be used to verify the consistency of the model setup. This utility checks for common errors and inconsistencies in the model input files, such as missing or misconfigured packages, and provides helpful error messages to guide the user in fixing any issues.\n",
    "\n",
    "Be prepared to address any errors or warnings that the utility may find before proceeding with the model simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run FloPy's built-in input checker (prints a summary)\n",
    "chk = mf.check(f=None, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3069312",
   "metadata": {},
   "source": [
    "You might encounter errors and warnings in the model check. For example if the starting heads are below the new bottom elevations plus the clearance, this will trigger a warning. Or if hydraulic parameters are not properly defined. You will then have to follow up on these issues before proceeding.\n",
    "\n",
    "### 6.3 Model Simulation (WORK IN PROGRESS)\n",
    "We now attempt a forward simulation to observe the model behavior over time. run_model will produce an output file that contains the simulation results (.list). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e766ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "success, buff = mf.run_model(silent=True, report=True)\n",
    "\n",
    "# We print the last lines of the listing file in case the model run fails.\n",
    "if not success:\n",
    "    print(\"Model did not run successfully. Reading listing file tail...\")\n",
    "    lst_path = os.path.join(workspace, f\"{model_name}.list\")\n",
    "    if os.path.exists(lst_path):\n",
    "        with open(lst_path, \"r\", errors=\"ignore\") as f:\n",
    "            lst_tail = f.read().splitlines()[-200:]\n",
    "        print(\"---- tail of listing (.list) ----\")\n",
    "        print(\"\\n\".join(lst_tail))\n",
    "    else:\n",
    "        print(f\"Listing file not found at: {lst_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f832bd",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "Boff, our model ran dry! We need to investigate the model setup, particularly the initial conditions and the boundary conditions applied to the constant head cells. Since the river leakage is our best bet to tweak the model fluxes in a physically meaningful way, let's try increasing the river conductivity by a factor of 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97115add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model geometry with ibound and riv, highlight the cell at row 21 and column 1. \n",
    "# Target MODFLOW indices (1-based from listing) -> Python (0-based)\n",
    "modflow_layer = 1\n",
    "modflow_row = 21\n",
    "modflow_col = 1\n",
    "k = modflow_layer - 1\n",
    "i = modflow_row - 1\n",
    "j = modflow_col - 1\n",
    "\n",
    "# Safety checks\n",
    "if not hasattr(mf, \"modelgrid\"):\n",
    "    raise RuntimeError(\"mf.modelgrid not set.\")\n",
    "if i < 0 or j < 0 or i >= mf.modelgrid.nrow or j >= mf.modelgrid.ncol:\n",
    "    raise ValueError(\"Requested cell (row/col) outside grid.\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,9))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=mf.modelgrid, ax=ax)\n",
    "\n",
    "# Plot IBOUND (active=1, inactive=0, CHD=-1)\n",
    "if 'bas' in globals():\n",
    "    pmv.plot_ibound(ibound=bas.ibound.array, color_noflow='lightgrey', color_ch='orange')\n",
    "\n",
    "# Plot river boundary (RIV package)\n",
    "if 'riv' in globals():\n",
    "    pmv.plot_bc(package=riv, color='deepskyblue', linewidths=1.4)\n",
    "\n",
    "# Optional: CHD cells (if you want them visible distinctly)\n",
    "if 'chd' in globals():\n",
    "    pmv.plot_bc(package=chd, color='navy', linewidths=1.2)\n",
    "\n",
    "# Highlight target cell\n",
    "verts = mf.modelgrid.get_cell_vertices(i, j)\n",
    "poly = mpatches.Polygon(verts, facecolor='none', edgecolor='red', linewidth=2.2, linestyle='--')\n",
    "ax.add_patch(poly)\n",
    "\n",
    "# Mark center\n",
    "xc = mf.modelgrid.xcellcenters[i, j]\n",
    "yc = mf.modelgrid.ycellcenters[i, j]\n",
    "ax.scatter([xc], [yc], c='red', s=70, marker='x', zorder=5)\n",
    "ax.text(xc, yc, f\"R{modflow_row}C{modflow_col}\", color='red', fontsize=9,\n",
    "        ha='left', va='bottom')\n",
    "\n",
    "ax.set_title(f\"IBOUND, RIV cells, highlighted CHD cell (R{modflow_row} C{modflow_col})\")\n",
    "ax.set_xlabel(\"X (m)\")\n",
    "ax.set_ylabel(\"Y (m)\")\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# Simple legend handles\n",
    "handles = []\n",
    "handles.append(mlines.Line2D([], [], color='deepskyblue', lw=2, label='RIV'))\n",
    "if 'chd' in globals():\n",
    "    handles.append(mlines.Line2D([], [], color='navy', lw=2, label='CHD'))\n",
    "handles.append(mlines.Line2D([], [], color='red', lw=2, linestyle='--', label='Highlighted cell'))\n",
    "ax.legend(handles=handles, loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17be431",
   "metadata": {},
   "source": [
    "The problematic cell is all the way to the right of the aquifer in flow direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ffbd87",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce690b82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc60254d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2e521f9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's try reducing the hydraulic conductivities in the model by a factor of 10 and see if that resolves the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce hydraulic conductivities in the layer property flow package by a factor of 10\n",
    "def scale_lpf_conductivity(lpf_obj, factor, rebuild=False):\n",
    "    \"\"\"\n",
    "    Scale hk and vka one time.\n",
    "    rebuild=True recreates the LPF package (use if in-place edit causes issues).\n",
    "    \"\"\"\n",
    "    if hasattr(lpf_obj, \"_scaled_flag\"):\n",
    "        print(f\"Already scaled by {lpf_obj._scaled_flag}; skipping.\")\n",
    "        return lpf_obj\n",
    "\n",
    "    if not rebuild:\n",
    "        # In-place edit (fast & typical)\n",
    "        lpf_obj.hk.array *= factor\n",
    "        lpf_obj.vka.array *= factor\n",
    "        lpf_obj._scaled_flag = factor\n",
    "        print(f\"In-place scaled hk & vka by {factor}.\")\n",
    "        return lpf_obj\n",
    "    else:\n",
    "        # Full rebuild\n",
    "        mf = lpf_obj.parent\n",
    "        hk_new = lpf_obj.hk.array * factor\n",
    "        vka_new = lpf_obj.vka.array * factor\n",
    "\n",
    "        sy = lpf_obj.sy.array if lpf_obj.sy is not None else 0.0\n",
    "        ss = lpf_obj.ss.array if lpf_obj.ss is not None else 0.0\n",
    "        laytyp = lpf_obj.laytyp.array if lpf_obj.laytyp is not None else 0\n",
    "        laywet = lpf_obj.laywet.array if lpf_obj.laywet is not None else None\n",
    "\n",
    "        mf.remove_package(\"LPF\")\n",
    "        new_lpf = flopy.modflow.ModflowLpf(\n",
    "            mf,\n",
    "            hk=hk_new,\n",
    "            vka=vka_new,\n",
    "            sy=sy,\n",
    "            ss=ss,\n",
    "            laytyp=laytyp,\n",
    "            ipakcb=lpf_obj.ipakcb,\n",
    "            hdry=lpf_obj.hdry,\n",
    "            wetfct=lpf_obj.wetfct,\n",
    "            iwetit=lpf_obj.iwetit,\n",
    "            laywet=laywet,\n",
    "        )\n",
    "        new_lpf._scaled_flag = factor\n",
    "        print(f\"Rebuilt LPF with hk & vka scaled by {factor}.\")\n",
    "        return new_lpf\n",
    "\n",
    "# Scale K by 0.1 \n",
    "scale_lpf_conductivity(lpf, 0.1, rebuild=True)\n",
    "\n",
    "# Re-write the input files\n",
    "mf.write_input()\n",
    "\n",
    "# Re-check the model\n",
    "mf.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef07c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "success, buff = mf.run_model(silent=True, report=True)\n",
    "\n",
    "# We print the last lines of the listing file in case the model run fails.\n",
    "if not success:\n",
    "    print(\"Model did not run successfully. Reading listing file tail...\")\n",
    "    lst_path = os.path.join(workspace, f\"{model_name}.list\")\n",
    "    if os.path.exists(lst_path):\n",
    "        with open(lst_path, \"r\", errors=\"ignore\") as f:\n",
    "            lst_tail = f.read().splitlines()[-200:]\n",
    "        print(\"---- tail of listing (.list) ----\")\n",
    "        print(\"\\n\".join(lst_tail))\n",
    "    else:\n",
    "        print(f\"Listing file not found at: {lst_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f7d2d",
   "metadata": {},
   "source": [
    "### 6.4 Typical run-time issues in MODFLOW (with Flopy) — and how to fix them\n",
    "Don't despair if your model doesn't run successfully (this is the default). Here are some common issues and strategies of how to fix them:\n",
    "\n",
    "- Geometry conflicts (negative thickness / inverted layers): top < botm or botm(k-1) < botm(k) causes aborts.\n",
    "Fix: enforce a minimum thickness, repair ordering top→bottom, deactivate outcrops; add assertions after building arrays.\n",
    "\n",
    "- Dry/oscillating heads: cells go dry near rivers/wells or heads bounce and won’t converge.\n",
    "Fix: enable LPF wetting (IWETIT, WETFCT), reduce time-step size (smaller DELT/nper), moderate boundary conductances, refine grid or smooth parameter contrasts.\n",
    "\n",
    "- Convergence failures (solver): “failed to converge” with large mass-balance errors.\n",
    "Fix: tighten or relax tolerances sensibly (HCLOSE, RCLOSE), increase iteration limits (MXITER, ITER1), switch/improve solver (e.g., PCG→GMG if available), reduce parameter contrasts, shorten stress periods.\n",
    "\n",
    "- Units & magnitudes off: m/s vs m/d, recharge too large, conductance orders-of-magnitude high.\n",
    "Fix: decide on a consistent unit system (m, days), back-calc plausible ranges (e.g., riv conductance), sanity-check budgets.\n",
    "\n",
    "- Bad/stale stress data: stage below riverbed, wells in inactive cells, missing data in later stress periods.\n",
    "Fix: validate every SP: river stage > rbot, stresses only on active cells, explicitly provide or carry forward data for each period.\n",
    "\n",
    "- Package/grid size mismatches: array shapes don’t match nlay/nrow/ncol.\n",
    "Fix: check shapes before write_input(), broadcast carefully, and inspect warnings in the .lst.\n",
    "\n",
    "- Executable & workspace issues: wrong exe_name, files not written, or running in another folder.\n",
    "Fix: call m.write_input(), verify m.exe_name, set a clean model_ws, then success, buff = m.run_model(report=True).\n",
    "\n",
    "**Diagnosing quickly**: always read the list file for the first failing step, check water budget residuals, and plot heads/budgets after each run to see where issues originate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407cd8ba",
   "metadata": {},
   "source": [
    "## 7 Visualize results for first sanity checks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gw_course_students",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
