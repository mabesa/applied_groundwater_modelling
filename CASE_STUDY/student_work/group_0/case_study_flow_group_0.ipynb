{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d67353",
   "metadata": {},
   "source": [
    "Groundwater | Case Study\n",
    "# Template Student Task: Groundwater Well Group Impact Assessment\n",
    "Dr. Xiang-Zhao Kong & Dr. Beatrice Marti & Louise Noël du Payrat\n",
    "\n",
    "## 1 Overview and Learning Objectives\n",
    "\n",
    "In this case study, you are tasked with **evaluating the impact of a well group on the regional groundwater flow field** through a comprehensive three-stage modeling approach:\n",
    "\n",
    "1. **Base model (no wells)**: Regional groundwater conditions without your assigned well group operating\n",
    "2. **Base model with wells**: Current groundwater extraction/injection rates at your assigned well group implemented in the telescope submodel\n",
    "3. **Scenario conditions**: Modified forcing conditions (e.g., changed recharge, boundary conditions, or pumping rates) implemented in the regional model, with impacts assessed through the telescope submodel\n",
    "\n",
    "This notebook demonstrates the complete **telescope modeling workflow** (also called sub-modeling or child modeling approach) that you will use to complete your assessment. The telescope approach involves:\n",
    "\n",
    "- Creating a **high-resolution submodel** in the area of interest around your well group\n",
    "- Extracting **boundary conditions** from the regional parent model to properly nest the submodel\n",
    "- Running three sequential simulations to assess cumulative and scenario-specific impacts\n",
    "- Comparing results to quantify changes in groundwater flow patterns, drawdowns, and capture zones\n",
    "\n",
    "\n",
    "### 1.1 Why Use the Telescope Approach?\n",
    "\n",
    "The telescope approach is essential because:\n",
    "- **Computational efficiency**: We can achieve fine-scale resolution (5m cells) around wells without requiring the entire regional model to be refined\n",
    "- **Proper boundary conditions**: The submodel receives realistic boundary conditions from the regional model simulation\n",
    "- **Scale-appropriate analysis**: Local well impacts require high resolution that regional models cannot provide efficiently\n",
    "- **Industry standard**: This nested modeling approach is widely used in professional groundwater consulting\n",
    "- **Scenario flexibility**: Changes to regional forcings can be easily propagated to the local scale\n",
    "\n",
    "### 1.2 Three-Stage Modeling Workflow\n",
    "\n",
    "**Stage 1: Base Regional Model (No Wells)**\n",
    "- Run regional model without well group to establish baseline conditions\n",
    "- Extract boundary conditions for telescope submodel\n",
    "- Document natural groundwater flow patterns in the submodel\n",
    "\n",
    "**Stage 2: Base Model with Wells**  \n",
    "- Implement well group in telescope submodel using Stage 1 boundary conditions\n",
    "- Assess direct impact of well operations on local flow field\n",
    "- Quantify drawdowns and capture zones under current conditions\n",
    "\n",
    "**Stage 3: Scenario Assessment**\n",
    "- Modify forcing conditions in regional model (e.g., changed recharge, boundary conditions)\n",
    "- Re-extract boundary conditions from updated regional model\n",
    "- Run telescope submodel with new boundary conditions to assess combined impacts\n",
    "- Compare Stage 3 vs Stage 2 in the submodel to isolate scenario-specific effects\n",
    "\n",
    "### 1.3 Your Task\n",
    "\n",
    "1. **Copy and adapt this notebook** for your specific well group configuration\n",
    "2. **Modify the parameters** in the case_config.yaml and in your copy of this notebook (group number, buffer distances, pumping rates) as needed for your assignment\n",
    "3. **Execute the three-stage workflow** systematically\n",
    "4. **Analyze and compare results** between all three stages to understand:\n",
    "   - Direct well impacts (Stage 2 vs Stage 1)\n",
    "   - Scenario impacts (Stage 3 vs Stage 2)  \n",
    "   - Combined effects (Stage 3 vs Stage 1)\n",
    "5. **Document your findings** for inclusion in your final report and presentation\n",
    "\n",
    "The results from your three-stage submodel analysis will form a key component of your **final report and presentation**, demonstrating your understanding of groundwater flow processes, numerical modeling techniques, and scenario assessment at multiple scales.\n",
    "\n",
    "3. **Execute the three-stage workflow** systematically\n",
    "4. **Analyze and compare results** between all three stages to understand:\n",
    "   - Direct well impacts (Stage 2 vs Stage 1)\n",
    "   - Scenario impacts (Stage 3 vs Stage 2)  \n",
    "   - Combined effects (Stage 3 vs Stage 1)\n",
    "5. **Document your findings** for inclusion in your final report and presentation\n",
    "\n",
    "### 1.4 Essential Checklist - Search for #TODO in Your Code\n",
    "\n",
    "Before running your analysis, **search for \"#TODO\" in your notebook copy** to find all locations requiring your attention. Key items to verify:\n",
    "\n",
    "**Model Configuration:**\n",
    "- [ ] **Group number** matches your assignment in case_config.yaml\n",
    "- [ ] **Well pumping rates** reflect actual concessioned rates from maps.zh.ch\n",
    "- [ ] **Buffer distances** are adequate for your well field (check 10+ day travel times)\n",
    "- [ ] **Cell size** provides sufficient resolution around wells (typically 5m or finer)\n",
    "\n",
    "**Boundary Conditions:**\n",
    "- [ ] **Submodel extent** captures full zone of influence from your wells\n",
    "- [ ] **Boundary extraction** properly maps heads from parent to submodel grid\n",
    "\n",
    "**Well Implementation:**\n",
    "- [ ] **Well locations** correctly mapped to active (non-CHD) cells\n",
    "- [ ] **Pumping/injection rates** assigned according to well type (negative for extraction, positive for injection)\n",
    "\n",
    "**Quality Control:**\n",
    "- [ ] **Mass balance** acceptable (<1% error) for all model runs  \n",
    "- [ ] **Flow patterns** consistent with regional hydrogeology\n",
    "- [ ] **Convergence** achieved within iteration limits\n",
    "\n",
    "**Analysis Requirements:**\n",
    "- [ ] **Three-stage comparison** completed with clear quantification of impacts\n",
    "- [ ] **Results documentation** prepared for final report and presentation\n",
    "\n",
    "The results from your three-stage submodel analysis will form a key component of your **final report and presentation**, demonstrating your understanding of groundwater flow processes, numerical modeling techniques, and scenario assessment at multiple scales.\n",
    "\n",
    "**⚠️ Important:** If your initial results show well impacts extending to the submodel boundaries, **increase your buffer distances and re-run the analysis**. The submodel domain must be large enough to contain the zone of influence.\n",
    "\n",
    "### 1.4 Expected Deliverables\n",
    "\n",
    "Your analysis should quantify:\n",
    "- Changes in hydraulic head distribution around the well field\n",
    "- Modifications to groundwater flow directions and magnitudes  \n",
    "- Impacts on capture zones and areas of influence\n",
    "- Mass balance considerations and boundary interactions\n",
    "- Assessment of potential impacts on neighboring wells or environmental features\n",
    "\n",
    "Let's begin by implementing the telescope modeling workflow for your assigned well group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c8698a",
   "metadata": {},
   "source": [
    "## 2 Create the Telescope Submodel sub_base\n",
    "\n",
    "This notebook demonstrates how to create a refined submodel around wells using the same boundary polygon approach and grid generation workflow established in notebook 4. Instead of working directly with grid indices, we'll create a proper boundary polygon for the submodel domain and then apply the proven workflow.\n",
    "\n",
    "### 2.1 Approach Overview\n",
    "\n",
    "1. **Load base model and identify wells** from case study configuration\n",
    "2. **Define buffer distances** around wells based on hydrogeological considerations  \n",
    "3. **Create submodel boundary polygon** using buffer distances\n",
    "4. **Generate refined grid** using the same workflow from notebook 4\n",
    "5. **Extract boundary conditions** from parent model results\n",
    "6. **Extract and interpolate aquifer properties** to the refined grid ()\n",
    "7. **Set up and run** the complete submodel\n",
    "\n",
    "This approach ensures consistency with the established grid generation methodology while providing the fine-scale resolution needed around wells.\n",
    "\n",
    "### 2.2 Set Up Your Working Environment \n",
    "#### 2.2.1 Configure your Group Information\n",
    "Your first task is to configure your group information in the case_config.yaml file located in your group's working folder. This file contains essential metadata about your group and will be used throughout the case study.\n",
    "\n",
    "`#TODO`: Update your group number in case_config.yaml in your groups working folder\n",
    "\n",
    "> **Example:** CASE_STUDY/student_work/group_0/case_config.yaml\n",
    "> \n",
    "> Below, you see example content of case_config.yaml. Look for #TODO in the yaml file and update the group number and authors accordingly. \n",
    ">\n",
    "> ```yaml\n",
    "> group:   \n",
    ">   number: 0               # TODO: integer group number (0-8).  \n",
    ">   authors:                # TODO: list all group members (2–3 persons).  \n",
    ">     - \"Hedwig Muster\"   \n",
    ">     - \"Karl Beispiel\"     # add third if needed    \n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1392449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.affinity import rotate\n",
    "import flopy\n",
    "from flopy.discretization import StructuredGrid\n",
    "\n",
    "# print current working directory\n",
    "print(\"Current working directory: \", os.getcwd())\n",
    "\n",
    "# Add the support repo to the path\n",
    "sys.path.append(os.path.abspath('../../../SUPPORT_REPO/src'))\n",
    "sys.path.append(os.path.abspath('../../../SUPPORT_REPO/src/scripts/scripts_exercises'))\n",
    "\n",
    "# Import local modules\n",
    "import case_utils \n",
    "from data_utils import download_named_file, get_default_data_folder\n",
    "import grid_utils\n",
    "from print_images import display_image\n",
    "import plot_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27104b42",
   "metadata": {},
   "source": [
    "#### 2.2.2 Load Base Model \n",
    "\n",
    "We'll load the parent MODFLOW model and identify well locations from the case study configuration. This follows the same approach as the case study template but focuses on creating a proper submodel domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load case study configuration\n",
    "CASE_YAML = 'case_config.yaml'\n",
    "cfg = case_utils.load_yaml(CASE_YAML)\n",
    "\n",
    "# Get group configuration\n",
    "group_number = cfg['group'].get('number', 0)\n",
    "if not isinstance(group_number, int) or group_number < 0 or group_number > 8:\n",
    "    raise ValueError(\"Group number must be an integer between 0 and 8.\")\n",
    "\n",
    "print(f\"Group number: {group_number}\")\n",
    "\n",
    "# Download parent base model and save it to your workspace\n",
    "parent_base_model_name = cfg['model']['data_name']\n",
    "parent_base_model_path = download_named_file(\n",
    "    parent_base_model_name, \n",
    "    data_type='baseline_model',\n",
    ")\n",
    "\n",
    "# Handle zip file extraction if needed\n",
    "if parent_base_model_path.endswith('.zip'):\n",
    "    import zipfile\n",
    "    extract_path = os.path.dirname(parent_base_model_path)\n",
    "    with zipfile.ZipFile(parent_base_model_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "    parent_base_model_path = os.path.join(extract_path, parent_base_model_name + '.nam')\n",
    "\n",
    "print(f'Downloaded the parent base model to path: {parent_base_model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4768a9f7",
   "metadata": {},
   "source": [
    "#### 2.2.3 Define names & paths for scenarios and base model\n",
    "We will define the names and paths for the base model and scenarios based on your group configuration.\n",
    "\n",
    "We will have multiple models we are running in this case study: \n",
    "- Parent base model (as developed in notebook 4): Identified with prefix `parent_base`  \n",
    "- Submodel with boundary conditions from parent base model: Identified with prefix `submodel_base`\n",
    "- Submodel with boundary conditions from parent base model and wells implemented: Identified with prefix `submodel_wells`\n",
    "- Parent model with scenario conditions (e.g., changed recharge, boundary conditions): Identified with prefix `parent_scenario`\n",
    "- Submodel with boundary conditions from parent scenario model and wells implemented: Identified with prefix `submodel_scenario`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9662003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each model, we will create a dedicated output workspace\n",
    "parent_base_ws = os.path.expanduser(cfg['output']['workspace'])\n",
    "# Add group number to path and add sub-directory for the parent base model\n",
    "parent_base_ws = parent_base_ws + str(group_number) + \"/parent_base\"\n",
    "case_utils.ensure_dir(parent_base_ws)\n",
    "# Set up workspace for parent scenario model\n",
    "parent_scenario_ws = parent_base_ws.replace('parent_base', 'parent_scenario')\n",
    "case_utils.ensure_dir(parent_scenario_ws)\n",
    "\n",
    "# Set up workspace for submodels\n",
    "sub_base_ws = parent_base_ws.replace('parent_base', 'sub_base')\n",
    "case_utils.ensure_dir(sub_base_ws)\n",
    "sub_wells_ws = parent_base_ws.replace('parent_base', 'sub_wells')\n",
    "case_utils.ensure_dir(sub_wells_ws)\n",
    "sub_scenario_ws = parent_base_ws.replace('parent_base', 'sub_scenario')\n",
    "case_utils.ensure_dir(sub_scenario_ws)\n",
    "\n",
    "# Set up a folder to store comparison plots and analysis\n",
    "results_ws = parent_base_ws.replace('parent_base', 'results')\n",
    "case_utils.ensure_dir(results_ws)\n",
    "\n",
    "# Set up a folder to store grid files and shapefiles\n",
    "grids_ws = parent_base_ws.replace('parent_base', 'grids')\n",
    "case_utils.ensure_dir(grids_ws)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639b85ea",
   "metadata": {},
   "source": [
    "#### 2.2.4 Inspect the Parent Base Model and save to your workspace\n",
    "In this section, we load the groundwater flow model we have developed in notebook 4. This is the parent base model without wells. We will inspect the model and save a copy to your workspace for further processing.\n",
    "\n",
    "##### Load & Copy Parent Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d78e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the baseline model\n",
    "namefile = cfg['model']['namefile']  # Name of your model files, does not change\n",
    "print(f'Loading parent base model from namefile: {namefile}')\n",
    "print(f'From folder: {os.path.dirname(parent_base_model_path)}')\n",
    "m_parent_base = flopy.modflow.Modflow.load(\n",
    "    namefile, \n",
    "    model_ws=os.path.dirname(parent_base_model_path),\n",
    "    forgive=True, \n",
    "    check=False, \n",
    "    exe_name='mfnwt'\n",
    ")\n",
    "# Change workspace to the new directory parent_base_ws\n",
    "m_parent_base.model_ws = parent_base_ws\n",
    "# Write all input files to the new location\n",
    "m_parent_base.write_input()\n",
    "\n",
    "print(f'Loaded parent base model: {m_parent_base.name}')\n",
    "print(f'Input files written to: {parent_base_ws}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd42567",
   "metadata": {},
   "source": [
    "##### Steady-State Groundwater Heads of Base Model\n",
    "In this section, we visualize the steady-state groundwater heads from the parent base model. This allows us to check if the model output is ready for further analysis. It further provides a reference for understanding the natural groundwater flow conditions before implementing wells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e9ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Load model results ----- #\n",
    "# Check if heads file exists, if not run the model\n",
    "parent_hds_path = os.path.join(parent_base_ws, f\"{m_parent_base.name}.hds\")\n",
    "if not os.path.exists(parent_hds_path):\n",
    "    print(\"Parent model heads file not found. Running parent model...\")\n",
    "    success, buff = m_parent_base.run_model(silent=True, report=True)\n",
    "    if not success:\n",
    "        raise RuntimeError(\"Parent model failed to run\")\n",
    "    print(\"✓ Parent model run completed\")\n",
    "\n",
    "# Load and visualize groundwater heads\n",
    "headobj = flopy.utils.HeadFile(parent_hds_path)\n",
    "print(f'Heads loaded from {parent_hds_path}')\n",
    "heads = headobj.get_data()[0]  # Layer 0, stress period 0\n",
    "\n",
    "\n",
    "# ----- Create visualization ----- #\n",
    "# Create visualization\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "# Plot model with heads\n",
    "pmv = flopy.plot.PlotMapView(model=m_parent_base, ax=ax)\n",
    "\n",
    "# Plot head distribution as colored background\n",
    "heads_masked = np.ma.masked_where(m_parent_base.bas6.ibound.array[0] <= 0, heads)\n",
    "im = pmv.plot_array(heads_masked, alpha=0.6, cmap='Blues')\n",
    "\n",
    "# Add head contours\n",
    "contour_levels = np.linspace(np.nanmin(heads_masked), np.nanmax(heads_masked), 15)\n",
    "cont = pmv.contour_array(heads_masked, levels=contour_levels, colors='black', \n",
    "                        linewidths=1.5, linestyles='-')\n",
    "ax.clabel(cont, inline=True, fontsize=9, fmt='%.1f m')\n",
    "\n",
    "# Plot model grid (light)\n",
    "pmv.plot_grid(color='gray', alpha=0.3, linewidth=0.5)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.3, pad=0.02)\n",
    "cbar.set_label('Hydraulic Head (m a.s.l.)', fontsize=12)\n",
    "\n",
    "# Formatting\n",
    "ax.set_title(f'Parent Base Model - Groundwater Flow Field\\nGroup {group_number} - Hydraulic Heads', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('X Coordinate (m)', fontsize=12)\n",
    "ax.set_ylabel('Y Coordinate (m)', fontsize=12)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# Add text box with model info\n",
    "info_text = f'Model: {m_parent_base.name}\\nGrid: {m_parent_base.nrow}×{m_parent_base.ncol}\\nCell size: {m_parent_base.dis.delr[0]:.0f}m'\n",
    "ax.text(0.02, 0.98, info_text, transform=ax.transAxes, fontsize=10,\n",
    "        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea19982",
   "metadata": {},
   "source": [
    "### 2.3 Identify Well Locations and Define Buffer Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb8d55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the rotated model grid for visualization\n",
    "print(f\"Constructiong modelgrid_path:\")\n",
    "modelgrid_path = os.path.join(os.path.dirname(parent_base_model_path), f\"{namefile.replace('.nam', '')}_modelgrid.pkl\")\n",
    "with open(modelgrid_path, 'rb') as f:\n",
    "    parent_modelgrid = pickle.load(f)\n",
    "\n",
    "print(f\"Parent model grid loaded\")\n",
    "print(f\"Grid rotation: {parent_modelgrid.angrot} degrees\")\n",
    "print(f\"Grid extent: X [{parent_modelgrid.extent[0]:.1f}, {parent_modelgrid.extent[1]:.1f}]\")\n",
    "print(f\"             Y [{parent_modelgrid.extent[2]:.1f}, {parent_modelgrid.extent[3]:.1f}]\")\n",
    "\n",
    "# Get well locations for the specified group\n",
    "scenario = case_utils.get_scenario_for_group(CASE_YAML, group_number)\n",
    "concession_id = scenario.get('concession', None)\n",
    "if concession_id is None:\n",
    "    raise ValueError(f\"Concession ID not defined for group {group_number}\")\n",
    "\n",
    "# Load and filter wells by concession\n",
    "well_data_path = download_named_file(name='wells', data_type='gis')\n",
    "wells_gdf = gpd.read_file(well_data_path, layer='GS_GRUNDWASSERFASSUNGEN_OGD_P')\n",
    "wells_gdf = case_utils.filter_wells_by_concession(wells_gdf, concession_id)\n",
    "\n",
    "print(f\"\\nWells for concession {concession_id}:\")\n",
    "print(wells_gdf[['GWR_ID', 'GWR_PREFIX', 'FASSART']])\n",
    "\n",
    "# Visualize wells on parent model\n",
    "case_utils.plot_wells_on_model(m_parent_base, modelgrid=parent_modelgrid, wells_gdf=wells_gdf, \n",
    "                               concession_id=concession_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b701379b",
   "metadata": {},
   "source": [
    "[maps.zh.ch](maps.zh.ch) shows the concessioned pumping rates for our well group 210 (zoom into the area where your groups wells are located and look for your groops concession number). For the demo case, we look for b1-210 where b1 is the indicator for the Limmat valley aquifer and 210 is the concession number. Click on that number to see the concessioned pumping rates in the Info sidepane (Look for \"Konzessionierte Entnahmemenge [l/min]\"). In our case, the concessioned pumping rate is 1400 l/s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1aeadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(\n",
    "    image_filename='case_study_0_concessioned_pumping_rates.png', \n",
    "    image_folder='0_case_study_demo',\n",
    "    caption='Figure 5: Printscreen of the groundwater map of the Canton of Zurich (Grundwasserkarte, Mittelwasserstand, maps.zh.ch) Concessioned pumping rates for well group 210. The concessioned pumping rate is 1400 l/s.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c26a0",
   "metadata": {},
   "source": [
    "We can therefore define the pumping and infiltration rates to be 1400 l/s for our well group 210."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbdcbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_rates_m3d = 1400 / 1000 * 86400  # 1400 l/s converted to m3/day\n",
    "round(well_rates_m3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e867251a",
   "metadata": {},
   "source": [
    "`#TODO`: Update the pumping rates according to your well group concessioned rates from maps.zh.ch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefebf50",
   "metadata": {},
   "source": [
    "### 2.4 Submodel Grid Definition\n",
    "Now, we define the submodel grid around our well group using the boundary polygon approach. This follows the same workflow as in notebook 4 but focuses on creating a proper submodel domain.\n",
    "\n",
    "#### 2.4.1 Define Submodel Extent with Buffer Distances\n",
    "We'll define buffer distances around the wells based on hydrogeological considerations. For the Limmat Valley, we need to account for the main flow direction and ensure adequate boundary distances for the submodel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4569e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define submodel parameters\n",
    "sub_cell_size = 5  # meters - refined resolution\n",
    "# Note: You are welcome to play with the submodel cell size, but keep in mind that\n",
    "# smaller cell sizes will lead to very large models and long computation times.\n",
    "# We recommend to start with 5 m grid size first and gradually decrease it if needed.\n",
    "\n",
    "parent_cell_size = parent_modelgrid.delr[0]  # parent model cell size\n",
    "\n",
    "print(f\"Parent model cell size: {parent_cell_size} m\")\n",
    "print(f\"Submodel cell size: {sub_cell_size} m\") \n",
    "print(f\"Refinement ratio: {parent_cell_size/sub_cell_size}×\")\n",
    "\n",
    "# Define buffer distances in meters based on hydrogeological considerations\n",
    "# These distances should provide adequate boundary conditions for the submodel\n",
    "downstream_buffer_m = 400   # 400 m buffer downstream (main flow direction)\n",
    "upstream_buffer_m = 400     # 400 m buffer upstream\n",
    "north_buffer_m = 200        # 200 m buffer to the north\n",
    "south_buffer_m = 200        # 200 m buffer to the south\n",
    "\n",
    "print(f\"\\nBuffer distances:\")\n",
    "print(f\"  Downstream: {downstream_buffer_m} m\")\n",
    "print(f\"  Upstream: {upstream_buffer_m} m\")\n",
    "print(f\"  North: {north_buffer_m} m\")\n",
    "print(f\"  South: {south_buffer_m} m\")\n",
    "\n",
    "# Get well extent\n",
    "well_x_min = wells_gdf.geometry.x.min()\n",
    "well_x_max = wells_gdf.geometry.x.max()\n",
    "well_y_min = wells_gdf.geometry.y.min()\n",
    "well_y_max = wells_gdf.geometry.y.max()\n",
    "\n",
    "print(f\"\\nWell extent:\")\n",
    "print(f\"  X: [{well_x_min:.1f}, {well_x_max:.1f}] (span: {well_x_max - well_x_min:.1f} m)\")\n",
    "print(f\"  Y: [{well_y_min:.1f}, {well_y_max:.1f}] (span: {well_y_max - well_y_min:.1f} m)\")\n",
    "\n",
    "# Calculate submodel bounds with buffers\n",
    "# For Limmat Valley, assuming downstream is towards the west (negative X)\n",
    "submodel_xmin = well_x_min - downstream_buffer_m\n",
    "submodel_xmax = well_x_max + upstream_buffer_m  \n",
    "submodel_ymin = well_y_min - south_buffer_m\n",
    "submodel_ymax = well_y_max + north_buffer_m\n",
    "\n",
    "print(f\"\\nSubmodel extent with buffers:\")\n",
    "print(f\"  X: [{submodel_xmin:.1f}, {submodel_xmax:.1f}] (span: {submodel_xmax - submodel_xmin:.1f} m)\")\n",
    "print(f\"  Y: [{submodel_ymin:.1f}, {submodel_ymax:.1f}] (span: {submodel_ymax - submodel_ymin:.1f} m)\")\n",
    "\n",
    "# Calculate expected grid dimensions\n",
    "expected_ncol = int(np.ceil((submodel_xmax - submodel_xmin) / sub_cell_size))\n",
    "expected_nrow = int(np.ceil((submodel_ymax - submodel_ymin) / sub_cell_size))\n",
    "\n",
    "print(f\"\\nExpected submodel grid dimensions:\")\n",
    "print(f\"  {expected_nrow} rows × {expected_ncol} cols\")\n",
    "print(f\"  Total cells: {expected_nrow * expected_ncol:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f4d4c8",
   "metadata": {},
   "source": [
    "#### 2.4.2 Create Submodel Boundary Polygon\n",
    "\n",
    "Now we'll create a boundary polygon for the submodel domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fd10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the coordinate system alignment for submodel boundary calculation\n",
    "\n",
    "# Step 1: Get parent model grid parameters\n",
    "parent_xll = parent_modelgrid.xoffset  # or xll \n",
    "parent_yll = parent_modelgrid.yoffset  # or yll\n",
    "parent_rotation = parent_modelgrid.angrot\n",
    "\n",
    "print(f\"Parent model grid parameters:\")\n",
    "print(f\"  Origin (xll, yll): ({parent_xll:.1f}, {parent_yll:.1f})\")\n",
    "print(f\"  Rotation angle: {parent_rotation} degrees\")\n",
    "\n",
    "# Step 2: Convert wells from real-world to local model coordinates\n",
    "# This removes the rotation and offset, putting wells in the model's local coordinate system\n",
    "wells_local_coords = []\n",
    "for idx, well in wells_gdf.iterrows():\n",
    "    # Use FloPy's built-in coordinate transformation\n",
    "    local_x, local_y = parent_modelgrid.get_local_coords(well.geometry.x, well.geometry.y)\n",
    "    wells_local_coords.append((local_x, local_y))\n",
    "    print(f\"Well {well.get('GWR_ID', idx)}: ({well.geometry.x:.1f}, {well.geometry.y:.1f}) -> local ({local_x:.1f}, {local_y:.1f})\")\n",
    "\n",
    "# Step 3: Calculate submodel bounds in local coordinates\n",
    "wells_local_x = [coord[0] for coord in wells_local_coords]\n",
    "wells_local_y = [coord[1] for coord in wells_local_coords]\n",
    "\n",
    "local_well_x_min = min(wells_local_x)\n",
    "local_well_x_max = max(wells_local_x)\n",
    "local_well_y_min = min(wells_local_y)  \n",
    "local_well_y_max = max(wells_local_y)\n",
    "\n",
    "print(f\"\\nWells extent in local coordinates:\")\n",
    "print(f\"  X: [{local_well_x_min:.1f}, {local_well_x_max:.1f}]\")\n",
    "print(f\"  Y: [{local_well_y_min:.1f}, {local_well_y_max:.1f}]\")\n",
    "\n",
    "# Step 4: Add buffers in local coordinates\n",
    "submodel_local_xmin = local_well_x_min - downstream_buffer_m\n",
    "submodel_local_xmax = local_well_x_max + upstream_buffer_m\n",
    "submodel_local_ymin = local_well_y_min - south_buffer_m  \n",
    "submodel_local_ymax = local_well_y_max + north_buffer_m\n",
    "\n",
    "print(f\"\\nSubmodel bounds in local coordinates (with buffers):\")\n",
    "print(f\"  X: [{submodel_local_xmin:.1f}, {submodel_local_xmax:.1f}]\")\n",
    "print(f\"  Y: [{submodel_local_ymin:.1f}, {submodel_local_ymax:.1f}]\")\n",
    "\n",
    "# Step 5: Convert submodel boundary back to real-world coordinates\n",
    "# Create corner points in local coordinates\n",
    "local_corners = [\n",
    "    (submodel_local_xmin, submodel_local_ymin),  # SW\n",
    "    (submodel_local_xmax, submodel_local_ymin),  # SE  \n",
    "    (submodel_local_xmax, submodel_local_ymax),  # NE\n",
    "    (submodel_local_xmin, submodel_local_ymax),  # NW\n",
    "]\n",
    "\n",
    "# Transform back to real-world coordinates\n",
    "real_world_corners = []\n",
    "for local_x, local_y in local_corners:\n",
    "    real_x, real_y = parent_modelgrid.get_coords(local_x, local_y)\n",
    "    real_world_corners.append((real_x, real_y))\n",
    "    \n",
    "print(f\"\\nSubmodel corners in real-world coordinates:\")\n",
    "for i, (x, y) in enumerate(real_world_corners):\n",
    "    corners = ['SW', 'SE', 'NE', 'NW']\n",
    "    print(f\"  {corners[i]}: ({x:.1f}, {y:.1f})\")\n",
    "\n",
    "# Step 6: Create the properly aligned submodel boundary polygon\n",
    "# Close the polygon by adding the first point at the end\n",
    "real_world_boundary_coords = real_world_corners + [real_world_corners[0]]\n",
    "submodel_boundary_poly = Polygon(real_world_boundary_coords)\n",
    "\n",
    "# Step 7: Clip hte submodel boundary to the parent model boundary\n",
    "parent_model_boundary_file = download_named_file(\n",
    "    name='model_boundary',\n",
    "    data_type='gis'\n",
    ")\n",
    "parent_model_boundary = gpd.read_file(parent_model_boundary_file)\n",
    "# Clip\n",
    "clipped_submodel_boundary = submodel_boundary_poly.intersection(parent_model_boundary.geometry[0])\n",
    "\n",
    "# Create GeoDataFrame for the aligned submodel boundary\n",
    "submodel_boundary_gdf = gpd.GeoDataFrame(\n",
    "    [{'geometry': clipped_submodel_boundary, 'name': 'submodel_domain_aligned'}],\n",
    "    crs=parent_modelgrid.crs\n",
    ")\n",
    "\n",
    "print(f\"\\nAligned submodel boundary created:\")\n",
    "print(f\"  Area: {clipped_submodel_boundary.area / 1e6:.2f} km²\")\n",
    "print(f\"  Perimeter: {clipped_submodel_boundary.length / 1e3:.2f} km\")\n",
    "\n",
    "# Visualize the corrected alignment\n",
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "\n",
    "# Plot parent model\n",
    "pmv = flopy.plot.PlotMapView(model=m_parent_base, modelgrid=parent_modelgrid, ax=ax)\n",
    "pmv.plot_grid(color='lightgrey', alpha=0.3)\n",
    "pmv.plot_array(m_parent_base.bas6.ibound.array, alpha=0.3, cmap='RdYlBu', vmin=-1, vmax=1)\n",
    "\n",
    "# Plot aligned submodel boundary\n",
    "submodel_boundary_gdf.plot(ax=ax, facecolor='red', alpha=0.3, edgecolor='red', \n",
    "                          linewidth=3, label='Aligned Submodel Domain')\n",
    "\n",
    "# Plot wells\n",
    "wells_gdf.plot(ax=ax, color='blue', markersize=150, label='Wells', zorder=5,\n",
    "               edgecolors='white', linewidth=2)\n",
    "\n",
    "# Add corner labels\n",
    "# for i, (x, y) in enumerate(real_world_corners):\n",
    "#     corners = ['SW', 'SE', 'NE', 'NW'] \n",
    "#     ax.annotate(f'{corners[i]}\\n({x:.0f}, {y:.0f})',\n",
    "#                 xy=(x, y), xytext=(10, 10), textcoords='offset points',\n",
    "#                 fontsize=9, bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.8))\n",
    "\n",
    "legend_handles = [\n",
    "    mpatches.Patch(color='red', alpha=0.3, label='Aligned Submodel Domain'),\n",
    "    mlines.Line2D([], [], marker='o', color='blue', markeredgecolor='white', \n",
    "                  markeredgewidth=2, markersize=10, linestyle='None', label='Wells')\n",
    "]\n",
    "ax.set_title('Grid-Aligned Submodel Domain\\n(Boundary properly aligned with parent grid rotation)')\n",
    "ax.set_xlabel('X Coordinate (m)', fontsize=12)\n",
    "ax.set_ylabel('Y Coordinate (m)', fontsize=12)\n",
    "ax.legend(handles=legend_handles)\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d3e55b",
   "metadata": {},
   "source": [
    "#### 2.4.3 Generate Refined Grid Using Notebook 4 Workflow\n",
    "\n",
    "Now we'll apply the exact same grid generation workflow from notebook 4, using our submodel boundary polygon as the domain definition. This ensures consistency with the established methodology.\n",
    "\n",
    "##### Rotate the submodel boundary polygon for regular grid alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665785bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buffer the model boundary gdf\n",
    "submodel_boundary_gdf['geometry'] = submodel_boundary_gdf['geometry'].buffer(10)\n",
    "\n",
    "# Define the rotation angle in degrees\n",
    "grid_rotation_angle = 30  # degrees, identified by trial and error, you can adjust this angle to minimize the number of cells outside the boundary\n",
    "origin_rotation = Point(0, 0)  # Origin for rotation, can be adjusted as needed\n",
    "# Rotate the model boundary polygon\n",
    "submodel_boundary_gdf_rotated = submodel_boundary_gdf.copy()\n",
    "\n",
    "submodel_boundary_gdf_rotated['geometry'] = submodel_boundary_gdf_rotated['geometry'].apply(\n",
    "    lambda geom: rotate(geom, grid_rotation_angle, origin=origin_rotation)\n",
    ")\n",
    "# Get the bounding box of the rotated geometry\n",
    "xmin_rotated, ymin_rotated, xmax_rotated, ymax_rotated = submodel_boundary_gdf_rotated.total_bounds\n",
    "# Plot the rotated boundary to verify\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "submodel_boundary_gdf_rotated.plot(ax=ax, facecolor='none', edgecolor='blue', linewidth=2)\n",
    "ax.set_title(\"Figure 2: Rotated Model Boundary.\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0518f4",
   "metadata": {},
   "source": [
    "##### Create Sub-model Grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39275508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Creation of a new Model Grid based on the rotated Model Boundary ---\n",
    "# We now have new bounding box coordinates for the rotated model boundary. \n",
    "# These we need to rotate back to the original coordinate system to create a\n",
    "# regular grid that fits the rotated boundary.\n",
    "# We use the rotated bounding box to define the grid dimensions.\n",
    "# Calculate the new grid dimensions based on the rotated bounding box\n",
    "width_rotated = xmax_rotated - xmin_rotated\n",
    "height_rotated = ymax_rotated - ymin_rotated\n",
    "\n",
    "# Calculate the number of rows and columns based on the rotated bounding box\n",
    "ncol_rotated = int(np.ceil(width_rotated / sub_cell_size)) - 1 # Based on visual inspection of rotated grid.\n",
    "nrow_rotated = int(np.ceil(height_rotated / sub_cell_size))\n",
    "\n",
    "# Compare number of rows and columns with the original grid\n",
    "print(f\"Rotated Grid: {ncol_rotated} columns, {nrow_rotated} rows\")\n",
    "\n",
    "# Define the delr and delc for the rotated grid\n",
    "delr_rotated = np.full(ncol_rotated, sub_cell_size)\n",
    "delc_rotated = np.full(nrow_rotated, sub_cell_size)\n",
    "nlay = parent_modelgrid.nlay\n",
    "\n",
    "# Plot the rotated grid and the rotated boundary to verify\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "# Create a new StructuredGrid with the rotated dimensions\n",
    "rotated_grid = StructuredGrid(\n",
    "    delr=delr_rotated,\n",
    "    delc=delc_rotated,\n",
    "    top=np.ones((nrow_rotated, ncol_rotated)) * 100,  # Example top elevation\n",
    "    botm=np.ones((nlay, nrow_rotated, ncol_rotated)) * 50,  # Example bottom elevation\n",
    "    xoff=xmin_rotated,  # Use the lower-left of the rotated extent\n",
    "    yoff=ymin_rotated,  # Use the lower-left of the rotated extent\n",
    "    angrot=0,  # We are currently in the rotated coordinate system, so no additional rotation is needed\n",
    "    lenuni=2,  # Length unit code: 2 for meters\n",
    "    crs=submodel_boundary_gdf_rotated.crs.to_string()  # Automatically get CRS from geopackage\n",
    ")\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=rotated_grid, ax=ax)\n",
    "pc = pmv.plot_array(rotated_grid.top, alpha=0.5, cmap='terrain')\n",
    "pmv.plot_grid()\n",
    "ax.set_aspect('equal', adjustable='box') # Ensure correct aspect ratio\n",
    "ax.set_title(\"Figure 3: Rotated FloPy Grid with Rotated Boundary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8099260f",
   "metadata": {},
   "source": [
    "##### Rotate the new submodel grid to align with parent grid rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c22456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Rotation of the new Model Grid in the CH Coordinate System ---\n",
    "# Now we need to rotate the lower-left corner of the rotated grid back to the \n",
    "# original coordinate system.\n",
    "# The lower-left corner of the rotated bounding box\n",
    "# Create points from the rotated bounding box coordinates\n",
    "min_point_rotated = Point(xmin_rotated, ymin_rotated)\n",
    "max_point_rotated = Point(xmax_rotated, ymax_rotated)\n",
    "\n",
    "# Apply inverse rotation (negative angle) around the same origin\n",
    "min_point_original = rotate(min_point_rotated, -grid_rotation_angle, \n",
    "                            origin=origin_rotation)\n",
    "max_point_original = rotate(max_point_rotated, -grid_rotation_angle, \n",
    "                            origin=origin_rotation)\n",
    "\n",
    "# Extract the coordinates\n",
    "xmin_original = min_point_original.x\n",
    "ymin_original = min_point_original.y\n",
    "xmax_original = max_point_original.x\n",
    "ymax_original = max_point_original.y\n",
    "\n",
    "print(f\"Original coordinates after inverse rotation:\")\n",
    "print(f\"xmin: {xmin_original:.2f}, ymin: {ymin_original:.2f}\")\n",
    "print(f\"xmax: {xmax_original:.2f}, ymax: {ymax_original:.2f}\")\n",
    "\n",
    "xll = xmin_original\n",
    "yll = ymin_original\n",
    "\n",
    "print(f\"Corrected grid lower-left corner:\")\n",
    "print(f\"xll = {xll:.2f}\")\n",
    "print(f\"yll = {yll:.2f}\")\n",
    "print(f\"Number of cells in the rotated grid: {nrow_rotated * ncol_rotated * nlay}\")\n",
    "\n",
    "# Create the FloPy structured grid with the rotated bounding box\n",
    "sub_modelgrid = StructuredGrid(\n",
    "    delr=delr_rotated,\n",
    "    delc=delc_rotated,\n",
    "    xoff=xmin_original,  # Use the lower-left of the rotated extent\n",
    "    yoff=ymin_original,  # Use the lower-left of the rotated extent\n",
    "    angrot=-grid_rotation_angle,  # Apply the desired rotation to the grid\n",
    "    lenuni=2,  # Length unit code: 2 for meters\n",
    "    crs=submodel_boundary_gdf.crs.to_string()  # Automatically get CRS from geopackage\n",
    ")\n",
    "\n",
    "# Update grid polygons, tag active cells (≥50% inside), and get IBOUND\n",
    "grid_gdf, ibound = grid_utils.build_grid_gdf_and_ibound(\n",
    "    modelgrid=sub_modelgrid,\n",
    "    boundary_gdf=submodel_boundary_gdf,        # your boundary GeoDataFrame\n",
    "    frac_threshold=0.5,      # change if needed\n",
    "    nlay=nlay                 # use your model's nlay\n",
    ")\n",
    "# Count the number of active cells\n",
    "active_cells = ibound[ibound > 0].sum()\n",
    "print(f\"Total number of active cells in the grid: {active_cells}\")\n",
    "\n",
    "print(\"Model grid created with the following parameters:\")\n",
    "print(sub_modelgrid)\n",
    "\n",
    "# Plot the rotated grid and the model_boundary to check alignment\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=sub_modelgrid, ax=ax)\n",
    "pmv.plot_grid() \n",
    "submodel_boundary_gdf.plot(ax=ax, facecolor='none', edgecolor='red', linewidth=2)\n",
    "red_line = mlines.Line2D([], [], color='red', linewidth=2, label='Model Boundary')\n",
    "ax.legend(handles=[red_line], loc='upper right')\n",
    "ax.set_title(\"Figure 4: Correctly Rotated Grid with Model Boundaries\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "plt.show()\n",
    "ax.set_aspect('equal', adjustable='box') # Ensure correct aspect ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1730f41a",
   "metadata": {},
   "source": [
    "##### Export submodel grid to shapefile for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f13d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model grid to shapefile\n",
    "# Create a list to store grid cell polygons\n",
    "grid_cells = []\n",
    "\n",
    "# Get grid cell vertices using FloPy's grid functionality\n",
    "for i in range(sub_modelgrid.nrow):\n",
    "    for j in range(sub_modelgrid.ncol):\n",
    "        # Get cell vertices\n",
    "        cell_vertices = sub_modelgrid.get_cell_vertices(i, j)\n",
    "\n",
    "        # Create polygon from vertices\n",
    "        cell_polygon = Polygon(cell_vertices)\n",
    "        \n",
    "        # Store cell information\n",
    "        grid_cells.append({\n",
    "            'row': i,\n",
    "            'col': j,\n",
    "            'cell_id': f\"{i}_{j}\",\n",
    "            'geometry': cell_polygon,\n",
    "            'x': sub_modelgrid.xcellcenters[i, j],\n",
    "            'y': sub_modelgrid.ycellcenters[i, j]\n",
    "        })\n",
    "\n",
    "# Create GeoDataFrame\n",
    "grid_gdf = gpd.GeoDataFrame(grid_cells, crs=sub_modelgrid.crs)\n",
    "\n",
    "# Export to GeoPackage\n",
    "grid_geopackage_path = os.path.join(grids_ws, 'sub_model_grid.gpkg')\n",
    "grid_gdf.to_file(grid_geopackage_path, driver='GPKG', layer='sub_model_grid')\n",
    "\n",
    "print(f\"Model grid exported to: {grid_geopackage_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842b3865",
   "metadata": {},
   "source": [
    "### 2.5 Downscale Parent Model to Submodel Grid\n",
    "Now we will extract model geometry, parameters, and boundary conditions from the parent model to set up the submodel. This includes interpolating aquifer properties and extracting heads for boundary conditions. We will go through each package and ensure the submodel is properly configured.\n",
    "\n",
    "#### 2.5.1 DIS Package (Model Geometry)\n",
    "We will start by configuring the DIS package for the submodel, ensuring that the model geometry matches the refined grid we created earlier and is consistent with the parent DIS package. Let's remember what we define in the DIS package:\n",
    "- Number of layers, rows, columns\n",
    "- Cell dimensions (delr, delc)\n",
    "- Top and bottom elevations\n",
    "- Time discretization (steady-state or transient)\n",
    "\n",
    "Remember that you can always check the FloPy documentation for help on any package by using the help function. For example, to get help on the DIS package, you can use:\n",
    "```python\n",
    "help(flopy.modflow.mfdis.ModflowDis)\n",
    "```\n",
    "\n",
    "##### Model Top\n",
    "We start with the model top. We will re-import the high-resolution DEM to define the model top for the submodel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21eecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and resample DEM to submodel grid (following notebook 4)\n",
    "dem_path = download_named_file('dem_hres', data_type='gis')\n",
    "rio = flopy.utils.Raster.load(dem_path)\n",
    "\n",
    "print(f\"DEM loaded:\")\n",
    "print(f\"  CRS: {rio.crs}\")\n",
    "print(f\"  Bounds: {rio.bounds}\")\n",
    "\n",
    "# Resample DEM to submodel grid\n",
    "print(\"Resampling DEM to submodel grid...\")\n",
    "import time\n",
    "t0 = time.time()\n",
    "submodel_top = rio.resample_to_grid(sub_modelgrid, band=rio.bands[0], method=\"nearest\")\n",
    "resample_time = time.time() - t0\n",
    "\n",
    "# Clean up the resampled data\n",
    "submodel_top = np.round(submodel_top, 1)  # Round to 10 cm\n",
    "valid = np.isfinite(submodel_top) & (submodel_top > 0)\n",
    "\n",
    "if not np.any(valid):\n",
    "    raise RuntimeError(\"No valid DEM data found in submodel area\")\n",
    "\n",
    "print(f\"DEM resampling completed in {resample_time:.2f} seconds\")\n",
    "print(f\"  Elevation range: {submodel_top[valid].min():.1f} to {submodel_top[valid].max():.1f} m\")\n",
    "\n",
    "# Plot the submodel_top on the submodel grid\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=sub_modelgrid, ax=ax)\n",
    "im = pmv.plot_array(submodel_top, cmap='terrain', vmin=np.nanmin(submodel_top), vmax=np.nanmax(submodel_top))\n",
    "pmv.plot_grid(color='grey', alpha=0.2)\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.5)\n",
    "cbar.set_label('Elevation (m a.s.l.)')\n",
    "ax.set_title('Resampled DEM on Submodel Grid')\n",
    "ax.set_aspect('equal', adjustable='box') # Ensure correct aspect ratio\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bff4f4",
   "metadata": {},
   "source": [
    "##### Model Bottom\n",
    "We will follow the example in Notebook 4 to define the model bottom for the submodel. We will use the same approach to ensure consistency. The model bottom is calculated as the groundwater table minus the aquifer thickness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define submodel bottom based on groundwater levels and aquifer thickness\n",
    "# Load groundwater levels from file & interpolate to submodel grid\n",
    "isolines = download_named_file('groundwater_map_norm', data_type='gis')\n",
    "gdf_isolines = gpd.read_file(isolines, layer='GS_GW_ISOHYPSE_MW_L')\n",
    "gw_elevations = grid_utils.interpolate_isohypses_to_grid(gdf_isolines, sub_modelgrid)\n",
    "\n",
    "'''# Optional, plot gw_elevations for verification\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "im = ax.imshow(gw_elevations, extent=sub_modelgrid.extent, origin='upper', cmap='Blues')\n",
    "ax.set_title(\"Figure 5: Interpolated Groundwater Elevations on Submodel Grid\")\n",
    "ax.set_xlabel(\"X-coordinate\")\n",
    "ax.set_ylabel(\"Y-coordinate\")\n",
    "plt.colorbar(im, ax=ax, label=\"Groundwater Elevation (m a.s.l.)\")\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.show()'''\n",
    "\n",
    "# Load groundwater thickness from file, requires 4_model_implementation.ipynb to have been run once first\n",
    "workspace = os.path.join(get_default_data_folder(), 'limmat_valley_model')\n",
    "thickness_path = os.path.join(workspace, 'aquifer_thickness_contours.gpkg')\n",
    "aquifer_thickness_gdf = gpd.read_file(thickness_path, layer='aquifer_thickness_contours')\n",
    "# Interpolate aquifer thickness to submodel grid\n",
    "aquifer_thickness_resampled = grid_utils.interpolate_aquifer_thickness_to_grid_with_contour_densification(\n",
    "    contour_gdf=aquifer_thickness_gdf,\n",
    "    modelgrid=sub_modelgrid,\n",
    "    thickness_column='aquifer_thickness',\n",
    "    contour_interval=2.0,  # Create intermediate contours every 2m\n",
    "    plot_intermediate=False,  # Show the contour densification step\n",
    "    plot_points=False,  # Set to True if you want to see final interpolation points\n",
    "    buffer_distance=300\n",
    ")\n",
    "# Smooth the resampled aquifer thickness to remove small-scale noise\n",
    "from scipy.ndimage import gaussian_filter\n",
    "aquifer_thickness_resampled = gaussian_filter(aquifer_thickness_resampled, sigma=4)\n",
    "\n",
    "'''# Plot aquifer thickness for verification\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "im = ax.imshow(aquifer_thickness_resampled, extent=sub_modelgrid.extent, origin='upper', cmap='YlOrBr')\n",
    "ax.set_title(\"Figure 6: Interpolated Aquifer Thickness on Submodel Grid\")\n",
    "ax.set_xlabel(\"X-coordinate\")\n",
    "ax.set_ylabel(\"Y-coordinate\")\n",
    "plt.colorbar(im, ax=ax, label=\"Aquifer Thickness (m)\")\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "plt.show()'''\n",
    "\n",
    "# Calculate bottom elevation\n",
    "submodel_bottom = gw_elevations - aquifer_thickness_resampled\n",
    "\n",
    "# Ensure bottom is 3D array format\n",
    "if submodel_bottom.ndim == 2:\n",
    "    submodel_bottom = submodel_bottom[np.newaxis, :, :]\n",
    "\n",
    "print(f\"Submodel bottom calculated:\")\n",
    "print(f\"  Bottom range: {submodel_bottom[0][valid].min():.1f} to {submodel_bottom[0][valid].max():.1f} m\")\n",
    "\n",
    "# Define the delr and delc for the submodel grid\n",
    "delr = np.full(sub_modelgrid.ncol, sub_cell_size)\n",
    "delc = np.full(sub_modelgrid.nrow, sub_cell_size)\n",
    "\n",
    "# Update the submodel grid with real elevations\n",
    "submodel_grid = StructuredGrid(\n",
    "    delr=delr,\n",
    "    delc=delc,\n",
    "    top=submodel_top,\n",
    "    botm=submodel_bottom,\n",
    "    nlay=nlay,\n",
    "    xoff=xll,\n",
    "    yoff=yll,\n",
    "    angrot=-grid_rotation_angle\n",
    ")\n",
    "\n",
    "print(\"Submodel grid updated with DEM elevations\")\n",
    "\n",
    "# Plot the final submodel grid with bottom elevations\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=submodel_grid, ax=ax)\n",
    "im = pmv.plot_array(submodel_grid.botm, cmap='terrain', vmin=np.nanmin(submodel_grid.botm), vmax=np.nanmax(submodel_grid.botm))\n",
    "pmv.plot_grid(color='grey', alpha=0.2)\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.5)\n",
    "cbar.set_label('Elevation (m a.s.l.)')\n",
    "ax.set_title('Submodel Bottom Elevations')\n",
    "ax.set_aspect('equal', adjustable='box') # Ensure correct aspect ratio\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8719fc8",
   "metadata": {},
   "source": [
    "##### Initiate sub_base model and write submodel DIS package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecaa533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sub_base model\n",
    "m_sub_base = flopy.modflow.Modflow(\n",
    "    namefile.replace('.nam', ''), \n",
    "    model_ws=sub_base_ws,\n",
    "    version='mfnwt',\n",
    "    exe_name='mfnwt.exe'  # Ensure the executable is correctly specified\n",
    ")\n",
    "\n",
    "# Get temporal parameters from parent model\n",
    "nper = m_parent_base.dis.nper\n",
    "perlen = m_parent_base.dis.perlen.array\n",
    "nstp = m_parent_base.dis.nstp.array\n",
    "tsmult = m_parent_base.dis.tsmult.array # Time step multiplier\n",
    "steady = m_parent_base.dis.steady.array\n",
    "\n",
    "sub_base_dis = flopy.modflow.ModflowDis(\n",
    "    model=m_sub_base,\n",
    "    model_ws=sub_base_ws,\n",
    "    nlay=nlay,\n",
    "    nrow=sub_modelgrid.nrow,\n",
    "    ncol=sub_modelgrid.ncol,\n",
    "    delr=delr,\n",
    "    delc=delc,\n",
    "    xul=xll,\n",
    "    yul=yll + (sub_modelgrid.nrow * sub_cell_size),  # Upper-left y-coordinate\n",
    "    angrot=-grid_rotation_angle,\n",
    "    crs=sub_modelgrid.crs.to_string(),\n",
    "    top=submodel_top,\n",
    "    botm=submodel_bottom,\n",
    "    nper=nper,\n",
    "    perlen=perlen,\n",
    "    nstp=nstp,\n",
    "    tsmult=tsmult,\n",
    "    steady=steady,\n",
    "    itmuni=4,  # Time unit: days\n",
    "    lenuni=2,  # Length unit: meters\n",
    ")\n",
    "\n",
    "# Plot sub_base_grid for verification\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "pmv = flopy.plot.PlotMapView(model=m_sub_base, ax=ax)\n",
    "pmv.plot_grid(color='grey', alpha=0.2)\n",
    "ax.set_title(\"Submodel Grid Verification\")\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "ax.set_aspect('equal', adjustable='box') # Ensure correct aspect ratio\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e498adf",
   "metadata": {},
   "source": [
    "#### 2.5.2 BAS Package (Initial Heads)\n",
    "We will set up the BAS package for the submodel, ensuring that the initial heads are consistent with the parent model. We will extract the steady-state heads from the parent model and interpolate them to the submodel grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a99bb9",
   "metadata": {},
   "source": [
    "##### Extract boundary heads from parent model\n",
    "\n",
    "We'll extract head values along the submodel boundary from the parent model results. These will become constant head (CHD) boundary conditions along all lateral boundaries of the submodel, ensuring proper nesting within the parent model domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1470a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract parent model heads for boundary interpolation\n",
    "print(\"Extracting parent model heads for boundary condition interpolation...\")\n",
    "\n",
    "# Load parent model heads\n",
    "parent_hds_path = os.path.join(parent_base_ws, f\"{m_parent_base.name}.hds\")\n",
    "if not os.path.exists(parent_hds_path):\n",
    "    print(\"Parent model heads file not found. Running parent model...\")\n",
    "    success, buff = m_parent_base.run_model(silent=True, report=True)\n",
    "    if not success:\n",
    "        raise RuntimeError(\"Parent model failed to run\")\n",
    "    print(\"✓ Parent model run completed\")\n",
    "\n",
    "# Load parent heads\n",
    "headobj_parent = flopy.utils.HeadFile(parent_hds_path)\n",
    "parent_heads = headobj_parent.get_data()[0]  # Layer 0, stress period 0\n",
    "\n",
    "# Get parent model grid coordinates and active cells\n",
    "parent_ibound = m_parent_base.bas6.ibound.array[0]  # Layer 0\n",
    "parent_active_mask = parent_ibound == 1\n",
    "\n",
    "# Extract coordinates of active parent cells\n",
    "parent_x_centers = parent_modelgrid.xcellcenters[parent_active_mask]\n",
    "parent_y_centers = parent_modelgrid.ycellcenters[parent_active_mask]\n",
    "parent_heads_active = parent_heads[parent_active_mask]\n",
    "\n",
    "# Filter out any invalid heads (NaN, inf, or unrealistic values)\n",
    "valid_head_mask = (np.isfinite(parent_heads_active) & \n",
    "                   (parent_heads_active > 300) &  # Reasonable lower bound for elevation\n",
    "                   (parent_heads_active < 600))   # Reasonable upper bound for elevation\n",
    "\n",
    "parent_coords_valid = np.column_stack([\n",
    "    parent_x_centers[valid_head_mask],\n",
    "    parent_y_centers[valid_head_mask]\n",
    "])\n",
    "parent_heads_valid = parent_heads_active[valid_head_mask]\n",
    "\n",
    "print(f\"Parent model head extraction:\")\n",
    "print(f\"  Total parent cells: {parent_heads.size:,}\")\n",
    "print(f\"  Active parent cells: {np.sum(parent_active_mask):,}\")\n",
    "print(f\"  Valid heads for interpolation: {len(parent_heads_valid):,}\")\n",
    "print(f\"  Head range: {parent_heads_valid.min():.1f} to {parent_heads_valid.max():.1f} m\")\n",
    "\n",
    "# Create KDTree for efficient nearest neighbor search\n",
    "from scipy.spatial import cKDTree\n",
    "parent_tree = cKDTree(parent_coords_valid)\n",
    "\n",
    "print(\"✓ Parent model heads prepared for boundary interpolation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b08c94",
   "metadata": {},
   "source": [
    "##### Get IBOUND array for submodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f35e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create complete CHD boundary\n",
    "def create_complete_boundary_ibound(submodel_grid, boundary_polygon, boundary_thickness=1):\n",
    "    \"\"\"\n",
    "    Create IBOUND array with complete CHD boundary around submodel domain.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    submodel_grid : flopy.discretization.StructuredGrid\n",
    "        Submodel grid\n",
    "    boundary_polygon : shapely.geometry.Polygon\n",
    "        Clipped boundary polygon\n",
    "    boundary_thickness : int\n",
    "        Number of cell layers to mark as CHD from domain edge\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    ibound : numpy.ndarray\n",
    "        IBOUND array with CHD boundaries\n",
    "    boundary_cells : list\n",
    "        List of boundary cell information\n",
    "    \"\"\"\n",
    "    from shapely.geometry import Point\n",
    "    \n",
    "    # Initialize IBOUND as all active cells\n",
    "    ibound = np.ones((nlay, submodel_grid.nrow, submodel_grid.ncol), dtype=int)\n",
    "    boundary_cells = []\n",
    "    \n",
    "    # Method 1: Mark cells outside or on boundary of clipped polygon as CHD\n",
    "    for i in range(submodel_grid.nrow):\n",
    "        for j in range(submodel_grid.ncol):\n",
    "            # Get cell center coordinates\n",
    "            x_center = submodel_grid.xcellcenters[i, j]\n",
    "            y_center = submodel_grid.ycellcenters[i, j]\n",
    "            cell_point = Point(x_center, y_center)\n",
    "            \n",
    "            # Check if cell center is outside boundary or very close to boundary\n",
    "            distance_to_boundary = cell_point.distance(boundary_polygon.boundary)\n",
    "            \n",
    "            # Mark as CHD if:\n",
    "            # 1. Cell is outside the boundary polygon, OR\n",
    "            # 2. Cell is very close to boundary (within half cell size)\n",
    "            if (not boundary_polygon.contains(cell_point) or \n",
    "                distance_to_boundary < sub_cell_size * 0.5):\n",
    "                \n",
    "                # Only mark as CHD if cell has valid coordinates (not completely outside model domain)\n",
    "                if (submodel_grid.extent[0] <= x_center <= submodel_grid.extent[1] and\n",
    "                    submodel_grid.extent[2] <= y_center <= submodel_grid.extent[3]):\n",
    "                    \n",
    "                    ibound[0, i, j] = -1  # CHD cell\n",
    "                    boundary_cells.append({\n",
    "                        'submodel_row': i,\n",
    "                        'submodel_col': j,\n",
    "                        'x': x_center,\n",
    "                        'y': y_center,\n",
    "                        'distance_to_boundary': distance_to_boundary\n",
    "                    })\n",
    "    \n",
    "    # Method 2: Ensure edge cells are CHD (safety measure)\n",
    "    edge_thickness = max(1, boundary_thickness)\n",
    "    \n",
    "    # Top and bottom edges\n",
    "    ibound[:, :edge_thickness, :] = -1\n",
    "    ibound[:, -edge_thickness:, :] = -1\n",
    "    \n",
    "    # Left and right edges  \n",
    "    ibound[:, :, :edge_thickness] = -1\n",
    "    ibound[:, :, -edge_thickness:] = -1\n",
    "    \n",
    "    # Add edge cells to boundary_cells list if not already included\n",
    "    for i in range(submodel_grid.nrow):\n",
    "        for j in range(submodel_grid.ncol):\n",
    "            if ibound[0, i, j] == -1:\n",
    "                x_center = submodel_grid.xcellcenters[i, j]\n",
    "                y_center = submodel_grid.ycellcenters[i, j]\n",
    "                \n",
    "                # Check if this cell is already in boundary_cells\n",
    "                cell_exists = any(\n",
    "                    cell['submodel_row'] == i and cell['submodel_col'] == j \n",
    "                    for cell in boundary_cells\n",
    "                )\n",
    "                \n",
    "                if not cell_exists:\n",
    "                    boundary_cells.append({\n",
    "                        'submodel_row': i,\n",
    "                        'submodel_col': j,\n",
    "                        'x': x_center,\n",
    "                        'y': y_center,\n",
    "                        'distance_to_boundary': 0.0  # Edge cell\n",
    "                    })\n",
    "    \n",
    "    return ibound, boundary_cells\n",
    "\n",
    "# Detect the complete boundary and create IBOUND\n",
    "print(\"Creating complete CHD boundary around submodel domain...\")\n",
    "submodel_ibound_complete, boundary_cells_complete = create_complete_boundary_ibound(\n",
    "    submodel_grid, clipped_submodel_boundary, boundary_thickness=1\n",
    ")\n",
    "\n",
    "print(f\"Complete boundary detection results:\")\n",
    "print(f\"  Total boundary cells: {len(boundary_cells_complete)}\")\n",
    "print(f\"  CHD cells: {np.sum(submodel_ibound_complete == -1):,}\")\n",
    "print(f\"  Active cells: {np.sum(submodel_ibound_complete == 1):,}\")\n",
    "\n",
    "# Head interpolation for all boundary cells\n",
    "print(\"Interpolating heads for all boundary cells...\")\n",
    "\n",
    "# Use the same KDTree approach but for all boundary cells\n",
    "sub_boundary_coords_complete = []\n",
    "for cell in boundary_cells_complete:\n",
    "    sub_boundary_coords_complete.append([cell['x'], cell['y']])\n",
    "\n",
    "sub_boundary_coords_complete = np.array(sub_boundary_coords_complete)\n",
    "\n",
    "# Perform inverse distance weighted interpolation\n",
    "k_neighbors = min(5, len(parent_heads_valid))\n",
    "distances, neighbor_indices = parent_tree.query(sub_boundary_coords_complete, k=k_neighbors)\n",
    "\n",
    "# Handle zero distances\n",
    "distances = np.maximum(distances, 1e-10)\n",
    "\n",
    "# Calculate weights\n",
    "weights = 1.0 / distances\n",
    "weights = weights / weights.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Weighted average\n",
    "interpolated_heads_complete = np.sum(\n",
    "    parent_heads_valid[neighbor_indices] * weights, axis=1\n",
    ")\n",
    "\n",
    "# Create CHD package data for all boundary cells\n",
    "chd_data_complete = []\n",
    "for i, cell in enumerate(boundary_cells_complete):\n",
    "    interpolated_head = float(interpolated_heads_complete[i])\n",
    "    \n",
    "    chd_data_complete.append([\n",
    "        0,  # Layer 0\n",
    "        cell['submodel_row'],\n",
    "        cell['submodel_col'],\n",
    "        interpolated_head,\n",
    "        interpolated_head\n",
    "    ])\n",
    "\n",
    "print(f\"Complete CHD data created: {len(chd_data_complete)} cells\")\n",
    "\n",
    "# Update variables for consistency with rest of notebook\n",
    "submodel_ibound_clipped = submodel_ibound_complete\n",
    "boundary_cells = boundary_cells_complete\n",
    "submodel_chd_data = chd_data_complete\n",
    "\n",
    "# Visualize the complete boundary conditions\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Define colormap for IBOUND visualization  \n",
    "import matplotlib.colors as mcolors\n",
    "cmap = mcolors.ListedColormap(['blue', 'white'])  # CHD=-1: blue, Active=1: white\n",
    "bounds = [-1.5, -0.5, 1.5]\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=submodel_grid, ax=ax)\n",
    "im = pmv.plot_array(submodel_ibound_complete[0], cmap=cmap, norm=norm)\n",
    "pmv.plot_grid(color='gray', alpha=0.3, linewidth=0.3)\n",
    "\n",
    "# Plot original clipped boundary for reference\n",
    "if hasattr(clipped_submodel_boundary, 'exterior'):\n",
    "    boundary_x, boundary_y = clipped_submodel_boundary.exterior.xy\n",
    "    ax.plot(boundary_x, boundary_y, 'red', linewidth=2, label='Original Boundary')\n",
    "\n",
    "# Plot wells\n",
    "wells_gdf.plot(ax=ax, color='red', markersize=80, label='Wells', zorder=5,\n",
    "               edgecolors='white', linewidth=1)\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.3, ticks=[-1, 1])\n",
    "cbar.ax.set_yticklabels([\"CHD (-1)\", \"Active (1)\"])\n",
    "cbar.set_label(\"IBOUND\")\n",
    "\n",
    "ax.set_title('Complete Submodel Boundary Conditions\\n(Blue: CHD boundary, White: Active cells)')\n",
    "ax.legend()\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Complete CHD boundary created around entire submodel domain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb1f86",
   "metadata": {},
   "source": [
    "##### Write CHD & BAS package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694be3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_base_chd = flopy.modflow.ModflowChd(\n",
    "    model=m_sub_base,\n",
    "    stress_period_data={0: submodel_chd_data},\n",
    "    ipakcb=53,\n",
    "    model_ws=sub_base_ws\n",
    ")\n",
    "\n",
    "# Extract CHD package data and visualize with continuous colormap\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "pmv = flopy.plot.PlotMapView(model=m_sub_base, ax=ax)\n",
    "pmv.plot_grid(color='gray', alpha=0.3, linewidth=0.3)\n",
    "\n",
    "# Extract CHD data\n",
    "chd_package = m_sub_base.chd\n",
    "chd_data = chd_package.stress_period_data[0]  # First stress period\n",
    "\n",
    "# Create arrays to hold CHD head values for plotting\n",
    "chd_array = np.full((m_sub_base.nrow, m_sub_base.ncol), np.nan)\n",
    "chd_coords_x = []\n",
    "chd_coords_y = []\n",
    "chd_heads = []\n",
    "\n",
    "for chd_cell in chd_data:\n",
    "    layer, row, col, start_head, end_head = chd_cell\n",
    "    chd_array[row, col] = start_head\n",
    "    \n",
    "    # Also collect coordinates for scatter plot option\n",
    "    x = m_sub_base.modelgrid.xcellcenters[row, col]\n",
    "    y = m_sub_base.modelgrid.ycellcenters[row, col]\n",
    "    chd_coords_x.append(x)\n",
    "    chd_coords_y.append(y)\n",
    "    chd_heads.append(start_head)\n",
    "\n",
    "# Method 1: Plot CHD as array (shows cells as squares)\n",
    "chd_masked = np.ma.masked_where(np.isnan(chd_array), chd_array)\n",
    "im = pmv.plot_array(chd_masked, alpha=0.8, cmap='viridis')\n",
    "\n",
    "# Method 2: Alternative - plot as scatter points (optional, comment out if using array method)\n",
    "# scatter = ax.scatter(chd_coords_x, chd_coords_y, \n",
    "#                     c=chd_heads, \n",
    "#                     s=30,  # Size of points\n",
    "#                     cmap='viridis',\n",
    "#                     edgecolors='white',\n",
    "#                     linewidth=0.5,\n",
    "#                     alpha=0.8)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.7)\n",
    "cbar.set_label('CHD Head (m a.s.l.)', fontsize=12)\n",
    "\n",
    "# Add contours of CHD heads for better visualization\n",
    "if len(chd_heads) > 3:  # Need at least a few points for contouring\n",
    "    from scipy.interpolate import griddata\n",
    "    \n",
    "    # Create a regular grid for interpolation\n",
    "    xi = np.linspace(ax.get_xlim()[0], ax.get_xlim()[1], 50)\n",
    "    yi = np.linspace(ax.get_ylim()[0], ax.get_ylim()[1], 50)\n",
    "    xi_grid, yi_grid = np.meshgrid(xi, yi)\n",
    "    \n",
    "    # Interpolate CHD values\n",
    "    zi_grid = griddata((chd_coords_x, chd_coords_y), chd_heads, \n",
    "                       (xi_grid, yi_grid), method='linear')\n",
    "    \n",
    "    # Add contour lines\n",
    "    contours = ax.contour(xi_grid, yi_grid, zi_grid, \n",
    "                         levels=8, colors='white', linewidths=1, alpha=0.8)\n",
    "    ax.clabel(contours, inline=True, fontsize=9, fmt='%.1f m')\n",
    "\n",
    "# Plot wells for reference\n",
    "if 'wells_gdf' in locals():\n",
    "    wells_gdf.plot(ax=ax, color='red', markersize=60, label='Wells', zorder=5,\n",
    "                   edgecolors='white', linewidth=1)\n",
    "\n",
    "ax.set_title('CHD Package - Specified Heads with Continuous Colormap')\n",
    "ax.set_xlabel('X Coordinate (m)')\n",
    "ax.set_ylabel('Y Coordinate (m)')\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print CHD statistics\n",
    "print(f\"CHD Package Summary:\")\n",
    "print(f\"  Number of CHD cells: {len(chd_data)}\")\n",
    "print(f\"  Head range: {min(chd_heads):.2f} to {max(chd_heads):.2f} m\")\n",
    "print(f\"  Mean head: {np.mean(chd_heads):.2f} m\")\n",
    "print(f\"  Standard deviation: {np.std(chd_heads):.2f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2afb6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_base_bas = flopy.modflow.ModflowBas(m_sub_base, ibound=submodel_ibound_clipped, strt=gw_elevations)\n",
    "\n",
    "# Plot IBOUND and starting heads\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "pmv = flopy.plot.PlotMapView(model=m_sub_base, ax=ax)\n",
    "im = pmv.plot_ibound()\n",
    "plt.colorbar(im, ax=ax, shrink=0.7, ticks=[-1, 0, 1])\n",
    "pmv.plot_grid(color='gray', alpha=0.3, linewidth=0.3)\n",
    "ax.set_title('IBOUND Array')\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "ax.set_aspect('equal')   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd96a0a7",
   "metadata": {},
   "source": [
    "#### 2.5.3 UPW Package (Aquifer Properties)\n",
    "We will set up the UPW package for the submodel, ensuring that the aquifer properties are consistent with the parent model. We will extract the hydraulic conductivity and specific storage values from the parent model and interpolate them to the submodel grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2b437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the UPW package from parent model\n",
    "parent_upw = m_parent_base.upw\n",
    "parent_ibound = m_parent_base.bas6.ibound.array  # Get parent model IBOUND\n",
    "\n",
    "# Extract hydraulic conductivity arrays from parent model\n",
    "parent_hk = parent_upw.hk.array  # Horizontal hydraulic conductivity\n",
    "parent_vka = parent_upw.vka.array  # Vertical hydraulic conductivity (or anisotropy ratio)\n",
    "# Only for transient models\n",
    "# parent_sy = parent_upw.sy.array  # Specific yield\n",
    "# parent_ss = parent_upw.ss.array  # Specific storage\n",
    "\n",
    "print(f\"Parent model aquifer parameters:\")\n",
    "print(f\"  HK range: {parent_hk.min():.2f} to {parent_hk.max():.2f} m/day\")\n",
    "print(f\"  VKA range: {parent_vka.min():.6f} to {parent_vka.max():.6f}\")# Get the UPW package from parent model\n",
    "parent_upw = m_parent_base.upw\n",
    "parent_ibound = m_parent_base.bas6.ibound.array  # Get parent model IBOUND\n",
    "\n",
    "# Extract hydraulic conductivity arrays from parent model\n",
    "parent_hk = parent_upw.hk.array  # Horizontal hydraulic conductivity\n",
    "parent_vka = parent_upw.vka.array  # Vertical hydraulic conductivity (or anisotropy ratio)\n",
    "\n",
    "print(f\"Parent model aquifer parameters:\")\n",
    "print(f\"  HK range: {parent_hk.min():.2f} to {parent_hk.max():.2f} m/day\")\n",
    "print(f\"  VKA range: {parent_vka.min():.6f} to {parent_vka.max():.6f}\")\n",
    "\n",
    "# Check parent model active cells\n",
    "if parent_ibound.ndim == 3:\n",
    "    parent_active_cells = (parent_ibound[0, :, :] == 1).sum()\n",
    "    active_mask_parent = parent_ibound[0, :, :] == 1\n",
    "    print(f\"  Active cells in parent model: {parent_active_cells:,}\")\n",
    "else:\n",
    "    parent_active_cells = (parent_ibound == 1).sum()\n",
    "    active_mask_parent = parent_ibound == 1\n",
    "    print(f\"  Active cells in parent model: {parent_active_cells:,}\")\n",
    "\n",
    "# Use representative uniform values from active parent cells instead of interpolation\n",
    "print(\"\\nUsing uniform parameter values from active parent model cells...\")\n",
    "print(f\"Submodel grid shape: {sub_modelgrid.nrow} x {sub_modelgrid.ncol}\")\n",
    "\n",
    "# Extract statistics from active cells only (exclude zeros and inactive cells)\n",
    "active_hk = parent_hk[0][active_mask_parent]\n",
    "active_vka = parent_vka[0][active_mask_parent]\n",
    "\n",
    "# Filter out zeros and get representative values\n",
    "valid_hk = active_hk[active_hk > 0]\n",
    "valid_vka = active_vka[active_vka > 0]\n",
    "\n",
    "# Use median values for uniform parameters (more robust than mean)\n",
    "uniform_hk = np.median(valid_hk) if len(valid_hk) > 0 else 20.0  # Default for gravel aquifer\n",
    "uniform_vka = np.median(valid_vka) if len(valid_vka) > 0 else 2.0  # Default VKA\n",
    "\n",
    "print(f\"\\nRepresentative uniform values from active cells:\")\n",
    "print(f\"  Uniform HK: {uniform_hk:.2f} m/day (from {len(valid_hk)} active cells)\")\n",
    "print(f\"  Uniform VKA: {uniform_vka:.6f} (from {len(valid_vka)} active cells)\")\n",
    "\n",
    "# Create uniform parameter arrays for submodel\n",
    "sub_hk = np.full((nlay, sub_modelgrid.nrow, sub_modelgrid.ncol), uniform_hk)\n",
    "sub_vka = np.full((nlay, sub_modelgrid.nrow, sub_modelgrid.ncol), uniform_vka)\n",
    "\n",
    "# Ensure all values are physically realistic (positive)\n",
    "sub_hk = np.maximum(sub_hk, 0.1)  # Minimum 0.1 m/day\n",
    "sub_vka = np.maximum(sub_vka, 0.001)  # Minimum VKA\n",
    "\n",
    "print(f\"\\nSubmodel aquifer parameters (uniform values, all >0):\")\n",
    "print(f\"  HK: {sub_hk.min():.2f} to {sub_hk.max():.2f} m/day (uniform)\")\n",
    "print(f\"  VKA: {sub_vka.min():.6f} to {sub_vka.max():.6f} (uniform)\")\n",
    "\n",
    "# Verify array dimensions match submodel grid\n",
    "print(f\"\\nArray dimension verification:\")\n",
    "print(f\"  sub_hk shape: {sub_hk.shape}\")\n",
    "print(f\"  Expected shape: ({nlay}, {sub_modelgrid.nrow}, {sub_modelgrid.ncol})\")\n",
    "\n",
    "# Create arrays with submodel dimensions for parent parameters\n",
    "# For parameters that don't need interpolation, create uniform arrays\n",
    "sub_laytyp = np.ones(nlay, dtype=int) * parent_upw.laytyp.array[0]  # Use first layer value\n",
    "\n",
    "# Extract scalar value from parent hani array - it might be 2D or 3D\n",
    "if parent_upw.hani.array.ndim == 3:\n",
    "    hani_value = parent_upw.hani.array[0, 0, 0]  # 3D array: [layer, row, col]\n",
    "elif parent_upw.hani.array.ndim == 2:\n",
    "    hani_value = parent_upw.hani.array[0, 0]     # 2D array: [row, col]\n",
    "else:\n",
    "    hani_value = parent_upw.hani.array[0]        # 1D array: [layer]\n",
    "\n",
    "# Ensure hani_value is reasonable (>0)\n",
    "if hani_value <= 0:\n",
    "    hani_value = 1.0  # Default isotropic\n",
    "    print(f\"  Warning: Parent HANI ≤0, using default value: {hani_value}\")\n",
    "\n",
    "print(f\"  hani_value used: {hani_value}\")\n",
    "\n",
    "# Create UPW package for submodel with uniform arrays\n",
    "sub_base_upw = flopy.modflow.ModflowUpw(\n",
    "    m_sub_base,\n",
    "    laytyp=sub_laytyp,\n",
    "    hk=sub_hk,\n",
    "    hani=hani_value,  # Use scalar value\n",
    "    vka=sub_vka,\n",
    "    ipakcb=53  # Save cell-by-cell budget\n",
    ")\n",
    "\n",
    "# Visualize uniform hydraulic conductivity\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Plot HK\n",
    "im1 = axes[0].imshow(sub_hk[0], extent=sub_modelgrid.extent, origin='upper', cmap='viridis')\n",
    "axes[0].set_title('Hydraulic Conductivity (HK)\\n[m/day]')\n",
    "plt.colorbar(im1, ax=axes[0], shrink=0.7)\n",
    "\n",
    "# Plot VKA\n",
    "im2 = axes[1].imshow(sub_vka[0], extent=sub_modelgrid.extent, origin='upper', cmap='plasma')\n",
    "axes[1].set_title('Vertical Hydraulic Conductivity (VKA)\\n[m/day or ratio]')\n",
    "plt.colorbar(im2, ax=axes[1], shrink=0.7)\n",
    "\n",
    "# Format axes\n",
    "for ax in axes.flat:\n",
    "    ax.set_xlabel('X Coordinate (m)')\n",
    "    ax.set_ylabel('Y Coordinate (m)')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.suptitle('Uniform Aquifer Parameters on Submodel Grid', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ UPW package created with uniform parameters from parent model statistics\")\n",
    "print(\"✓ All hydraulic conductivity values are >0 and physically realistic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9308a7",
   "metadata": {},
   "source": [
    "#### 2.5.4 RECH Package (Recharge)\n",
    "We will set up the RECH package for the submodel, ensuring that the recharge rates are consistent with the parent model. We will extract the recharge values from the parent model and interpolate them to the submodel grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acc30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the RECH package code with this corrected version\n",
    "\n",
    "# Extract recharge from parent model\n",
    "parent_rch = m_parent_base.rch\n",
    "if parent_rch is not None:\n",
    "    parent_recharge = parent_rch.rech.array\n",
    "    \n",
    "    # Get representative recharge value from parent model\n",
    "    # Check if recharge is 2D or 3D array\n",
    "    if parent_recharge.ndim == 3:\n",
    "        # 3D array: [stress_period, row, col]\n",
    "        parent_rech_values = parent_recharge[0]  # First stress period\n",
    "    else:\n",
    "        # 2D array: [row, col]\n",
    "        parent_rech_values = parent_recharge\n",
    "    \n",
    "    # Get active cells in parent model for statistics\n",
    "    # Make sure we match the dimensions correctly\n",
    "    if parent_ibound.ndim == 3:\n",
    "        parent_active_mask = parent_ibound[0] == 1  # Use first layer\n",
    "        print(f\"Parent IBOUND shape: {parent_ibound.shape}, using layer 0\")\n",
    "    else:\n",
    "        parent_active_mask = parent_ibound == 1\n",
    "        print(f\"Parent IBOUND shape: {parent_ibound.shape}\")\n",
    "    \n",
    "    print(f\"Parent recharge shape: {parent_rech_values.shape}\")\n",
    "    print(f\"Parent active mask shape: {parent_active_mask.shape}\")\n",
    "    \n",
    "    # Ensure dimensions match\n",
    "    if parent_rech_values.shape != parent_active_mask.shape:\n",
    "        print(f\"Warning: Dimension mismatch between recharge {parent_rech_values.shape} and active mask {parent_active_mask.shape}\")\n",
    "        # If recharge is 1D (single value), expand it to match grid\n",
    "        if parent_rech_values.ndim == 0 or (parent_rech_values.ndim == 1 and len(parent_rech_values) == 1):\n",
    "            uniform_recharge = float(parent_rech_values) if parent_rech_values.ndim == 0 else parent_rech_values[0]\n",
    "            print(f\"Using scalar recharge value: {uniform_recharge:.6f} m/day\")\n",
    "        else:\n",
    "            # Use fallback value\n",
    "            uniform_recharge = 0.110 / 365.25  # 110 mm/year converted to m/day\n",
    "            print(f\"Dimension mismatch, using default recharge: {uniform_recharge:.6f} m/day\")\n",
    "    else:\n",
    "        # Calculate representative recharge from active cells\n",
    "        active_recharge_values = parent_rech_values[parent_active_mask]\n",
    "        valid_recharge = active_recharge_values[active_recharge_values > 0]\n",
    "        \n",
    "        if len(valid_recharge) > 0:\n",
    "            uniform_recharge = np.median(valid_recharge)\n",
    "            print(f\"Extracted recharge from parent model:\")\n",
    "            print(f\"  Active cells with recharge: {len(valid_recharge):,}\")\n",
    "            print(f\"  Recharge range: {valid_recharge.min():.6f} to {valid_recharge.max():.6f} m/day\")\n",
    "            print(f\"  Median recharge: {uniform_recharge:.6f} m/day ({uniform_recharge*365.25*1000:.1f} mm/year)\")\n",
    "        else:\n",
    "            # Fallback to typical values for Swiss conditions\n",
    "            uniform_recharge = 0.110 / 365.25  # 110 mm/year converted to m/day\n",
    "            print(f\"No valid recharge found in parent model, using default: {uniform_recharge:.6f} m/day\")\n",
    "        \n",
    "else:\n",
    "    # No recharge package in parent model - use default\n",
    "    uniform_recharge = 0.110 / 365.25  # m/day (110 mm/year)\n",
    "    print(f\"No RCH package in parent model, using default recharge: {uniform_recharge:.6f} m/day\")\n",
    "\n",
    "# Create uniform recharge array for submodel\n",
    "sub_recharge_array = np.full((sub_modelgrid.nrow, sub_modelgrid.ncol), uniform_recharge)\n",
    "\n",
    "# Create RCH package for submodel\n",
    "sub_base_rch = flopy.modflow.ModflowRch(\n",
    "    m_sub_base,\n",
    "    rech=sub_recharge_array,\n",
    "    nrchop=3  # Apply recharge to highest active cell\n",
    ")\n",
    "\n",
    "print(f\"\\nSubmodel RCH package created:\")\n",
    "print(f\"  Uniform recharge rate: {uniform_recharge:.6f} m/day ({uniform_recharge*365.25*1000:.1f} mm/year)\")\n",
    "print(f\"  Applied to grid: {sub_modelgrid.nrow} × {sub_modelgrid.ncol} cells\")\n",
    "\n",
    "# Visualize recharge distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=submodel_grid, ax=ax)\n",
    "im = pmv.plot_array(sub_recharge_array * 365.25 * 1000, cmap='Blues', alpha=0.7)  # Convert to mm/year for display\n",
    "pmv.plot_grid(color='gray', alpha=0.3, linewidth=0.3)\n",
    "\n",
    "# Plot wells for reference\n",
    "wells_gdf.plot(ax=ax, color='red', markersize=60, label='Wells', zorder=5,\n",
    "               edgecolors='white', linewidth=1)\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.3)\n",
    "cbar.set_label('Recharge Rate (mm/year)')\n",
    "\n",
    "ax.set_title(f'Uniform Recharge on Submodel Grid\\n{uniform_recharge*365.25*1000:.1f} mm/year')\n",
    "ax.set_xlabel('X Coordinate (m)')\n",
    "ax.set_ylabel('Y Coordinate (m)')\n",
    "ax.legend()\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ RCH package created with uniform recharge from parent model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ee4d5",
   "metadata": {},
   "source": [
    "#### 2.5.5 Solver & output control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NWT Solver\n",
    "nwt = flopy.modflow.ModflowNwt(\n",
    "    m_sub_base,\n",
    "    headtol=0.01,      # Head tolerance\n",
    "    fluxtol=5.0,       # Flux tolerance  \n",
    "    maxiterout=100,    # Maximum outer iterations\n",
    "    thickfact=1e-05,   # Thickness factor for dry cells\n",
    "    linmeth=1,         # Linear solution method (1=GMRES, 2=XMD)\n",
    "    iprnwt=1,          # Print flag\n",
    "    ibotav=0,          # Bottom averaging flag\n",
    "    options='COMPLEX'  # Use complex option for difficult problems\n",
    ")\n",
    "\n",
    "# Output Control\n",
    "oc = flopy.modflow.ModflowOc(\n",
    "    m_sub_base,\n",
    "    stress_period_data={(0, 0): ['save head', 'save budget']}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc222e55",
   "metadata": {},
   "source": [
    "### 2.6 Run the sub_base model without wells\n",
    "Now that we have set up the submodel with boundary conditions and aquifer properties, we will run the submodel without wells to establish baseline conditions. This will allow us to assess the natural groundwater flow patterns in the submodel area before implementing wells (our `sub_base` model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22da4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write input files and run the submodel\n",
    "print(\"Writing submodel input files...\")\n",
    "m_sub_base.write_input()\n",
    "\n",
    "# Check model setup\n",
    "print(\"\\nChecking submodel setup...\")\n",
    "chk = m_sub_base.check(f=None, verbose=False)\n",
    "if chk.summary_array is not None and len(chk.summary_array) > 0:\n",
    "    print(\"Model check warnings found - reviewing...\")\n",
    "    for warning in chk.summary_array:\n",
    "        print(f\"  Warning: {warning}\")\n",
    "else:\n",
    "    print(\"Model check passed\")\n",
    "\n",
    "# Run the submodel\n",
    "print(f\"\\nRunning refined submodel...\")\n",
    "success, buff = m_sub_base.run_model(silent=False, report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb5926c",
   "metadata": {},
   "source": [
    "### 2.7 Visualize sub_base model results\n",
    "\n",
    "#### 2.7.1 Steady-State Groundwater Heads & Flow Vectors of sub_base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb44e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if success: \n",
    "    plot_utils.plot_model_results(m_sub_base, sub_base_ws, namefile.replace('.nam', ''),\n",
    "                                  show_wells=False, show_ibound=True)\n",
    "# Optional: save the image with plot_model_results by adding `save_path` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6686f50b",
   "metadata": {},
   "source": [
    "#### 2.7.2 Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc56e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_df = plot_utils.visualize_budget(\n",
    "    workspace=sub_base_ws, model_name=namefile.replace('.nam', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711c22c9",
   "metadata": {},
   "source": [
    "## 3 Implement sub_wells model by adding the WEL Package\n",
    "Now we copy the sub_base model to create the sub_wells model, where we will implement the well group. We will add the WEL package to the submodel and assign the appropriate pumping rates for our well group.\n",
    "\n",
    "### 3.1 Set Up sub_wells model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed001ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the m_sub_base model as m_sub_wells model and edit the workspace\n",
    "m_sub_wells = flopy.modflow.Modflow.load(\n",
    "    namefile.replace('.nam', ''), \n",
    "    model_ws=sub_base_ws,\n",
    "    forgive=True, \n",
    "    check=False, \n",
    "    exe_name='mfnwt'\n",
    ")\n",
    "# Change workspace to the new directory sub_wells_ws\n",
    "m_sub_wells.model_ws = sub_wells_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c74bfb",
   "metadata": {},
   "source": [
    "### 3.2 Add WEL Package to sub_wells model\n",
    "#### 3.2.1 Map new wells to refined grid\n",
    "\n",
    "Now we'll map the wells from the case study configuration to the refined grid cells and set up the WEL package with the appropriate pumping rates for the scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map wells to submodel grid cells\n",
    "from flopy.utils.gridintersect import GridIntersect\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Create GridIntersect object for the submodel\n",
    "gi = GridIntersect(submodel_grid, method='vertex', rtree=True)\n",
    "\n",
    "# Also prepare KDTree for fallback nearest-cell lookup\n",
    "xc_sub = submodel_grid.xcellcenters\n",
    "yc_sub = submodel_grid.ycellcenters\n",
    "centers_flat = np.column_stack([xc_sub.ravel(), yc_sub.ravel()])\n",
    "kdtree = cKDTree(centers_flat)\n",
    "\n",
    "well_cells = []\n",
    "for idx, well in wells_gdf.iterrows():\n",
    "    well_x, well_y = well.geometry.x, well.geometry.y\n",
    "    \n",
    "    # Try GridIntersect first\n",
    "    try:\n",
    "        result = gi.intersect(Point(well_x, well_y))\n",
    "        if len(result) > 0:\n",
    "            # Extract row, col from intersection result\n",
    "            if hasattr(result, 'iloc'):  # DataFrame\n",
    "                row = int(result.iloc[0]['row'])  \n",
    "                col = int(result.iloc[0]['col'])\n",
    "            else:  # Other formats\n",
    "                row = int(result[0]['row'])\n",
    "                col = int(result[0]['col'])\n",
    "        else:\n",
    "            raise ValueError(\"No intersection found\")\n",
    "    except:\n",
    "        # Fallback to nearest cell center\n",
    "        dist, idx_flat = kdtree.query([well_x, well_y])\n",
    "        row, col = np.unravel_index(idx_flat, xc_sub.shape)\n",
    "    \n",
    "    # Check if cell is active (not CHD)\n",
    "    if submodel_ibound_clipped[0, row, col] == 1:  # Active cell\n",
    "        well_cells.append({\n",
    "            'well_idx': idx,\n",
    "            'well_id': well.get('GWR_ID', f'well_{idx}'),\n",
    "            'x': well_x,\n",
    "            'y': well_y,\n",
    "            'layer': 0,\n",
    "            'row': row, \n",
    "            'col': col,\n",
    "            'fassart': well.get('FASSART', 'Unknown')\n",
    "        })\n",
    "        print(f\"Well {well.get('GWR_ID', idx)}: mapped to cell (L0, R{row}, C{col})\")\n",
    "    else:\n",
    "        print(f\"Warning: Well {well.get('GWR_ID', idx)} mapped to CHD cell (L0, R{row}, C{col}) - skipping\")\n",
    "\n",
    "print(f\"\\nMapped {len(well_cells)} wells to active submodel cells\")\n",
    "\n",
    "# Define pumping rates based on scenario\n",
    "# Use the concessioned pumping rates from maps.ch.ch (if available)\n",
    "pumping_rates = {\n",
    "    'Entnahme': -well_rates_m3d,    # m³/day (negative = pumping)\n",
    "    'Rückgabe': +well_rates_m3d,     # m³/day (positive = injection) \n",
    "}\n",
    "\n",
    "# Create WEL stress period data\n",
    "wel_data = []\n",
    "for well_info in well_cells:\n",
    "    # Determine pumping rate based on well type\n",
    "    fassart = well_info['fassart']\n",
    "    \n",
    "    # Map FASSART to pumping rate\n",
    "    if 'Entnahme' in fassart:\n",
    "        rate = pumping_rates.get('Entnahme', -500)\n",
    "    elif 'Rückgabe' in fassart:\n",
    "        rate = pumping_rates.get('Rückgabe', 500)  \n",
    "    else:\n",
    "        rate = -100  # Default pumping rate\n",
    "        print(f\"Warning: Unknown FASSART '{fassart}' for well {well_info['well_id']}, using default rate\")\n",
    "    \n",
    "    wel_data.append([well_info['layer'], well_info['row'], well_info['col'], rate])\n",
    "    print(f\"  {well_info['well_id']} ({fassart}): {rate} m³/day at (L{well_info['layer']}, R{well_info['row']}, C{well_info['col']})\")\n",
    "\n",
    "print(f\"\\nWEL package data created with {len(wel_data)} wells\")\n",
    "total_pumping = sum(rate for _, _, _, rate in wel_data if rate < 0)\n",
    "total_injection = sum(rate for _, _, _, rate in wel_data if rate > 0)\n",
    "print(f\"  Total pumping: {total_pumping:,.0f} m³/day\")\n",
    "print(f\"  Total injection: {total_injection:,.0f} m³/day\")\n",
    "print(f\"  Net extraction: {total_pumping + total_injection:,.0f} m³/day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef77da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize wells on the refined submodel grid\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Plot submodel grid\n",
    "pmv = flopy.plot.PlotMapView(modelgrid=submodel_grid, ax=ax)\n",
    "pmv.plot_array(submodel_grid.top, alpha=0.6, cmap='terrain')\n",
    "pmv.plot_grid(color='white', alpha=0.5, linewidth=0.3)\n",
    "\n",
    "# Plot boundary conditions\n",
    "im_bound = pmv.plot_array(np.ma.masked_where(submodel_ibound_clipped[0] != -1, submodel_ibound_clipped[0]), \n",
    "                         cmap='Blues', alpha=0.8)\n",
    "\n",
    "# Plot wells with different colors for different types\n",
    "pumping_wells = [(info['row'], info['col']) for info in well_cells \n",
    "                 if any(rate < 0 for _, r, c, rate in wel_data if r == info['row'] and c == info['col'])]\n",
    "injection_wells = [(info['row'], info['col']) for info in well_cells \n",
    "                   if any(rate > 0 for _, r, c, rate in wel_data if r == info['row'] and c == info['col'])]\n",
    "\n",
    "if pumping_wells:\n",
    "    p_rows, p_cols = zip(*pumping_wells)\n",
    "    ax.scatter(submodel_grid.xcellcenters[p_rows, p_cols],\n",
    "              submodel_grid.ycellcenters[p_rows, p_cols],\n",
    "              c='red', s=100, marker='o', edgecolors='white', linewidth=2,\n",
    "              label=f'Pumping Wells ({len(pumping_wells)})', zorder=5)\n",
    "\n",
    "if injection_wells:\n",
    "    i_rows, i_cols = zip(*injection_wells) \n",
    "    ax.scatter(submodel_grid.xcellcenters[i_rows, i_cols],\n",
    "              submodel_grid.ycellcenters[i_rows, i_cols], \n",
    "              c='green', s=100, marker='s', edgecolors='white', linewidth=2,\n",
    "              label=f'Injection Wells ({len(injection_wells)})', zorder=5)\n",
    "\n",
    "# Add well labels\n",
    "for well_info in well_cells:\n",
    "    ax.annotate(f\"{well_info['well_id'].split('_')[-1]}\", \n",
    "                xy=(submodel_grid.xcellcenters[well_info['row'], well_info['col']],\n",
    "                    submodel_grid.ycellcenters[well_info['row'], well_info['col']]),\n",
    "                xytext=(2, 2), textcoords='offset points',\n",
    "                fontsize=8, fontweight='bold',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "ax.set_title('Refined Submodel with Wells\\n(Red: Pumping, Green: Injection, Blue: CHD Boundary)')\n",
    "ax.legend()\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f180aac",
   "metadata": {},
   "source": [
    "#### 3.2.3 Write WEL package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f287494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the wel package for the submodel\n",
    "wel = flopy.modflow.ModflowWel(m_sub_wells, stress_period_data={0: wel_data})\n",
    "\n",
    "# Visualize the wel package data on the submodel grid\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "# Plot submodel grid\n",
    "pmv = flopy.plot.PlotMapView(m_sub_wells, ax=ax)\n",
    "#pmv.plot_array(submodel_grid.top, alpha=0.6, cmap='terrain')\n",
    "pmv.plot_ibound()\n",
    "pmv.plot_grid(color='grey', alpha=0.5, linewidth=0.3)\n",
    "# Plot wells with different colors for different types\n",
    "pmv.plot_bc(package=wel)\n",
    "ax.set_title('WEL Package on Submodel Grid')\n",
    "ax.legend()\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faecd297",
   "metadata": {},
   "source": [
    "### 3.3. Set Up and Run Submodel sub_wells\n",
    "\n",
    "Finally, we'll complete the submodel setup with all necessary packages and run the simulation. We'll use MODFLOW-NWT for better convergence with the refined grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67279b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write input files and run the submodel\n",
    "print(\"Writing submodel input files...\")\n",
    "m_sub_wells.write_input()\n",
    "\n",
    "# Check model setup\n",
    "print(\"\\nChecking submodel setup...\")\n",
    "chk = m_sub_wells.check(f=None, verbose=False)\n",
    "if chk.summary_array is not None and len(chk.summary_array) > 0:\n",
    "    print(\"Model check warnings found - reviewing...\")\n",
    "    for warning in chk.summary_array:\n",
    "        print(f\"  Warning: {warning}\")\n",
    "else:\n",
    "    print(\"Model check passed\")\n",
    "\n",
    "# Run the submodel\n",
    "print(f\"\\nRunning refined submodel...\")\n",
    "success, buff = m_sub_wells.run_model(silent=False, report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6d09df",
   "metadata": {},
   "source": [
    "### 3.4 Visualize sub_wells model results\n",
    "\n",
    "#### 3.4.1 Steady-State Groundwater Heads & Flow Vectors of sub_wells model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c72ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if success: \n",
    "    plot_utils.plot_model_results(m_sub_wells, sub_wells_ws, namefile.replace('.nam', ''),\n",
    "                                  show_wells=False, show_ibound=True, show_vectors=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bdae36",
   "metadata": {},
   "source": [
    "#### 3.4.2 Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5581f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_df = plot_utils.visualize_budget(\n",
    "    workspace=sub_base_ws, model_name=namefile.replace('.nam', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe0c0f",
   "metadata": {},
   "source": [
    "### 3.5 Particle tracking with MODPATH (Optional)\n",
    "Now that your groundwater model is running, we'll perform a critical design check for our geothermal system. We need to ensure that the thermally-altered water from the injection well won't be drawn back into the extraction well too quickly. This problem, known as thermal breakthrough, would reduce the system's efficiency over time. To investigate this, we'll use MODPATH to perform particle tracking simulations.\n",
    "\n",
    "##### How Particle Tracking Works\n",
    "Think of MODPATH as a hydrogeological GPS that uses the flow map created by MODFLOW. We place a \"virtual particle\"—essentially a digital marker—at a starting location. MODPATH then calculates its path through the aquifer based on the simulated groundwater flow.\n",
    "\n",
    "The particle's speed and direction at any point are determined by the model's outputs, specifically:\n",
    "\n",
    "- The hydraulic gradient (how steeply the water pressure changes).\n",
    "\n",
    "- The aquifer's hydraulic conductivity (how easily water passes through the material).\n",
    "\n",
    "- The material's effective porosity (the amount of interconnected pore space the water can actually travel through).\n",
    "\n",
    "MODPATH allows for two types of simulations:\n",
    "\n",
    "**Forward Tracking**: We place a particle at a source (like our injection well) and track it forward in time to see where it will go and how long it will take to get there. This helps us predict the future path of the injected water.\n",
    "\n",
    "**Backward Tracking**: This is like rewinding a video of the groundwater flow. We place a particle at a destination (like our extraction well) and ask: \"Where did the water arriving at this point come from?\" The simulation traces the flow path backward in time, step by step, to identify the particle's origin.\n",
    "\n",
    "##### Practical Applications\n",
    "This technique is essential in many real-world hydrogeology projects:\n",
    "\n",
    "**Wellhead Protection**: This is a primary use case. To protect a drinking water well, hydrogeologists perform backward tracking from the well screen for a specific duration (e.g., 10 days). The resulting area the particles came from is defined as the \"10-day capture zone.\" Any potential sources of contamination, like industrial sites or landfills, located within this zone are flagged as a high risk to the water supply.\n",
    "\n",
    "**Contaminant Source Identification**: Imagine a monitoring well shows contamination. To find the source, you can release particles from the contaminated well and track them backward. Their path can act as a pointer, leading investigators toward the likely source of the pollution, such as a leaky underground storage tank.\n",
    "\n",
    "**Groundwater-Surface Water Interactions**: To understand how an aquifer sustains a river or wetland, particles can be released along the riverbed and tracked backward. This reveals which parts of the landscape are providing the essential baseflow to the ecosystem.\n",
    "\n",
    "#### 3.5.1 Identify the pumping and injection wells where to place particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data = m_sub_wells.wel.stress_period_data[0]\n",
    "injection_wells = well_data[well_data['flux'] > 0]\n",
    "pumping_wells = well_data[well_data['flux'] < 0]\n",
    "\n",
    "# Extract layer, row, column for the injection wells\n",
    "# Note: Flopy/MODFLOW use 0-based indexing (k, i, j)\n",
    "injection_locs_df = injection_wells[['k', 'i', 'j']]\n",
    "pumping_wells_df = pumping_wells [['k', 'i', 'j']]\n",
    "\n",
    "print(f\"Found {len(injection_locs_df)} injection wells for particle tracking.\")\n",
    "print(f\"Found {len(pumping_wells_df)} pumping wells for particle tracking.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d645b",
   "metadata": {},
   "source": [
    "#### 3.5.2 Create a grid of 100 particles in each well cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f7dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of 100 particles in the injection wells for forward tracking\n",
    "if injection_locs_df.size > 0:\n",
    "    # Create a list of single-cell regions from the well locations\n",
    "    # The format for a region is [Lstart, Rstart, Cstart, Lend, Rend, Cend]\n",
    "    lrc_regions = []\n",
    "    for loc in injection_locs_df:\n",
    "        k, i, j = loc[0], loc[1], loc[2]\n",
    "        # Define a region that is just one cell\n",
    "        lrc_regions.append([k, i, j, k, i, j])\n",
    "\n",
    "    # Define how to subdivide each cell/region to generate particles\n",
    "    # 10x10 in rows/columns and 1 in the layer direction = 100 particles\n",
    "    subdivision_data = flopy.modpath.CellDataType(\n",
    "        drape=0,\n",
    "        columncelldivisions=10,\n",
    "        rowcelldivisions=10,\n",
    "        layercelldivisions=1\n",
    "    )\n",
    "\n",
    "    # Create the particle data object using regions and subdivision info\n",
    "    p_data = flopy.modpath.LRCParticleData(\n",
    "        subdivisiondata=[subdivision_data], lrcregions=[lrc_regions]\n",
    "    )\n",
    "\n",
    "    # Create the particle group using the LRCTemplate class\n",
    "    well_particle_group = flopy.modpath.ParticleGroupLRCTemplate(\n",
    "        particlegroupname=\"InjectionWells_100p\",\n",
    "        particledata=p_data,\n",
    "        filename=\"injection_wells_100p.sloc\"\n",
    "    )\n",
    "\n",
    "    # Use this group for the simulation\n",
    "    particlegroups = [well_particle_group]\n",
    "\n",
    "    print(f\"Successfully created 100 particles for each of the {len(lrc_regions)} injection wells.\")\n",
    "\n",
    "else:\n",
    "    print(\"No injection wells found. No particles will be created.\")\n",
    "    particlegroups = []\n",
    "\n",
    "# And the same for the pumping wells, but for backward tracking\n",
    "if len(pumping_wells_df) > 0:\n",
    "    # Create LRC regions for the pumping wells\n",
    "    pumping_lrc_regions = []\n",
    "    for loc in pumping_wells_df:\n",
    "        k, i, j = loc[0], loc[1], loc[2]\n",
    "        # Define a region that is just one cell\n",
    "        pumping_lrc_regions.append([k, i, j, k, i, j])\n",
    "\n",
    "    # Use the same subdivision strategy as forward tracking\n",
    "    # This creates a grid of particles within each pumping well cell\n",
    "    backward_subdivision_data = flopy.modpath.CellDataType(\n",
    "        drape=0,\n",
    "        columncelldivisions=10,\n",
    "        rowcelldivisions=10,\n",
    "        layercelldivisions=1\n",
    "    )\n",
    "\n",
    "    # Create the particle data object for backward tracking\n",
    "    backward_p_data = flopy.modpath.LRCParticleData(\n",
    "        subdivisiondata=[backward_subdivision_data], \n",
    "        lrcregions=[pumping_lrc_regions]\n",
    "    )\n",
    "\n",
    "    # Create the particle group for backward tracking\n",
    "    backward_particle_group = flopy.modpath.ParticleGroupLRCTemplate(\n",
    "        particlegroupname=\"PumpingWells_Backward_100p\",\n",
    "        particledata=backward_p_data,\n",
    "        filename=\"pumping_wells_backward_100p.sloc\"\n",
    "    )\n",
    "\n",
    "    print(f\"Successfully created 100 particles for backward tracking from {len(pumping_lrc_regions)} pumping wells.\")\n",
    "\n",
    "else:\n",
    "    print(\"No pumping wells found. No backward particles will be created.\")\n",
    "    backward_particle_group = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434c2dc",
   "metadata": {},
   "source": [
    "#### 3.5.3 Create & run the MODPATH model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default iface for MODFLOW-2005 and MODFLOW 6\n",
    "defaultiface = {\"RECHARGE\": 6, \"ET\": 6}\n",
    "\n",
    "# Define zones for MODPATH\n",
    "# Get grid dimensions from the MODFLOW model\n",
    "nrow = m_sub_wells.dis.nrow\n",
    "ncol = m_sub_wells.dis.ncol\n",
    "\n",
    "# 1. Create a base zone array, setting all cells to Zone 1 by default\n",
    "#    The dtype must be an integer type, like np.int32\n",
    "zones = np.ones((nrow, ncol), dtype=np.int32)\n",
    "# 2. Set zone 2 for the injection well cells\n",
    "for loc in injection_locs_df:\n",
    "    k, i, j = loc[0], loc[1], loc[2]\n",
    "    zones[i, j] = 2  # Set to Zone 2\n",
    "# 3. Set zone 3 for the pumping well cells\n",
    "for loc in wel_data:\n",
    "    k, i, j, rate = loc\n",
    "    if rate < 0:  # Pumping well\n",
    "        zones[i, j] = 3  # Set to Zone 3\n",
    "        \n",
    "# Create MODPATH files\n",
    "exe_name = \"mp7\"\n",
    "\n",
    "if particlegroups is not None:\n",
    "    # Set up the MODPATH model \n",
    "    mp = flopy.modpath.Modpath7(\n",
    "        modelname=namefile.replace('.nam', '') + \"_mp\", \n",
    "        flowmodel=m_sub_wells, \n",
    "        version='modpath7', \n",
    "        exe_name=exe_name, \n",
    "        model_ws=sub_wells_ws, \n",
    "        verbose=True\n",
    "    )\n",
    "    # Basic MODPATH settings\n",
    "    mpbas = flopy.modpath.Modpath7Bas(\n",
    "        mp, \n",
    "        porosity=0.1, \n",
    "        defaultiface=defaultiface\n",
    "    )\n",
    "    # Create the simulation object with FORWARD tracking\n",
    "    mpsim = flopy.modpath.Modpath7Sim(\n",
    "        mp,\n",
    "        simulationtype=\"combined\",\n",
    "        trackingdirection=\"forward\",\n",
    "        weaksinkoption=\"pass_through\",\n",
    "        weaksourceoption=\"pass_through\",\n",
    "        budgetoutputoption=\"summary\",\n",
    "        budgetcellnumbers=[1049, 1259],\n",
    "        traceparticledata=[1, 1000],\n",
    "        timepointdata=[500, 1.0],\n",
    "        zonedataoption=\"on\",\n",
    "        zones=zones,\n",
    "        particlegroups=particlegroups,\n",
    "        referencetime=[0, 0, 0.0],\n",
    "        stoptimeoption=\"specified\",          \n",
    "        stoptime=3.0,                     # Run for 3 days\n",
    "    )\n",
    "\n",
    "    # write modpath datasets\n",
    "    mp.write_input()\n",
    "\n",
    "    mp.check()\n",
    "\n",
    "    # run modpath\n",
    "    success_forward, buff_forward = mp.run_model(silent=True, report=True)\n",
    "    assert success_forward, \"mp7 failed to run\"\n",
    "    for line in buff_forward[-5:]:  # Show last 5 lines of output\n",
    "        print(line)\n",
    "    else: \n",
    "        print(\"No particles to track - skipping MODPATH forward tracking.\")\n",
    "\n",
    "if backward_particle_group is not None:\n",
    "    # Create a new MODPATH model for backward tracking\n",
    "    mp_backward = flopy.modpath.Modpath7(\n",
    "        modelname=namefile.replace('.nam', '') + \"_mp_backward\", \n",
    "        flowmodel=m_sub_wells, \n",
    "        version='modpath7', \n",
    "        exe_name=exe_name, \n",
    "        model_ws=sub_wells_ws, \n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Use the same basic settings as forward tracking\n",
    "    mpbas_backward = flopy.modpath.Modpath7Bas(\n",
    "        mp_backward, \n",
    "        porosity=0.1, \n",
    "        defaultiface=defaultiface\n",
    "    )\n",
    "\n",
    "    # Create the simulation object with BACKWARD tracking\n",
    "    mpsim_backward = flopy.modpath.Modpath7Sim(\n",
    "        mp_backward,\n",
    "        simulationtype=\"combined\",\n",
    "        trackingdirection=\"backward\",  # Key difference: backward instead of forward\n",
    "        weaksinkoption=\"pass_through\",\n",
    "        weaksourceoption=\"pass_through\",\n",
    "        budgetoutputoption=\"summary\",\n",
    "        traceparticledata=[1, 1000],\n",
    "        timepointdata=[500, 1.0],\n",
    "        zonedataoption=\"on\",\n",
    "        zones=zones,  # Use the same zones we defined earlier\n",
    "        particlegroups=[backward_particle_group],\n",
    "        referencetime=[0, 0, 0.0],\n",
    "        stoptimeoption=\"specified\",          \n",
    "        stoptime=3.0,  # Run for 3 days (same as forward tracking)\n",
    "    )\n",
    "\n",
    "    # Write and run the backward tracking model\n",
    "    mp_backward.write_input()\n",
    "    mp_backward.check()\n",
    "\n",
    "    # Run the backward tracking simulation\n",
    "    print(\"Running backward particle tracking simulation...\")\n",
    "    success_backward, buff_backward = mp_backward.run_model(silent=True, report=True)\n",
    "    assert success_backward, \"Backward tracking mp7 failed to run\"\n",
    "    \n",
    "    print(\"Backward tracking simulation completed successfully!\")\n",
    "    for line in buff_backward[-5:]:  # Show last 5 lines of output\n",
    "        print(line)\n",
    "\n",
    "else:\n",
    "    print(\"Cannot run backward tracking - no pumping wells found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2791b",
   "metadata": {},
   "source": [
    "#### 3.5.4 Load Modpath results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074db18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Get the injection well location from the well data\n",
    "injection_well = injection_locs_df[0]  # Get the first (and likely only) injection well\n",
    "layer, row, col = int(injection_well['k']), int(injection_well['i']), int(injection_well['j'])\n",
    "\n",
    "# Get the node number for the injection well\n",
    "nodew = m_sub_wells.dis.get_node((layer, row, col))[0]  # Extract the first (and only) node number\n",
    "print(f\"Injection well at layer {layer}, row {row}, col {col} has node number: {nodew}\")\n",
    "\n",
    "fpth = os.path.join(sub_wells_ws, namefile.replace('.nam', '') + \"_mp.mppth\")\n",
    "p = flopy.utils.PathlineFile(fpth)\n",
    "pw0 = p.get_destination_pathline_data(nodew, to_recarray=True)\n",
    "\n",
    "fpth = os.path.join(sub_wells_ws, namefile.replace('.nam', '') + \"_mp.mpend\")\n",
    "e = flopy.utils.EndpointFile(fpth)\n",
    "well_epd = e.get_destination_endpoint_data(dest_cells=nodew)\n",
    "'''\n",
    "if 'success_forward' in locals() and success_forward:\n",
    "    # Load the pathline file for forward tracking\n",
    "    fpth = os.path.join(sub_wells_ws, namefile.replace('.nam', '') + \"_mp.mppth\")\n",
    "    p = flopy.utils.PathlineFile(fpth)\n",
    "    \n",
    "    # Load the endpoint file for forward tracking\n",
    "    fpth_end = os.path.join(sub_wells_ws, namefile.replace('.nam', '') + \"_mp.mpend\")\n",
    "    e = flopy.utils.EndpointFile(fpth_end)\n",
    "    \n",
    "    # Get all pathlines (these show where injected water goes)\n",
    "    forward_pathlines = p.get_alldata()\n",
    "    \n",
    "    # Get all endpoints (these show the final locations of injected water)\n",
    "    forward_endpoints = e.get_alldata()\n",
    "    \n",
    "    print(f\"Forward tracking results:\")\n",
    "    print(f\"  - Total pathlines: {len(forward_pathlines)}\")\n",
    "    print(f\"  - Total endpoints: {len(forward_endpoints)}\")\n",
    "    \n",
    "    # Handle the case where pathlines might be a list of arrays\n",
    "    if len(forward_pathlines) > 0:\n",
    "        # Convert list to a single array if needed\n",
    "        if isinstance(forward_pathlines, list):\n",
    "            import numpy as np\n",
    "            # Concatenate all pathline data if it's a list of arrays\n",
    "            if len(forward_pathlines) > 0 and hasattr(forward_pathlines[0], 'dtype'):\n",
    "                forward_pathlines_array = np.concatenate(forward_pathlines)\n",
    "            else:\n",
    "                print(\"Warning: Unexpected pathline data format\")\n",
    "                forward_pathlines_array = None\n",
    "        else:\n",
    "            forward_pathlines_array = forward_pathlines\n",
    "        \n",
    "        # Show travel time statistics if we have valid data\n",
    "        if forward_pathlines_array is not None and len(forward_pathlines_array) > 0:\n",
    "            travel_times = forward_pathlines_array['time']\n",
    "            print(f\"  - Travel times range from {travel_times.min():.2f} to {travel_times.max():.2f} days\")\n",
    "            print(f\"\\nTravel time statistics:\")\n",
    "            print(f\"  - Minimum travel time: {travel_times.min():.2f} days\")\n",
    "            print(f\"  - Maximum travel time: {travel_times.max():.2f} days\")\n",
    "            print(f\"  - Mean travel time: {travel_times.mean():.2f} days\")\n",
    "        else:\n",
    "            print(\"  - Could not extract travel time data\")\n",
    "\n",
    "if 'success_backward' in locals() and success_backward:\n",
    "    # Load the pathline file for backward tracking\n",
    "    fpth_backward = os.path.join(sub_wells_ws, namefile.replace('.nam', '') + \"_mp_backward.mppth\")\n",
    "    p_backward = flopy.utils.PathlineFile(fpth_backward)\n",
    "    \n",
    "    # Load the endpoint file for backward tracking\n",
    "    fpth_backward_end = os.path.join(sub_wells_ws, namefile.replace('.nam', '') + \"_mp_backward.mpend\")\n",
    "    e_backward = flopy.utils.EndpointFile(fpth_backward_end)\n",
    "    \n",
    "    # Get all pathlines (these show where pumped water comes from)\n",
    "    backward_pathlines = p_backward.get_alldata()\n",
    "    \n",
    "    # Get all endpoints (these show the starting locations of captured water)\n",
    "    backward_endpoints = e_backward.get_alldata()\n",
    "    \n",
    "    print(f\"\\nBackward tracking results:\")\n",
    "    print(f\"  - Total pathlines: {len(backward_pathlines)}\")\n",
    "    print(f\"  - Total endpoints: {len(backward_endpoints)}\")\n",
    "    \n",
    "    # Handle the case where pathlines might be a list of arrays\n",
    "    if len(backward_pathlines) > 0:\n",
    "        # Convert list to a single array if needed\n",
    "        if isinstance(backward_pathlines, list):\n",
    "            import numpy as np\n",
    "            # Concatenate all pathline data if it's a list of arrays\n",
    "            if len(backward_pathlines) > 0 and hasattr(backward_pathlines[0], 'dtype'):\n",
    "                backward_pathlines_array = np.concatenate(backward_pathlines)\n",
    "            else:\n",
    "                print(\"Warning: Unexpected pathline data format\")\n",
    "                backward_pathlines_array = None\n",
    "        else:\n",
    "            backward_pathlines_array = backward_pathlines\n",
    "        \n",
    "        # Show travel time statistics if we have valid data\n",
    "        if backward_pathlines_array is not None and len(backward_pathlines_array) > 0:\n",
    "            travel_times = backward_pathlines_array['time']\n",
    "            print(f\"  - Travel times range from {travel_times.min():.2f} to {travel_times.max():.2f} days\")\n",
    "            print(f\"\\nTravel time statistics:\")\n",
    "            print(f\"  - Minimum travel time: {travel_times.min():.2f} days\")\n",
    "            print(f\"  - Maximum travel time: {travel_times.max():.2f} days\")\n",
    "            print(f\"  - Mean travel time: {travel_times.mean():.2f} days\")\n",
    "        else:\n",
    "            print(\"  - Could not extract travel time data\")\n",
    "\n",
    "else:\n",
    "    print(\"No backward tracking results available - simulation may have failed or not been run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f7ec47",
   "metadata": {},
   "source": [
    "#### 3.5.5 Visualize MODPATH results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511deabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'forward_pathlines' in locals() and len(forward_pathlines) > 0:\n",
    "    # Create a comprehensive visualization showing both forward and backward tracking\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    # Left plot: Forward tracking (from injection wells)\n",
    "    mm_forward = flopy.plot.PlotMapView(model=m_sub_wells, layer=0, ax=ax1)\n",
    "    mm_forward.plot_grid(lw=0.5, alpha=0.3)\n",
    "    mm_forward.plot_pathline(forward_pathlines, layer=\"all\", colors=\"blue\", label=\"Forward: from injection wells\", linewidth=2)\n",
    "    mm_forward.plot_endpoint(forward_endpoints, direction=\"starting\", colorbar=False, s=20, alpha=0.7)\n",
    "    \n",
    "    # Add wells to forward plot\n",
    "    for loc in injection_locs_df:\n",
    "        k, i, j = loc[0], loc[1], loc[2]\n",
    "        x, y = m_sub_wells.modelgrid.xcellcenters[i, j], m_sub_wells.modelgrid.ycellcenters[i, j]\n",
    "        ax1.scatter(x, y, c='green', s=100, marker='^', label='Injection well' if loc is injection_locs_df[0] else \"\", \n",
    "                   edgecolors='black', linewidth=2, zorder=5)\n",
    "    \n",
    "    for loc in pumping_wells_df:\n",
    "        k, i, j = loc[0], loc[1], loc[2]\n",
    "        x, y = m_sub_wells.modelgrid.xcellcenters[i, j], m_sub_wells.modelgrid.ycellcenters[i, j]\n",
    "        ax1.scatter(x, y, c='red', s=100, marker='v', label='Pumping well' if loc is pumping_wells_df[0] else \"\", \n",
    "                   edgecolors='black', linewidth=2, zorder=5)\n",
    "    \n",
    "    ax1.set_title('Forward Particle Tracking\\n(From injection wells)', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.set_aspect('equal')\n",
    "    \n",
    "    # Right plot: Backward tracking (to pumping wells)\n",
    "    if 'backward_pathlines' in locals() and len(backward_pathlines) > 0:\n",
    "        mm_backward = flopy.plot.PlotMapView(model=m_sub_wells, layer=0, ax=ax2)\n",
    "        mm_backward.plot_grid(lw=0.5, alpha=0.3)\n",
    "        mm_backward.plot_pathline(backward_pathlines, layer=\"all\", colors=\"red\", \n",
    "                                 label=\"Backward: to pumping wells\", linewidth=2, alpha=0.8)\n",
    "        mm_backward.plot_endpoint(backward_endpoints, direction=\"starting\", colorbar=False, \n",
    "                                 s=20, alpha=0.7, color='orange')   \n",
    "        # Add wells to backward plot\n",
    "        for loc in injection_locs_df:\n",
    "            k, i, j = loc[0], loc[1], loc[2]\n",
    "            x, y = m_sub_wells.modelgrid.xcellcenters[i, j], m_sub_wells.modelgrid.ycellcenters[i, j]\n",
    "            ax2.scatter(x, y, c='green', s=100, marker='^', label='Injection well' if loc is injection_locs_df[0] else \"\", \n",
    "                       edgecolors='black', linewidth=2, zorder=5)   \n",
    "        for loc in pumping_wells_df:\n",
    "            k, i, j = loc[0], loc[1], loc[2]\n",
    "            x, y = m_sub_wells.modelgrid.xcellcenters[i, j], m_sub_wells.modelgrid.ycellcenters[i, j]\n",
    "            ax2.scatter(x, y, c='red', s=100, marker='v', label='Pumping well' if loc is pumping_wells_df[0] else \"\", \n",
    "                       edgecolors='black', linewidth=2, zorder=5)\n",
    "        ax2.set_title('Backward Particle Tracking\\n(Capture zone of pumping wells)', fontsize=14, fontweight='bold')\n",
    "        ax2.legend(loc='upper right')\n",
    "        ax2.set_aspect('equal')\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'No backward tracking data available', horizontalalignment='center', \n",
    "                 verticalalignment='center', transform=ax2.transAxes, fontsize=16, color='red')\n",
    "        ax2.set_title('Backward Particle Tracking\\n(Capture zone of pumping wells)', fontsize=14, fontweight='bold')\n",
    "        ax2.set_aspect('equal')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed4f2cd",
   "metadata": {},
   "source": [
    "## 4 Implement forcing scenario in parent model parent_scenario\n",
    "\n",
    "### 4.1 Set up parent_scenario model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c8aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the m_sub_base model as m_parent_scenario model and edit the workspace\n",
    "m_parent_scenario = flopy.modflow.Modflow.load(\n",
    "    namefile.replace('.nam', ''), \n",
    "    model_ws=parent_base_ws,\n",
    "    forgive=True, \n",
    "    check=False, \n",
    "    exe_name='mfnwt'\n",
    ")\n",
    "# Change workspace to the new directory parent_scenario_ws\n",
    "m_parent_scenario.model_ws = parent_scenario_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c289d1f7",
   "metadata": {},
   "source": [
    "### 4.1 Implement scenario changes in parent_scenario model\n",
    "The demonstration scenario SC0 involves a lowering of the outflow boundary head by 1 m. This is implemented in the parent_scenario model.\n",
    "\n",
    "We will first update the CHD boundary condition in the parent_scenario model to reflect the scenario change.\n",
    "\n",
    "`#TODO`: You will need to implement your own scenario changes here. Replace the following code chunk for your own scenario changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91117f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "chd_parent_base = m_parent_scenario.chd\n",
    "if chd_parent_base is None:\n",
    "    print(\"No CHD package in parent model - cannot add new CHD boundaries\")\n",
    "else:\n",
    "    # Extract existing CHD data\n",
    "    chd_data = chd_parent_base.stress_period_data[0]  # Assuming single stress period for simplicity\n",
    "    print(f\"Parent model has {len(chd_data)} existing CHD boundary conditions\")\n",
    "\n",
    "    # Create a copy of the existing CHD data to modify\n",
    "    new_chd_data = chd_data.copy()\n",
    "    \n",
    "    # Extract the CHD head change value for the current group\n",
    "    # Find the scenario that matches the group number\n",
    "    scenario_options = cfg['scenarios']['options']\n",
    "    chd_head_change_m = None\n",
    "    \n",
    "    for scenario in scenario_options:\n",
    "        if scenario['id'] == group_number:\n",
    "            chd_head_change_m = scenario['chd_head_change_m']\n",
    "            print(f\"Group {group_number}: CHD head change = {chd_head_change_m} m\")\n",
    "            break\n",
    "    \n",
    "    if chd_head_change_m is None:\n",
    "        print(f\"No scenario found for group {group_number}\")\n",
    "    else:\n",
    "        print(f\"Applying CHD head change of {chd_head_change_m} m to boundary conditions\")\n",
    "        # Add chd_head_change_m to the head values of all CHD cells in the group\n",
    "        for idx, (layer, row, col, head_start, head_end) in enumerate(new_chd_data):\n",
    "            # Here we assume all CHD cells belong to the group for simplicity\n",
    "            new_head_start = head_start + chd_head_change_m\n",
    "            new_head_end = head_end + chd_head_change_m\n",
    "            new_chd_data[idx] = (layer, row, col, new_head_start, new_head_end)\n",
    "            print(f\"  Updated CHD at (L{layer}, R{row}, C{col}): {head_start:.2f} -> {new_head_start:.2f} m, {head_end:.2f} -> {new_head_end:.2f} m\")\n",
    "\n",
    "        # Update the CHD package with modified data\n",
    "        chd_parent_scenario = flopy.modflow.ModflowChd(\n",
    "            m_parent_scenario,\n",
    "            stress_period_data={0: new_chd_data},\n",
    "            ipakcb=53  # Save cell-by-cell budget\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a02fe1",
   "metadata": {},
   "source": [
    "### 4.2 Plot old and new CHD boundary\n",
    "\n",
    "`#TODO`: We highly recommend you visualize your changes of the boundary conditions. You can remove this section if not needed for your scenario changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f019a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_utils.plot_chd_comparison(m_parent_base, m_parent_scenario, figsize=(15, 6), buffer_cells=5)\n",
    "\n",
    "# Print a summary of the comparison of the chd packages in the parent base and \n",
    "# scenario models\n",
    "if fig is not None:\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CHD BOUNDARY CONDITIONS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Extract CHD data for analysis\n",
    "    chd_base = m_parent_base.chd.stress_period_data[0]\n",
    "    chd_scenario = m_parent_scenario.chd.stress_period_data[0]\n",
    "    \n",
    "    # Calculate head values\n",
    "    base_heads = [cell[4] for cell in chd_base]  # end head values\n",
    "    scenario_heads = [cell[4] for cell in chd_scenario]  # end head values\n",
    "    \n",
    "    print(f\"Base model:\")\n",
    "    print(f\"  Number of CHD cells: {len(chd_base)}\")\n",
    "    print(f\"  Head range: {min(base_heads):.2f} - {max(base_heads):.2f} m\")\n",
    "    print(f\"  Mean head: {np.mean(base_heads):.2f} m\")\n",
    "    \n",
    "    print(f\"\\nScenario model:\")\n",
    "    print(f\"  Number of CHD cells: {len(chd_scenario)}\")\n",
    "    print(f\"  Head range: {min(scenario_heads):.2f} - {max(scenario_heads):.2f} m\")\n",
    "    print(f\"  Mean head: {np.mean(scenario_heads):.2f} m\")\n",
    "    \n",
    "    # Calculate differences\n",
    "    if len(base_heads) == len(scenario_heads):\n",
    "        head_differences = [s - b for s, b in zip(scenario_heads, base_heads)]\n",
    "        print(f\"\\nHead differences (Scenario - Base):\")\n",
    "        print(f\"  Range: {min(head_differences):.2f} - {max(head_differences):.2f} m\")\n",
    "        print(f\"  Mean difference: {np.mean(head_differences):.2f} m\")\n",
    "    else:\n",
    "        print(f\"\\nWarning: Different number of CHD cells between models!\")\n",
    "        print(f\"Cannot calculate direct differences.\")\n",
    "        \n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbaa745",
   "metadata": {},
   "source": [
    "### 4.2 Run parent_scenario model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666f0422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write input files and run the parent model\n",
    "print(\"Writing parent model input files...\")\n",
    "m_parent_scenario.write_input()\n",
    "\n",
    "# Check model setup\n",
    "print(\"\\nChecking parent model setup...\")\n",
    "chk = m_parent_scenario.check(f=None, verbose=False)\n",
    "if chk.summary_array is not None and len(chk.summary_array) > 0:\n",
    "    print(\"Model check warnings found - reviewing...\")\n",
    "    for warning in chk.summary_array:\n",
    "        print(f\"  Warning: {warning}\")\n",
    "else:\n",
    "    print(\"Model check passed\")\n",
    "\n",
    "# Run the parent model\n",
    "print(f\"\\nRunning scenario parent model...\")\n",
    "success, buff = m_parent_scenario.run_model(silent=False, report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd09bb6",
   "metadata": {},
   "source": [
    "### 4.3 Visualize parent_scenario model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes, head_diff = plot_utils.plot_head_difference(\n",
    "    model_base=m_parent_base,\n",
    "    model_scenario=m_parent_scenario, \n",
    "    ws_base=parent_base_ws,\n",
    "    ws_scenario=parent_scenario_ws,\n",
    "    model_name=namefile.replace('.nam', ''),\n",
    "    scenario_name=\"Parent Scenario\",\n",
    "    show_depth_plots=False,\n",
    "    min_contour_diff=1.0,\n",
    "    well_marker_size=40,  # Smaller for regional model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58290697",
   "metadata": {},
   "source": [
    "## 5 Update the CHD boundary for the sub_scenario model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7209a8aa",
   "metadata": {},
   "source": [
    "### 5.1 Set up sub_scenario model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e8a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the m_sub_base model as m_sub_scenario model and edit the workspace\n",
    "m_sub_scenario = flopy.modflow.Modflow.load(\n",
    "    namefile.replace('.nam', ''), \n",
    "    model_ws=sub_base_ws,\n",
    "    forgive=True, \n",
    "    check=False, \n",
    "    exe_name='mfnwt'\n",
    ")\n",
    "# Change workspace to the new directory sub_scenario_ws\n",
    "m_sub_scenario.model_ws = sub_scenario_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee722a4a",
   "metadata": {},
   "source": [
    "### 5.2 Update CHD boundary conditions for sub_scenario model\n",
    "We will now update the CHD boundary conditions for the sub_scenario model based on the results from the parent_scenario model. This ensures that the submodel reflects the new forcing conditions.\n",
    "\n",
    "#### Extract boundary heads from parent_scenario model\n",
    "Same procedure as in Chapter 2.5.2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92dc679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract parent model heads for boundary interpolation\n",
    "print(\"Extracting parent model heads for boundary condition interpolation...\")\n",
    "\n",
    "# Load parent model heads\n",
    "parent_hds_path = os.path.join(parent_scenario_ws, f\"{m_parent_scenario.name}.hds\")\n",
    "if not os.path.exists(parent_hds_path):\n",
    "    print(\"Parent model heads file not found. Running parent model...\")\n",
    "    success, buff = m_parent_scenario.run_model(silent=True, report=True)\n",
    "    if not success:\n",
    "        raise RuntimeError(\"Parent model failed to run\")\n",
    "    print(\"✓ Parent model run completed\")\n",
    "\n",
    "# Load parent heads\n",
    "headobj_parent = flopy.utils.HeadFile(parent_hds_path)\n",
    "parent_heads = headobj_parent.get_data()[0]  # Layer 0, stress period 0\n",
    "\n",
    "# Get parent model grid coordinates and active cells\n",
    "parent_ibound = m_parent_scenario.bas6.ibound.array[0]  # Layer 0\n",
    "parent_active_mask = parent_ibound == 1\n",
    "\n",
    "# Extract coordinates of active parent cells\n",
    "parent_x_centers = parent_modelgrid.xcellcenters[parent_active_mask]\n",
    "parent_y_centers = parent_modelgrid.ycellcenters[parent_active_mask]\n",
    "parent_heads_active = parent_heads[parent_active_mask]\n",
    "\n",
    "# Filter out any invalid heads (NaN, inf, or unrealistic values)\n",
    "valid_head_mask = (np.isfinite(parent_heads_active) & \n",
    "                   (parent_heads_active > 300) &  # Reasonable lower bound for elevation\n",
    "                   (parent_heads_active < 600))   # Reasonable upper bound for elevation\n",
    "\n",
    "parent_coords_valid = np.column_stack([\n",
    "    parent_x_centers[valid_head_mask],\n",
    "    parent_y_centers[valid_head_mask]\n",
    "])\n",
    "parent_heads_valid = parent_heads_active[valid_head_mask]\n",
    "\n",
    "print(f\"Parent model head extraction:\")\n",
    "print(f\"  Total parent cells: {parent_heads.size:,}\")\n",
    "print(f\"  Active parent cells: {np.sum(parent_active_mask):,}\")\n",
    "print(f\"  Valid heads for interpolation: {len(parent_heads_valid):,}\")\n",
    "print(f\"  Head range: {parent_heads_valid.min():.1f} to {parent_heads_valid.max():.1f} m\")\n",
    "\n",
    "# Create KDTree for efficient nearest neighbor search\n",
    "from scipy.spatial import cKDTree\n",
    "parent_tree = cKDTree(parent_coords_valid)\n",
    "\n",
    "print(\"✓ Parent model heads prepared for boundary interpolation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe42e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the complete boundary and create IBOUND\n",
    "print(\"Creating complete CHD boundary around submodel domain...\")\n",
    "submodel_ibound_complete, boundary_cells_complete = create_complete_boundary_ibound(\n",
    "    submodel_grid, clipped_submodel_boundary, boundary_thickness=1\n",
    ")\n",
    "\n",
    "print(f\"Complete boundary detection results:\")\n",
    "print(f\"  Total boundary cells: {len(boundary_cells_complete)}\")\n",
    "print(f\"  CHD cells: {np.sum(submodel_ibound_complete == -1):,}\")\n",
    "print(f\"  Active cells: {np.sum(submodel_ibound_complete == 1):,}\")\n",
    "\n",
    "# Head interpolation for all boundary cells\n",
    "print(\"Interpolating heads for all boundary cells...\")\n",
    "\n",
    "# Use the same KDTree approach but for all boundary cells\n",
    "sub_boundary_coords_complete = []\n",
    "for cell in boundary_cells_complete:\n",
    "    sub_boundary_coords_complete.append([cell['x'], cell['y']])\n",
    "\n",
    "sub_boundary_coords_complete = np.array(sub_boundary_coords_complete)\n",
    "\n",
    "# Perform inverse distance weighted interpolation\n",
    "k_neighbors = min(5, len(parent_heads_valid))\n",
    "distances, neighbor_indices = parent_tree.query(sub_boundary_coords_complete, k=k_neighbors)\n",
    "\n",
    "# Handle zero distances\n",
    "distances = np.maximum(distances, 1e-10)\n",
    "\n",
    "# Calculate weights\n",
    "weights = 1.0 / distances\n",
    "weights = weights / weights.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Weighted average\n",
    "interpolated_heads_complete = np.sum(\n",
    "    parent_heads_valid[neighbor_indices] * weights, axis=1\n",
    ")\n",
    "\n",
    "# Create CHD package data for all boundary cells\n",
    "chd_data_complete = []\n",
    "for i, cell in enumerate(boundary_cells_complete):\n",
    "    interpolated_head = float(interpolated_heads_complete[i])\n",
    "    \n",
    "    chd_data_complete.append([\n",
    "        0,  # Layer 0\n",
    "        cell['submodel_row'],\n",
    "        cell['submodel_col'],\n",
    "        interpolated_head,\n",
    "        interpolated_head\n",
    "    ])\n",
    "\n",
    "print(f\"Complete CHD data created: {len(chd_data_complete)} cells\")\n",
    "\n",
    "# Update variables for consistency with rest of notebook\n",
    "submodel_ibound_clipped = submodel_ibound_complete\n",
    "boundary_cells = boundary_cells_complete\n",
    "submodel_chd_data = chd_data_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf37504",
   "metadata": {},
   "source": [
    "#### Write CHD package for sub_scenario model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_scenario_chd = flopy.modflow.ModflowChd(\n",
    "    model=m_sub_wells,\n",
    "    stress_period_data={0: submodel_chd_data},\n",
    "    ipakcb=53,\n",
    "    model_ws=sub_scenario_ws\n",
    ")\n",
    "\n",
    "# Extract CHD package data and visualize with continuous colormap\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "pmv = flopy.plot.PlotMapView(model=m_sub_scenario, ax=ax)\n",
    "pmv.plot_grid(color='gray', alpha=0.3, linewidth=0.3)\n",
    "\n",
    "# Extract CHD data\n",
    "chd_package = m_sub_scenario.chd\n",
    "chd_data = chd_package.stress_period_data[0]  # First stress period\n",
    "\n",
    "# Create arrays to hold CHD head values for plotting\n",
    "chd_array = np.full((m_sub_scenario.nrow, m_sub_scenario.ncol), np.nan)\n",
    "chd_coords_x = []\n",
    "chd_coords_y = []\n",
    "chd_heads = []\n",
    "\n",
    "for chd_cell in chd_data:\n",
    "    layer, row, col, start_head, end_head = chd_cell\n",
    "    chd_array[row, col] = start_head\n",
    "    \n",
    "    # Also collect coordinates for scatter plot option\n",
    "    x = m_sub_scenario.modelgrid.xcellcenters[row, col]\n",
    "    y = m_sub_scenario.modelgrid.ycellcenters[row, col]\n",
    "    chd_coords_x.append(x)\n",
    "    chd_coords_y.append(y)\n",
    "    chd_heads.append(start_head)\n",
    "\n",
    "# Method 1: Plot CHD as array (shows cells as squares)\n",
    "chd_masked = np.ma.masked_where(np.isnan(chd_array), chd_array)\n",
    "im = pmv.plot_array(chd_masked, alpha=0.8, cmap='viridis')\n",
    "\n",
    "# Method 2: Alternative - plot as scatter points (optional, comment out if using array method)\n",
    "# scatter = ax.scatter(chd_coords_x, chd_coords_y, \n",
    "#                     c=chd_heads, \n",
    "#                     s=30,  # Size of points\n",
    "#                     cmap='viridis',\n",
    "#                     edgecolors='white',\n",
    "#                     linewidth=0.5,\n",
    "#                     alpha=0.8)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.7)\n",
    "cbar.set_label('CHD Head (m a.s.l.)', fontsize=12)\n",
    "\n",
    "# Add contours of CHD heads for better visualization\n",
    "if len(chd_heads) > 3:  # Need at least a few points for contouring\n",
    "    from scipy.interpolate import griddata\n",
    "    \n",
    "    # Create a regular grid for interpolation\n",
    "    xi = np.linspace(ax.get_xlim()[0], ax.get_xlim()[1], 50)\n",
    "    yi = np.linspace(ax.get_ylim()[0], ax.get_ylim()[1], 50)\n",
    "    xi_grid, yi_grid = np.meshgrid(xi, yi)\n",
    "    \n",
    "    # Interpolate CHD values\n",
    "    zi_grid = griddata((chd_coords_x, chd_coords_y), chd_heads, \n",
    "                       (xi_grid, yi_grid), method='linear')\n",
    "    \n",
    "    # Add contour lines\n",
    "    contours = ax.contour(xi_grid, yi_grid, zi_grid, \n",
    "                         levels=8, colors='white', linewidths=1, alpha=0.8)\n",
    "    ax.clabel(contours, inline=True, fontsize=9, fmt='%.1f m')\n",
    "\n",
    "# Plot wells for reference\n",
    "if 'wells_gdf' in locals():\n",
    "    wells_gdf.plot(ax=ax, color='red', markersize=60, label='Wells', zorder=5,\n",
    "                   edgecolors='white', linewidth=1)\n",
    "\n",
    "ax.set_title('CHD Package - Specified Heads with Continuous Colormap')\n",
    "ax.set_xlabel('X Coordinate (m)')\n",
    "ax.set_ylabel('Y Coordinate (m)')\n",
    "ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print CHD statistics\n",
    "print(f\"CHD Package Summary:\")\n",
    "print(f\"  Number of CHD cells: {len(chd_data)}\")\n",
    "print(f\"  Head range: {min(chd_heads):.2f} to {max(chd_heads):.2f} m\")\n",
    "print(f\"  Mean head: {np.mean(chd_heads):.2f} m\")\n",
    "print(f\"  Standard deviation: {np.std(chd_heads):.2f} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e92c5da",
   "metadata": {},
   "source": [
    "#### Write BAS package for sub_scenario model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3687b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_scenario_bas = flopy.modflow.ModflowBas(m_sub_scenario, ibound=submodel_ibound_clipped, strt=gw_elevations)\n",
    "\n",
    "# Plot IBOUND and starting heads\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "pmv = flopy.plot.PlotMapView(model=m_sub_scenario, ax=ax)\n",
    "im = pmv.plot_ibound()\n",
    "plt.colorbar(im, ax=ax, shrink=0.7, ticks=[-1, 0, 1])\n",
    "pmv.plot_grid(color='gray', alpha=0.3, linewidth=0.3)\n",
    "ax.set_title('IBOUND Array')\n",
    "plt.xlabel(\"X-coordinate\")\n",
    "plt.ylabel(\"Y-coordinate\")\n",
    "ax.set_aspect('equal')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ef63c",
   "metadata": {},
   "source": [
    "#### Get the WEL package from sub_wells model and add to sub_scenario model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abfb631",
   "metadata": {},
   "outputs": [],
   "source": [
    "wel_sub_wells = m_sub_wells.wel\n",
    "if wel_sub_wells is None:\n",
    "    print(\"No WEL package in submodel - cannot add wells\")\n",
    "else:\n",
    "    wel_sub_scenario = flopy.modflow.ModflowWel(\n",
    "        m_sub_scenario,\n",
    "        stress_period_data=wel_sub_wells.stress_period_data,\n",
    "        ipakcb=53  # Save cell-by-cell budget\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1cf4f2",
   "metadata": {},
   "source": [
    "### 5.3 Run sub_scenario model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfee353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write input files and run the submodel\n",
    "print(\"Writing submodel input files...\")\n",
    "m_sub_scenario.write_input()\n",
    "\n",
    "# Check model setup\n",
    "print(\"\\nChecking submodel setup...\")\n",
    "chk = m_sub_scenario.check(f=None, verbose=False)\n",
    "if chk.summary_array is not None and len(chk.summary_array) > 0:\n",
    "    print(\"Model check warnings found - reviewing...\")\n",
    "    for warning in chk.summary_array:\n",
    "        print(f\"  Warning: {warning}\")\n",
    "else:\n",
    "    print(\"Model check passed\")\n",
    "\n",
    "# Run the submodel\n",
    "print(f\"\\nRunning refined submodel...\")\n",
    "success, buff = m_sub_scenario.run_model(silent=False, report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a0d92c",
   "metadata": {},
   "source": [
    "### 5.4 Visualize sub_scenario model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fb6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if success: \n",
    "    plot_utils.plot_model_results(m_sub_scenario, sub_scenario_ws, namefile.replace('.nam', ''),\n",
    "                                  show_wells=False, show_ibound=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18b31a1",
   "metadata": {},
   "source": [
    "## 6 Comparison of Results\n",
    "\n",
    "In this section, we will compare the results from the different model runs to assess the impacts of the well group and the scenario changes. We will focus on key metrics such as groundwater heads, flow patterns, and mass balance.\n",
    "\n",
    "`#TODO`: You will need to implement your own comparison sections here. The following is just an example structure. We will expect you to discuss and interpret your results in your final report and presentation.\n",
    "\n",
    "### 6.1 Compare sub_base vs sub_wells\n",
    "\n",
    "#### 6.1.1 Steady-State Groundwater Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fe3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Full plot with both head and depth analysis (default behavior)\n",
    "fig, axes, head_diff = plot_utils.plot_head_difference(\n",
    "    model_base=m_sub_base,\n",
    "    model_scenario=m_sub_wells, \n",
    "    ws_base=sub_base_ws,\n",
    "    ws_scenario=sub_wells_ws,\n",
    "    model_name=namefile.replace('.nam', ''),\n",
    "    scenario_name=\"Wells 210\",\n",
    "    save_path=os.path.join(results_ws, 'head_difference_analysis_full.png')\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Example with only head analysis (no depth plots):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Example 2: Only head analysis plots (compact view)\n",
    "fig_compact, axes_compact, head_diff_compact = plot_utils.plot_head_difference(\n",
    "    model_base=m_sub_base,\n",
    "    model_scenario=m_sub_wells, \n",
    "    ws_base=sub_base_ws,\n",
    "    ws_scenario=sub_wells_ws,\n",
    "    model_name=namefile.replace('.nam', ''),\n",
    "    scenario_name=\"Wells 210\",\n",
    "    show_depth_plots=False,\n",
    "    save_path=os.path.join(results_ws, 'head_difference_analysis_compact.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943e1de2",
   "metadata": {},
   "source": [
    "#### 6.1.2 Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d6841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare budgets between sub_base and sub_wells models\n",
    "fig_budget, axes_budget, budget_comparison_df = plot_utils.compare_budget(\n",
    "    ws_base=sub_base_ws,\n",
    "    ws_scenario=sub_wells_ws, \n",
    "    model_name=namefile.replace('.nam', ''),\n",
    "    scenario_name=\"Wells 210\",\n",
    "    save_path=os.path.join(results_ws, 'sub_wells_budget_comparison.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73bbb9d",
   "metadata": {},
   "source": [
    "### 6.2 Compare sub_wells vs sub_scenario\n",
    "\n",
    "#### 6.2.1 Steady-State Groundwater Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e371c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_compact, axes_compact, head_diff_compact = plot_utils.plot_head_difference(\n",
    "    model_base=m_sub_wells,\n",
    "    model_scenario=m_sub_scenario, \n",
    "    ws_base=sub_wells_ws,\n",
    "    ws_scenario=sub_scenario_ws,\n",
    "    model_name=namefile.replace('.nam', ''),\n",
    "    scenario_name=\"CHD-1m\",\n",
    "    show_depth_plots=False,\n",
    "    save_path=os.path.join(results_ws, 'sub_scenario_head_difference_analysis_compact.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757821c",
   "metadata": {},
   "source": [
    "#### 6.2.2 Groundwater Budget Comparison\n",
    "\n",
    "Now let's compare the groundwater budgets between the base model (sub_wells) and the scenario model (sub_scenario) to understand how the change in boundary conditions affects water balance terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a047c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare budgets between sub_wells (base) and sub_scenario models\n",
    "fig_budget, axes_budget, budget_comparison_df = plot_utils.compare_budget(\n",
    "    ws_base=sub_wells_ws,\n",
    "    ws_scenario=sub_scenario_ws, \n",
    "    model_name=namefile.replace('.nam', ''),\n",
    "    scenario_name=\"CHD-1m\",\n",
    "    save_path=os.path.join(results_ws, 'sub_scenario_budget_comparison.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7363cc",
   "metadata": {},
   "source": [
    "The changed outflow boundary of the regional model does not have an impact on the local flow field around the well group. The flow field is insensitive to the 1m change of the outflow boundary condition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gw_course_students",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
