{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a660e845",
   "metadata": {},
   "source": [
    "### ðŸš¦ Repository Freshness & Reset (Read Before Running)\n",
    "\n",
    "This course repository should match the official `course_2025` branch so everyone works from the same, **clean** material. Each time you open this diagnostics notebook, we optionally verify the repository matches the remote branch.\n",
    "\n",
    "#### JupyterHub vs Local Safety\n",
    "- On **JupyterHub** (teaching environment), an automatic *hard reset* can be convenient to remove stray/accidental edits.\n",
    "- On your **local machine**, a hard reset could delete genuine work. So in local environments this notebook will **NOT** perform a destructive reset unless you explicitly opt in.\n",
    "\n",
    "Environment detection: we treat the session as JupyterHub only if at least one `JUPYTERHUB_*` environment variable is present. Otherwise we assume \"local\" and fall back to *instructions only*.\n",
    "\n",
    "#### Protect Your Personal Work\n",
    "If you have made your own edits inside this teaching repository, a hard reset will ERASE them. To keep personal work (e.g. model experiments, trial scripts, modified notebooks):\n",
    "\n",
    "1. Create a personal folder outside the teaching repo, e.g. `~/own_model_files/` (or use your home area / a personal git repo).\n",
    "2. Copy any changed files you care about into that folder *before* running (or forcing) a reset.\n",
    "3. Only then proceed with the reset step below.\n",
    "4. Please remember that you will lose access to your JupyterHub instance once the semester is complete. Please copy your important files to a personal location.\n",
    "\n",
    "#### What the next code cell does\n",
    "- Locates the repository directory (tries `~/applied_groundwater_modelling.git` then `~/applied_groundwater_modelling`).\n",
    "- Runs `git fetch origin`.\n",
    "- Lists uncommitted / untracked changes.\n",
    "- If local changes exist: it **will NOT reset automatically**; shows a warning + changed files.\n",
    "- If clean and in JupyterHub: performs a safe hard reset to `origin/course_2025` to guarantee a clean state.\n",
    "- If NOT in JupyterHub: only prints guidance unless you deliberately enable a local override flag.\n",
    "\n",
    "> Run the next cell only when you're sure you don't need to keep local edits inside this repository.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d14e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ENV] JupyterHub detected: False\n",
      "[INFO] Using repository: /Users/bea/Documents/GitHub/applied_groundwater_modelling\n",
      "[STEP] Fetch latest remote refs...\n",
      "[STEP] Checking status...\n",
      "\n",
      "[WARNING] Local (uncommitted or untracked) changes detected.\n",
      "    M 0_diagnostics.ipynb\n",
      "    ?? SUPPORT_REPO/src/repo_sync.py\n",
      "\n",
      "You have local work in the teaching repository.\n",
      "If you want to keep it, copy the changed files NOW to a personal directory, e.g.:\n",
      "    mkdir -p ~/own_model_files\n",
      "    cp <file_you_care_about> ~/own_model_files/\n",
      "Then re-run with appropriate flags (force_reset / allow_local_reset) if you intend to discard changes.\n",
      "\n",
      "\n",
      "=== SYNC SUMMARY ===\n",
      "repo_path: /Users/bea/Documents/GitHub/applied_groundwater_modelling\n",
      "jupyterhub: False\n",
      "changed_files:\n",
      "    M 0_diagnostics.ipynb\n",
      "    ?? SUPPORT_REPO/src/repo_sync.py\n",
      "performed_reset: False\n",
      "blocked: True\n",
      "message: Blocked: local changes present and force_reset is False\n",
      "error: None\n",
      "[STEP] Checking status...\n",
      "\n",
      "[WARNING] Local (uncommitted or untracked) changes detected.\n",
      "    M 0_diagnostics.ipynb\n",
      "    ?? SUPPORT_REPO/src/repo_sync.py\n",
      "\n",
      "You have local work in the teaching repository.\n",
      "If you want to keep it, copy the changed files NOW to a personal directory, e.g.:\n",
      "    mkdir -p ~/own_model_files\n",
      "    cp <file_you_care_about> ~/own_model_files/\n",
      "Then re-run with appropriate flags (force_reset / allow_local_reset) if you intend to discard changes.\n",
      "\n",
      "\n",
      "=== SYNC SUMMARY ===\n",
      "repo_path: /Users/bea/Documents/GitHub/applied_groundwater_modelling\n",
      "jupyterhub: False\n",
      "changed_files:\n",
      "    M 0_diagnostics.ipynb\n",
      "    ?? SUPPORT_REPO/src/repo_sync.py\n",
      "performed_reset: False\n",
      "blocked: True\n",
      "message: Blocked: local changes present and force_reset is False\n",
      "error: None\n"
     ]
    }
   ],
   "source": [
    "# Repository sync (lean) â€“ simplified: assumes this notebook runs from project root\n",
    "# and that SUPPORT_REPO/src exists directly under it.\n",
    "\n",
    "from importlib import reload\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "support_src = Path('SUPPORT_REPO/src').resolve()\n",
    "if not support_src.exists():\n",
    "    raise RuntimeError(\"Expected SUPPORT_REPO/src at project root but it was not found.\")\n",
    "if str(support_src) not in sys.path:\n",
    "    sys.path.insert(0, str(support_src))\n",
    "\n",
    "import repo_sync  # type: ignore\n",
    "reload(repo_sync)\n",
    "\n",
    "# User-adjustable flags\n",
    "FORCE_RESET = False          # destructive if True and changes exist\n",
    "ALLOW_LOCAL_RESET = False    # allow destructive reset off JupyterHub\n",
    "DRY_RUN = False              # report only\n",
    "REPO_PATH_OVERRIDE = None    # optional absolute path override\n",
    "TARGET_REMOTE = 'origin'\n",
    "TARGET_BRANCH = 'course_2025'\n",
    "\n",
    "result = repo_sync.sync_repository(\n",
    "    force_reset=FORCE_RESET,\n",
    "    allow_local_reset=ALLOW_LOCAL_RESET,\n",
    "    dry_run=DRY_RUN,\n",
    "    repo_path_override=REPO_PATH_OVERRIDE,\n",
    "    target_remote=TARGET_REMOTE,\n",
    "    target_branch=TARGET_BRANCH,\n",
    ")\n",
    "# repo_sync.print_sync_summary(result)\n",
    "repo_sync_result = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50f5db2",
   "metadata": {},
   "source": [
    "# Project Diagnostics Notebook (0_diagnostics)\n",
    "\n",
    "Run this notebook on JupyterHub to verify your computational environment for the *Applied Groundwater Modelling* course.\n",
    "It will:\n",
    "\n",
    "1. Summarize Python & platform info\n",
    "2. Parse environment YAML (if present) and compile required package list\n",
    "3. Check imports & report missing packages + versions\n",
    "4. Optionally (commented) help you install missing packages\n",
    "5. Verify geospatial stack (GeoPandas / Shapely / Fiona / PyProj / RasterIO / Contextily)\n",
    "6. Test folium, plotly interactive plotting\n",
    "7. Detect MODFLOW-2005 executable & run a minimal FloPy model\n",
    "8. Basic 3D visualization capability check (plotly)\n",
    "9. (Optional) Memory / performance snapshot (psutil)\n",
    "10. Produce an aggregated summary at the end\n",
    "\n",
    "If something fails, scroll to see the first failing diagnostic cell.\n",
    "\n",
    "---\n",
    "**Tip:** Re-run the whole notebook after fixing issues to confirm readiness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5dc627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a global results dictionary to accumulate checks\n",
    "from __future__ import annotations\n",
    "diag_results = {\n",
    "    'python': {},\n",
    "    'packages': {},\n",
    "    'geospatial': {},\n",
    "    'viz': {},\n",
    "    'modflow': {},\n",
    "    'system': {}\n",
    "}\n",
    "print('Diagnostics result container initialized.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebe0f15",
   "metadata": {},
   "source": [
    "## 1. Python & Platform Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, platform, os, datetime, shutil\n",
    "py_info = {\n",
    "    'python_version': sys.version.replace('\\n', ' '),\n",
    "    'executable': sys.executable,\n",
    "    'platform': platform.platform(),\n",
    "    'processor': platform.processor(),\n",
    "    'python_build': platform.python_build(),\n",
    "    'datetime_utc': datetime.datetime.utcnow().isoformat()+'Z'\n",
    "}\n",
    "diag_results['python'] = py_info\n",
    "print('Python/platform info collected:')\n",
    "for k,v in py_info.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d60b9ee",
   "metadata": {},
   "source": [
    "## 2. Compile Required Package List\n",
    "This attempts to parse `environment_students.yml` and `environment_development.yml` if available to build a dependency list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f73bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json\n",
    "required_packages = set()\n",
    "yaml_files = ['environment_students.yml','environment_development.yml']\n",
    "raw_dep_lines = []\n",
    "for yf in yaml_files:\n",
    "    if os.path.exists(yf):\n",
    "        try:\n",
    "            with open(yf,'r') as f:\n",
    "                for line in f:\n",
    "                    ls = line.strip()\n",
    "                    raw_dep_lines.append(ls)\n",
    "        except Exception as e:\n",
    "            print(f'Could not read {yf}: {e}')\n",
    "# Heuristic: capture package-like tokens (avoid channels, python=, version pins)\n",
    "pattern = re.compile(r'^[A-Za-z0-9_.-]+(?:==|=)?[A-Za-z0-9_.-]*$')\n",
    "skip_prefixes = ('python', 'pip', 'anaconda', 'mamba')\n",
    "for ln in raw_dep_lines:\n",
    "    if ln.startswith('- '):\n",
    "        token = ln[2:].strip()\n",
    "        # Cut off version spec after first = or space\n",
    "        token = re.split(r'[ =<>]', token)[0]\n",
    "        if token and pattern.match(token) and not token.lower().startswith(skip_prefixes):\n",
    "            required_packages.add(token)\n",
    "# Add core stack explicitly (ensures critical packages are checked)\n",
    "core = [\n",
    " 'numpy','pandas','matplotlib','geopandas','shapely','fiona','pyproj','rasterio',\n",
    " 'contextily','folium','plotly','flopy','scipy','xarray','netCDF4','tqdm','ruamel.yaml',\n",
    " 'IPython','jinja2','psutil'\n",
    " ]\n",
    "for c in core: required_packages.add(c)\n",
    "required_packages = sorted(required_packages)\n",
    "print(f'Total packages to check: {len(required_packages)}')\n",
    "print(', '.join(required_packages))\n",
    "diag_results['packages']['required_list'] = required_packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8df2d97",
   "metadata": {},
   "source": [
    "## 3. Import & Version Check\n",
    "Attempts to import each required package and record version or error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d96170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "package_status = {}\n",
    "missing = []\n",
    "for pkg in diag_results['packages']['required_list']:\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg.replace('-', '_'))\n",
    "        ver = getattr(mod, '__version__', 'unknown')\n",
    "        package_status[pkg] = {'ok': True, 'version': ver}\n",
    "    except Exception as e:\n",
    "        package_status[pkg] = {'ok': False, 'error': str(e)}\n",
    "        missing.append(pkg)\n",
    "diag_results['packages']['status'] = package_status\n",
    "print(f\"Packages OK: {sum(1 for v in package_status.values() if v['ok'])}\")\n",
    "print(f'Packages MISSING/FAILED: {len(missing)}')\n",
    "if missing:\n",
    "    print('Missing:', ', '.join(missing))\n",
    "else:\n",
    "    print('All required packages imported successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a985bb06",
   "metadata": {},
   "source": [
    "### (Optional) Install Missing Packages\n",
    "Uncomment and run the next cell ONLY if you have permission to install packages in this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3623ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to attempt installation (may not work on restricted JupyterHub)\n",
    "# if diag_results['packages'].get('status'):\n",
    "#     to_install = [p for p,s in diag_results['packages']['status'].items() if not s['ok']]\n",
    "#     if to_install:\n",
    "#         import sys, subprocess\n",
    "#         print('Attempting pip install for:', to_install)\n",
    "#         subprocess.check_call([sys.executable, '-m', 'pip', 'install', *to_install])\n",
    "#     else:\n",
    "#         print('No missing packages to install.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a563560",
   "metadata": {},
   "source": [
    "## 4. Geospatial Stack Smoke Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_checks = {}\n",
    "try:\n",
    "    import geopandas as gpd, shapely.geometry as geom, pyproj\n",
    "    from shapely.ops import unary_union\n",
    "    poly1 = geom.box(0,0,1,1)\n",
    "    poly2 = geom.box(0.5,0.5,1.5,1.5)\n",
    "    merged = unary_union([poly1, poly2])\n",
    "    gdf = gpd.GeoDataFrame({'id':[1,2],'geometry':[poly1, poly2]}, crs='EPSG:4326')\n",
    "    gdf_3857 = gdf.to_crs(3857)\n",
    "    area_ratio = gdf_3857.area.sum()/gdf.area.sum() if gdf.area.sum() else None\n",
    "    geo_checks['geopandas'] = True\n",
    "    geo_checks['shapely_union_ok'] = merged.is_valid\n",
    "    geo_checks['reproject_area_ratio'] = area_ratio\n",
    "except Exception as e:\n",
    "    geo_checks['error'] = str(e)\n",
    "# Fiona / rasterio presence\n",
    "for extra in ['fiona','rasterio','contextily']:\n",
    "    try:\n",
    "        __import__(extra)\n",
    "        geo_checks[extra] = True\n",
    "    except Exception as e:\n",
    "        geo_checks[extra] = f'ERROR: {e}'\n",
    "diag_results['geospatial'] = geo_checks\n",
    "print('Geospatial checks:')\n",
    "for k,v in geo_checks.items():\n",
    "    print(f'  {k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8106d41",
   "metadata": {},
   "source": [
    "## 5. Visualization Library Checks (folium, plotly, matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5f2adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_status = {}\n",
    "# Folium\n",
    "try:\n",
    "    import folium\n",
    "    fmap = folium.Map(location=[47.37, 8.55], zoom_start=10)\n",
    "    folium.Marker([47.37, 8.55], tooltip='Zurich').add_to(fmap)\n",
    "    viz_status['folium'] = 'ok (map object created)'\n",
    "except Exception as e:\n",
    "    viz_status['folium'] = f'ERROR: {e}'\n",
    "# Plotly\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    fig = go.Figure(data=[go.Scatter(x=[0,1], y=[0,1])])\n",
    "    viz_status['plotly'] = 'ok (scatter figure created)'\n",
    "except Exception as e:\n",
    "    viz_status['plotly'] = f'ERROR: {e}'\n",
    "# Matplotlib\n",
    "try:\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(); plt.plot([0,1],[0,1]); plt.close()\n",
    "    viz_status['matplotlib'] = 'ok (simple plot created)'\n",
    "except Exception as e:\n",
    "    viz_status['matplotlib'] = f'ERROR: {e}'\n",
    "diag_results['viz'] = viz_status\n",
    "print('Visualization stack:')\n",
    "for k,v in viz_status.items():\n",
    "    print(f'  {k}: {v}')\n",
    "# Display folium map last (if available)\n",
    "try:\n",
    "    fmap\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d36aa",
   "metadata": {},
   "source": [
    "## 6. MODFLOW-2005 Executable Detection & Minimal FloPy Model\n",
    "Attempts to locate a MODFLOW-2005 executable and run a 1-layer steady-state test model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9d6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile, textwrap, math\n",
    "modflow_diag = {}\n",
    "try:\n",
    "    import flopy\n",
    "    exe_candidates = ['mf2005','mf2005.exe','mf2005dbl','mfnwt']\n",
    "    found_exe = None\n",
    "    for cand in exe_candidates:\n",
    "        path = flopy.which(cand)\n",
    "        if path:\n",
    "            found_exe = path\n",
    "            break\n",
    "    modflow_diag['executable_found'] = bool(found_exe)\n",
    "    modflow_diag['executable_path'] = found_exe\n",
    "    if not found_exe:\n",
    "        print('No MODFLOW-2005 style executable detected; skipping run.')\n",
    "    else:\n",
    "        print(f'Using executable: {found_exe}')\n",
    "        with tempfile.TemporaryDirectory(prefix='mf2005_diag_') as ws:\n",
    "            m = flopy.modflow.Modflow('diagtest', model_ws=ws, exe_name=found_exe)\n",
    "            nlay, nrow, ncol = 1, 1, 10\n",
    "            Lx = 100.0\n",
    "            delr = Lx / ncol\n",
    "            delc = 1.0\n",
    "            top = 10.0\n",
    "            botm = 0.0\n",
    "            dis = flopy.modflow.ModflowDis(m, nlay, nrow, ncol, delr=delr, delc=delc, top=top, botm=botm)\n",
    "            ibound = [[[1]*ncol]]\n",
    "            # Constant heads at both ends\n",
    "            ibound[0][0][0] = -1\n",
    "            ibound[0][0][-1] = -1\n",
    "            strt = [[ [top if j==0 else 0.0 if j==ncol-1 else top/2 for j in range(ncol)] ]]\n",
    "            bas = flopy.modflow.ModflowBas(m, ibound=ibound, strt=strt)\n",
    "            lpf = flopy.modflow.ModflowLpf(m, hk=10.0, vka=10.0, ipakcb=53)\n",
    "            pcg = flopy.modflow.ModflowPcg(m)\n",
    "            oc = flopy.modflow.ModflowOc(m)\n",
    "            success, buff = m.run_model(silent=True)\n",
    "            modflow_diag['run_success'] = success\n",
    "            if success:\n",
    "                from flopy.utils import HeadFile\n",
    "                hf = HeadFile(os.path.join(ws,'diagtest.hds'))\n",
    "                h = hf.get_data(kstpkper=(0,0))[0,0,:]\n",
    "                modflow_diag['final_heads'] = h.tolist()\n",
    "                # Analytical linear solution between 10 and 0 over length Lx\n",
    "                x = [delr*(i+0.5) for i in range(ncol)]\n",
    "                analytical = [10.0*(1 - (xi/Lx)) for xi in x]\n",
    "                max_abs_err = max(abs(hi-ha) for hi,ha in zip(h, analytical))\n",
    "                modflow_diag['max_abs_error_linear_solution'] = max_abs_err\n",
    "                modflow_diag['analytical_ok'] = max_abs_err < 1e-3\n",
    "                print(f'Model run OK. Max abs error vs linear solution: {max_abs_err:.2e}')\n",
    "            else:\n",
    "                print('Model run failed.')\n",
    "except ModuleNotFoundError as e:\n",
    "    modflow_diag['error'] = f'FloPy not installed: {e}'\n",
    "except Exception as e:\n",
    "    modflow_diag['error'] = f'Unexpected error: {e}'\n",
    "diag_results['modflow'] = modflow_diag\n",
    "modflow_diag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1623fc",
   "metadata": {},
   "source": [
    "## 7. 3D Capability Check (Plotly Surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b1716",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_3d = {}\n",
    "try:\n",
    "    import numpy as np, plotly.graph_objects as go\n",
    "    X, Y = np.mgrid[-2:2:30j, -2:2:30j]\n",
    "    Z = np.exp(-(X**2 + Y**2))\n",
    "    fig3d = go.Figure(data=[go.Surface(z=Z, x=X, y=Y, colorscale='Viridis')])\n",
    "    fig3d.update_layout(title='3D Surface Test', margin=dict(l=0,r=0,b=0,t=30))\n",
    "    plotly_3d['success'] = True\n",
    "except Exception as e:\n",
    "    plotly_3d['success'] = False\n",
    "    plotly_3d['error'] = str(e)\n",
    "diag_results['viz']['plotly_3d'] = plotly_3d\n",
    "try: fig3d\n",
    "except NameError: pass\n",
    "plotly_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77654f21",
   "metadata": {},
   "source": [
    "## 8. System Resource Snapshot (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_snap = {}\n",
    "try:\n",
    "    import psutil\n",
    "    vm = psutil.virtual_memory()\n",
    "    sys_snap['memory_total_GB'] = round(vm.total/1024**3,2)\n",
    "    sys_snap['memory_available_GB'] = round(vm.available/1024**3,2)\n",
    "    proc = psutil.Process()\n",
    "    sys_snap['process_memory_MB'] = round(proc.memory_info().rss/1024**2,1)\n",
    "except Exception as e:\n",
    "    sys_snap['error'] = str(e)\n",
    "diag_results['system'] = sys_snap\n",
    "sys_snap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4aabfa",
   "metadata": {},
   "source": [
    "## 9. Aggregated Summary\n",
    "Run this cell last to see a compact readiness report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969340a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "summary = {}\n",
    "pkg_status = diag_results['packages'].get('status', {})\n",
    "missing = [p for p,s in pkg_status.items() if not s['ok']]\n",
    "summary['missing_packages'] = missing\n",
    "summary['modflow_executable_found'] = diag_results['modflow'].get('executable_found')\n",
    "summary['modflow_run_success'] = diag_results['modflow'].get('run_success')\n",
    "summary['modflow_linear_solution_ok'] = diag_results['modflow'].get('analytical_ok')\n",
    "summary['geospatial_errors'] = [k for k,v in diag_results['geospatial'].items() if isinstance(v,str) and v.startswith('ERROR')]\n",
    "summary['plotly_3d_success'] = diag_results['viz'].get('plotly_3d',{}).get('success')\n",
    "summary['overall_ready'] = (not missing) and summary['modflow_executable_found'] and summary['modflow_run_success'] and (summary['geospatial_errors']==[])\n",
    "diag_results['summary'] = summary\n",
    "print('=== DIAGNOSTICS SUMMARY ===')\n",
    "pprint(summary)\n",
    "if not summary['overall_ready']:\n",
    "    print('\\nOne or more checks failed. See above cells for details.')\n",
    "else:\n",
    "    print('\\nEnvironment appears READY for the course.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gw_course_students",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
